import { app, BrowserWindow, ipcMain, Menu, dialog, MenuItem, shell } from 'electron';
import { GitChunkedPushMain } from './git-chunked-push-main';
import fetch from 'node-fetch';

// Set the app name immediately
app.setName('Hive Consensus');

import * as path from 'path';
import * as fs from 'fs';
import simpleGit from 'simple-git';
import * as os from 'os';
import * as crypto from 'crypto';
import { Database } from 'sqlite3';
import { computeAnalytics } from './utils/analytics-compute';
import { spawn, ChildProcess } from 'child_process';
import { GitManager } from './git-manager';
import { GitManagerV2 } from './git-manager-v2';
import { EnhancedGitManager } from './git/EnhancedGitManager';
import { FileSystemManager } from './file-system';
import { ProcessManager } from './utils/ProcessManager';
import { PortManager } from './utils/PortManager';
// import { DirectConsensusEngine } from './consensus/DirectConsensusEngine';
import { SimpleConsensusEngine } from './consensus/SimpleConsensusEngine';
import { PidTracker } from './utils/PidTracker';
import { cliToolsDetector, setProcessManagerReference } from './main/cli-tools/detector';
import { CLI_TOOLS_REGISTRY } from './shared/types/cli-tools';
// Removed import - functions are now defined locally
import { logger } from './utils/SafeLogger';
import { registerTerminalHandlers, cleanupTerminals } from './terminal-ipc-handlers';
import { StartupOrchestrator } from './startup/StartupOrchestrator';
import { AIToolsDatabase } from './services/AIToolsDatabase';
import * as zlib from 'zlib';
import { isBackupDue, computeRetentionDeletes } from './utils/backup-policy';
import { ensureOpenRouterSchema, syncOpenRouter } from './maintenance/OpenRouterSync';

// This allows TypeScript to pick up the magic constants that's auto-generated by Forge's Webpack
// plugin that tells the Electron app where to look for the Webpack-bundled app code (depending on
// whether you're running in development or production).
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) {
  app.quit();
}

// Single source of truth for all process and port management
// Initialize early so it's available for all components
const processManager = new ProcessManager();

// Inject ProcessManager into CLI tools detector for dynamic port discovery
setProcessManagerReference(processManager);

let db: Database | null = null;
let dbFilePath: string | null = null;
let mainWindow: BrowserWindow | null = null;
// Help is now integrated into the main window - no separate help window needed

// Initialize SQLite database connection - use the existing hive-ai.db
const initDatabase = () => {
  // Use override path for tests if provided, else default to ~/.hive/hive-ai.db
  const overridePath = process.env.HIVE_DB_PATH;
  const defaultHiveDir = path.join(os.homedir(), '.hive');
  const dbPath = overridePath || path.join(defaultHiveDir, 'hive-ai.db');
  dbFilePath = dbPath;
  
  // Create parent directory if it doesn't exist
  const hiveDir = path.dirname(dbPath);
  if (!fs.existsSync(hiveDir)) {
    fs.mkdirSync(hiveDir, { recursive: true });
  }
  
  db = new Database(dbPath);
  
  // Apply recommended PRAGMAs
  db.exec('PRAGMA foreign_keys=ON;');
  db.exec('PRAGMA journal_mode=WAL;');
  db.exec('PRAGMA synchronous=NORMAL;');
  db.exec('PRAGMA busy_timeout=5000;');
  
  // The database already exists with proper schema
  // Just ensure the configurations table exists (matching Rust implementation)
  db.run(`CREATE TABLE IF NOT EXISTS configurations (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    encrypted BOOLEAN DEFAULT 0,
    user_id TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
  )`);
  
  // Ensure users table exists with default user
  db.run(`CREATE TABLE IF NOT EXISTS users (
    id TEXT PRIMARY KEY,
    email TEXT,
    tier TEXT
  )`);
  
  // Insert default user if not exists
  db.run(`INSERT OR IGNORE INTO users (id, email, tier) VALUES ('default', 'default@hive.ai', 'FREE')`);
  
  // Create consensus_settings table for active profile
  db.run(`CREATE TABLE IF NOT EXISTS consensus_settings (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
  )`);
  
  // Create general settings table for application preferences
  db.run(`CREATE TABLE IF NOT EXISTS settings (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
  )`);

  // Ensure OpenRouter schema exists (providers/models/aliases)
  ensureOpenRouterSchema(db);
  
  // Create sessions table for workspace persistence
  db.run(`CREATE TABLE IF NOT EXISTS sessions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    folder_path TEXT NOT NULL UNIQUE,
    tabs TEXT NOT NULL,
    active_tab TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
  )`);
  
  // Create recent_folders table
  db.run(`CREATE TABLE IF NOT EXISTS recent_folders (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    folder_path TEXT NOT NULL UNIQUE,
    last_opened TEXT DEFAULT CURRENT_TIMESTAMP,
    tab_count INTEGER DEFAULT 0
  )`);
  
  // Conversations and related analytics tables (ensure before stage_outputs)
  db.run(`CREATE TABLE IF NOT EXISTS conversations (
    id TEXT PRIMARY KEY,
    user_id TEXT,
    title TEXT,
    profile_id TEXT,
    total_cost REAL DEFAULT 0,
    total_tokens_input INTEGER DEFAULT 0,
    total_tokens_output INTEGER DEFAULT 0,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
  )`);

  db.run(`CREATE INDEX IF NOT EXISTS idx_conversations_created_at ON conversations(created_at)`);

  // Messages table used by memory/context systems and consensus logging
  db.run(`CREATE TABLE IF NOT EXISTS messages (
    id TEXT PRIMARY KEY,
    conversation_id TEXT,
    role TEXT,
    content TEXT,
    stage TEXT,
    model_used TEXT,
    tokens_used INTEGER DEFAULT 0,
    cost REAL DEFAULT 0,
    consensus_path TEXT,
    consensus_rounds INTEGER,
    parent_message_id TEXT,
    timestamp TEXT DEFAULT CURRENT_TIMESTAMP
  )`);

  // Migration: ensure expected columns exist on messages
  db.all(`PRAGMA table_info(messages)`, [], (err: any, cols: any[]) => {
    if (err || !cols) return;
    const names = new Set((cols || []).map((c: any) => c.name));
    const addCol = (sql: string) => db.run(sql, [], () => {});
    if (!names.has('stage')) addCol(`ALTER TABLE messages ADD COLUMN stage TEXT`);
    if (!names.has('model_used')) addCol(`ALTER TABLE messages ADD COLUMN model_used TEXT`);
    if (!names.has('tokens_used')) addCol(`ALTER TABLE messages ADD COLUMN tokens_used INTEGER DEFAULT 0`);
    if (!names.has('cost')) addCol(`ALTER TABLE messages ADD COLUMN cost REAL DEFAULT 0`);
    if (!names.has('consensus_path')) addCol(`ALTER TABLE messages ADD COLUMN consensus_path TEXT`);
    if (!names.has('consensus_rounds')) addCol(`ALTER TABLE messages ADD COLUMN consensus_rounds INTEGER`);
    if (!names.has('parent_message_id')) addCol(`ALTER TABLE messages ADD COLUMN parent_message_id TEXT`);
    if (!names.has('timestamp')) addCol(`ALTER TABLE messages ADD COLUMN timestamp TEXT DEFAULT CURRENT_TIMESTAMP`);
  });

  // Knowledge conversations: support both legacy (id, question, answer) and new (conversation_id, final_answer, source_of_truth)
  db.run(`CREATE TABLE IF NOT EXISTS knowledge_conversations (
    kc_id INTEGER PRIMARY KEY AUTOINCREMENT,
    id TEXT, -- optional legacy id
    conversation_id TEXT,
    question TEXT,
    answer TEXT,
    final_answer TEXT,
    source_of_truth TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
  )`);

  db.run(`CREATE TABLE IF NOT EXISTS conversation_usage (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT NOT NULL,
    conversation_id TEXT NOT NULL,
    timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
  )`);

  db.run(`CREATE TABLE IF NOT EXISTS performance_metrics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id TEXT NOT NULL,
    timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
    total_duration INTEGER,
    total_cost REAL,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
  )`);

  db.run(`CREATE TABLE IF NOT EXISTS cost_analytics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id TEXT NOT NULL,
    total_cost REAL,
    cost_per_token REAL,
    model_costs TEXT,
    optimization_potential REAL DEFAULT 0,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
  )`);

  // Create stage_outputs table to track model usage per stage
  db.run(`CREATE TABLE IF NOT EXISTS stage_outputs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id TEXT NOT NULL,
    stage_name TEXT NOT NULL,
    model TEXT NOT NULL,
    tokens_used INTEGER DEFAULT 0,
    cost REAL DEFAULT 0,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
  )`);
  
  // Keep consensus profiles table matching actual database schema
  db.run(`CREATE TABLE IF NOT EXISTS consensus_profiles (
    id TEXT PRIMARY KEY,
    profile_name TEXT NOT NULL,
    generator_model TEXT NOT NULL,
    refiner_model TEXT NOT NULL,
    validator_model TEXT NOT NULL,
    curator_model TEXT NOT NULL,
    max_consensus_rounds INTEGER DEFAULT 3,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
  )`);

  // Migration: Add max_consensus_rounds column if it doesn't exist
  db.run(`
    PRAGMA table_info(consensus_profiles)
  `, [], (err: any, rows: any[]) => {
    if (!err && rows) {
      const hasMaxRounds = rows.some((col: any) => col.name === 'max_consensus_rounds');
      if (!hasMaxRounds) {
        db.run(`ALTER TABLE consensus_profiles ADD COLUMN max_consensus_rounds INTEGER DEFAULT 3`, (err: any) => {
          if (!err) {
            console.log('âœ… Added max_consensus_rounds column to consensus_profiles table');
          }
        });
      }
    }
  });

  // Create consensus_iterations table to track model usage in iterative consensus
  db.run(`CREATE TABLE IF NOT EXISTS consensus_iterations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    consensus_id TEXT NOT NULL,
    datetime TEXT DEFAULT CURRENT_TIMESTAMP,
    model_id TEXT NOT NULL,
    stage_name TEXT NOT NULL,
    tokens_used INTEGER DEFAULT 0,
    count INTEGER DEFAULT 1,
    flag INTEGER DEFAULT 0,  -- 1 if model answered NO (cannot improve), 0 otherwise
    round_number INTEGER DEFAULT 1
  )`);
  
  // Create indexes for better query performance
  db.run(`CREATE INDEX IF NOT EXISTS idx_consensus_iterations_consensus_id 
          ON consensus_iterations(consensus_id)`);
  db.run(`CREATE INDEX IF NOT EXISTS idx_consensus_iterations_stage_model 
          ON consensus_iterations(stage_name, model_id)`);
  db.run(`CREATE INDEX IF NOT EXISTS idx_consensus_iterations_datetime 
          ON consensus_iterations(datetime)`);

  // Welcome analytics table
  db.run(`CREATE TABLE IF NOT EXISTS welcome_analytics (
    id INTEGER PRIMARY KEY,
    action TEXT NOT NULL,
    timestamp TEXT DEFAULT CURRENT_TIMESTAMP
  )`);
};

// Toggle to switch between implementations
// 0 = old GitManager, 1 = GitManagerV2, 2 = EnhancedGitManager with Auth
const GIT_MANAGER_VERSION = 2; // Use EnhancedGitManager with authentication

// Git Integration
let gitManager: GitManager | GitManagerV2 | EnhancedGitManager | null = null;

// Initialize Git manager - pass no path when no folder is open
const findGitRoot = async (startPath: string): Promise<string | null> => {
  try {
    const git = simpleGit(startPath);
    const isRepo = await git.checkIsRepo();
    if (!isRepo) {
      // Walk up to find a .git directory
      let dir = startPath;
      // Guard against empty/relative
      try { dir = path.resolve(dir); } catch {}
      while (true) {
        const gitDir = path.join(dir, '.git');
        if (fs.existsSync(gitDir)) return dir;
        const parent = path.dirname(dir);
        if (!parent || parent === dir) break;
        dir = parent;
      }
      return null;
    }
    // Use rev-parse for canonical root
    const root = await git.revparse(['--show-toplevel']).catch(() => startPath);
    return root || startPath;
  } catch {
    return null;
  }
};

const getConfigValue = async (key: string): Promise<string | null> => {
  return new Promise((resolve) => {
    try {
      db?.get('SELECT value FROM configurations WHERE key = ?', [key], (err: any, row: any) => {
        if (err || !row) return resolve(null);
        resolve(String(row.value ?? ''));
      });
    } catch { resolve(null); }
  });
};

const shouldPreferOpenedFolderRoot = async (): Promise<boolean> => {
  const v = await getConfigValue('git_prefer_opened_folder_root');
  return v === 'true';
};

const initGitManager = async (folderPath?: string) => {
  if (!folderPath) {
    logger.info('[Main] No folder path provided, GitManager will return null status');
    // Don't create a manager when no folder is open
    gitManager = null;
    return;
  }
  // Decide repo path: either prefer opened folder, or auto-detect nearest Git root
  let repoPathToUse = folderPath;
  try {
    const preferOpened = await shouldPreferOpenedFolderRoot();
    if (!preferOpened) {
      const detectedRoot = await findGitRoot(folderPath);
      if (detectedRoot && detectedRoot !== folderPath) {
        repoPathToUse = detectedRoot;
        logger.info(`[Main] Auto-detected Git root: ${detectedRoot} (from ${folderPath})`);
      }
    } else {
      logger.info('[Main] Respecting preference: using opened folder as Git root');
    }
  } catch {}
  
  if (GIT_MANAGER_VERSION === 2) {
    logger.info('[Main] Using EnhancedGitManager with authentication support for:', repoPathToUse);
    gitManager = new EnhancedGitManager(repoPathToUse);
    await (gitManager as EnhancedGitManager).initialize();
  } else if (GIT_MANAGER_VERSION === 1) {
    logger.info('[Main] Using GitManagerV2 with VS Code-style implementation');
    gitManager = new GitManagerV2(repoPathToUse);
  } else {
    logger.info('[Main] Using old GitManager with simple-git');
    gitManager = new GitManager(repoPathToUse);
  }
};

// File System Manager
let fileSystemManager: FileSystemManager | null = null;

// Initialize File System manager
const initFileSystemManager = () => {
  fileSystemManager = new FileSystemManager();
};

const createWindow = (show: boolean = true): BrowserWindow => {
  // Don't create duplicate windows
  if (mainWindow && !mainWindow.isDestroyed()) {
    logger.info('[Main] Window already exists, focusing it');
    if (show) mainWindow.focus();
    return mainWindow;
  }

  // Create the browser window.
  mainWindow = new BrowserWindow({
    height: 600,
    show: false, // Always start hidden, show later if requested
    width: 800,
    minWidth: 700, // Prevent window from becoming too small
    minHeight: 400,
    title: 'Hive Consensus',
    icon: path.join(__dirname, '../resources/icon.png'), // Icon for the window
    webPreferences: {
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY,
      nodeIntegration: false,
      contextIsolation: true,
      webSecurity: false, // Allow HTTP requests to localhost for development
      webviewTag: true, // Enable webview tags for ttyd terminals
    },
  });

  // and load the index.html of the app.
  mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY);

  // Open the DevTools.
  // mainWindow.webContents.openDevTools(); // Disabled to prevent warning overlay
  
  // Register terminal handlers with the shared ProcessManager
  // This is safe to call multiple times as it updates the window reference
  registerTerminalHandlers(mainWindow, processManager);
  
  // Create application menu
  createApplicationMenu();
  
  // Show window if requested
  if (show && mainWindow) {
    mainWindow.show();
    mainWindow.focus();
  }
  
  // After window creation, schedule backup if due (daily/weekly)
  try {
    scheduleAutoBackupIfDue();
  } catch (e) {
    logger.warn('[Backup] scheduleAutoBackupIfDue error', { error: e });
  }
  
  // Schedule OpenRouter provider/model sync (startup + daily)
  try {
    scheduleOpenRouterSync();
  } catch (e) {
    logger.warn('[OpenRouterSync] schedule error', { error: e });
  }

  return mainWindow;
};

// Retrieve OpenRouter API key from unified DB
async function getOpenRouterKeyFromDb(): Promise<string | null> {
  return new Promise((resolve) => {
    if (!db) return resolve(null);
    db.get('SELECT value FROM configurations WHERE key = ?', ['openrouter_api_key'], (err: any, row: any) => {
      resolve(row?.value || null);
    });
  });
}

async function runOpenRouterSyncOnce(): Promise<void> {
  try {
    const key = await getOpenRouterKeyFromDb();
    if (!key) { logger.info('[OpenRouterSync] No OpenRouter API key set; skipping sync'); return; }
    if (!db) { logger.warn('[OpenRouterSync] DB not initialized'); return; }
    const res = await syncOpenRouter(db, key);
    logger.info(`[OpenRouterSync] providers=${res.providersUpserted} models=${res.modelsUpserted} deactivated=${res.modelsDeactivated}`);
    // Store last-sync timestamp
    const ts = new Date().toISOString();
    db.run(`INSERT INTO configurations (key, value, updated_at) VALUES (?, ?, ?)
            ON CONFLICT(key) DO UPDATE SET value=excluded.value, updated_at=excluded.updated_at`,
      ['openrouter_last_sync', ts, ts]
    );
  } catch (e) {
    logger.error('[OpenRouterSync] Sync error', { error: e });
  }
}

function scheduleOpenRouterSync(): void {
  // Run once shortly after startup
  setTimeout(() => { runOpenRouterSyncOnce().catch(() => {}); }, 3000);
  // Run every 24h
  const dayMs = 24 * 60 * 60 * 1000;
  setInterval(() => { runOpenRouterSyncOnce().catch(() => {}); }, dayMs);
}

// Manual trigger
ipcMain.handle('models-sync-now', async () => {
  await runOpenRouterSyncOnce();
  return { ok: true };
});

const registerGitHandlers = () => {
  // Git IPC handlers
  ipcMain.handle('git-status', async () => {
    if (!gitManager) {
      // No folder is open, return null to show welcome screen
      logger.info('[Main] git-status: No folder open, returning null');
      return null;
    }
    const status = await gitManager.getStatus();
    try {
      // Attach repo root for UI transparency
      let repoPath: string;
      if ('getRepoPath' in gitManager && typeof (gitManager as any).getRepoPath === 'function') {
        repoPath = (gitManager as any).getRepoPath();
      } else {
        repoPath = (gitManager as any).repoPath;
      }
      return { ...(status || {}), repoPath };
    } catch {
      return status;
    }
  });

  ipcMain.handle('git-branches', async () => {
    if (!gitManager) {
      logger.info('[Main] git-branches: No folder open, returning empty');
      return { all: [], branches: {}, current: null, detached: false };
    }
    return await gitManager.getBranches();
  });

  ipcMain.handle('git-log', async (_, options?: { maxCount?: number; graph?: boolean; oneline?: boolean; limit?: number }) => {
    if (!gitManager) {
      logger.info('[Main] git-log: No folder open, returning empty');
      return '';
    }
    logger.info('[Main] git-log called with options:', options);
    const result = await gitManager.getLog(options || {});
    logger.info('[Main] git-log returning:', result ? result.substring(0, 100) + '...' : 'empty');
    return result;
  });

  ipcMain.handle('git-diff', async (_, file?: string) => {
    if (!gitManager) return '';
    return await gitManager.getDiff(file);
  });

  ipcMain.handle('git-staged-diff', async (_, file?: string) => {
    if (!gitManager) return '';
    return await gitManager.getStagedDiff(file);
  });

  ipcMain.handle('git-stage', async (_, files: string[]) => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    return await gitManager.stage(files);
  });

  ipcMain.handle('git-unstage', async (_, files: string[]) => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    return await gitManager.unstage(files);
  });

  ipcMain.handle('git-commit', async (_, message: string) => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    return await gitManager.commit(message);
  });

  ipcMain.handle('git-discard', async (_, files: string[]) => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    return await gitManager.discard(files);
  });

  ipcMain.handle('git-clean', async (_, files: string[]) => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    return await gitManager.clean(files);
  });

  ipcMain.handle('git-push', async () => {
    logger.info('[Main] git-push IPC called');
    if (!gitManager) {
      throw new Error('No folder open');
    }
    try {
      if (gitManager instanceof EnhancedGitManager) {
        const result = await gitManager.push();
        logger.info('[Main] git-push result:', result);
        if (!result.success) {
          throw new Error(result.error || 'Push failed');
        }
        return result.output;
      } else {
        const result = await gitManager!.push();
        logger.info('[Main] git-push completed successfully');
        return result;
      }
    } catch (error: any) {
      logger.error('[Main] git-push failed:', error);
      throw error;
    }
  });
  
  // Chunked push for large repositories
  ipcMain.handle('git-push-chunked', async () => {
    logger.info('[Main] git-push-chunked IPC called');
    if (!gitManager) {
      throw new Error('No folder open');
    }
    try {
      // Get the repository path from the git manager
      let repoPath: string;
      if ('getRepoPath' in gitManager && typeof gitManager.getRepoPath === 'function') {
        repoPath = gitManager.getRepoPath();
      } else {
        // Fallback to accessing the property directly
        repoPath = (gitManager as any).repoPath;
      }
      
      logger.info('[Main] Using repository path for chunked push:', repoPath);
      const result = await GitChunkedPushMain.pushInBatches(repoPath);
      logger.info('[Main] git-push-chunked result:', result);
      if (!result.success) {
        throw new Error(result.message);
      }
      return result.message;
    } catch (error: any) {
      logger.error('[Main] git-push-chunked failed:', error);
      throw error;
    }
  });
  
  // Get repository statistics
  ipcMain.handle('git-repo-stats', async () => {
    logger.info('[Main] git-repo-stats IPC called');
    if (!gitManager) {
      throw new Error('No folder open');
    }
    try {
      // Get the repository path from the git manager
      let repoPath: string;
      if ('getRepoPath' in gitManager && typeof gitManager.getRepoPath === 'function') {
        repoPath = gitManager.getRepoPath();
      } else {
        // Fallback to accessing the property directly
        repoPath = (gitManager as any).repoPath;
      }
      
      // Get current git status to know how many commits to push
      const gitStatus = await gitManager.getStatus();
      
      logger.info('[Main] Using repository path for stats:', repoPath);
      const stats = await GitChunkedPushMain.getRepoStats(repoPath, gitStatus);
      logger.info('[Main] Repository stats:', stats);
      return stats;
    } catch (error: any) {
      logger.error('[Main] git-repo-stats failed:', error);
      throw error;
    }
  });

  // Push with options support
  ipcMain.handle('git-push-with-options', async (_event, options: any) => {
    logger.info('[Main] git-push-with-options IPC called with:', options);
    if (!gitManager) {
      throw new Error('No folder open');
    }
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      // Get the repository path
      let repoPath: string;
      if ('getRepoPath' in gitManager && typeof gitManager.getRepoPath === 'function') {
        repoPath = gitManager.getRepoPath();
      } else {
        repoPath = (gitManager as any).repoPath;
      }
      
      // Build git push command with options
      let command: string;
      
      // Check if we have a custom command FIRST
      if (options.customCommand) {
        command = options.customCommand;
        // Custom command should already have all necessary options
        logger.info('[Main] Using custom command:', command);
      } else {
        // Build standard git push command
        command = 'git push';
        
        if (options.forceWithLease) {
          command += ' --force-with-lease';
        }
        if (options.includeTags) {
          command += ' --tags';
        }
        if (options.setUpstream) {
          // Get current branch name
          const status = await gitManager.getStatus();
          const branch = status.current || 'main';
          command += ` -u origin ${branch}`;
        }
        if (options.atomic) {
          command += ' --atomic';
        }
        if (options.signPush) {
          command += ' --signed';
        }
        if (options.thinPack) {
          command += ' --thin';
        }
        if (options.commitLimit) {
          // Push only last N commits
          const status = await gitManager.getStatus();
          const branch = status.current || 'main';
          command = `git push origin HEAD~${options.commitLimit}:${branch}`;
          
          // Add other options if commit limit is set
          if (options.forceWithLease) command += ' --force-with-lease';
          if (options.atomic) command += ' --atomic';
        }
      }
      
      logger.info('[Main] Executing push command:', command);
      const result = await execAsync(command, { cwd: repoPath, maxBuffer: 10 * 1024 * 1024 });
      
      logger.info('[Main] Push with options completed successfully');
      return result.stdout || 'Push completed successfully';
    } catch (error: any) {
      logger.error('[Main] git-push-with-options failed:', error);
      throw error;
    }
  });

  // Push with --force-with-lease
  ipcMain.handle('git-push-force-lease', async () => {
    logger.info('[Main] git-push-force-lease IPC called');
    if (!gitManager) {
      throw new Error('No folder open');
    }
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      let repoPath: string;
      if ('getRepoPath' in gitManager && typeof gitManager.getRepoPath === 'function') {
        repoPath = gitManager.getRepoPath();
      } else {
        repoPath = (gitManager as any).repoPath;
      }
      
      const result = await execAsync('git push --force-with-lease', { 
        cwd: repoPath,
        maxBuffer: 10 * 1024 * 1024 
      });
      
      logger.info('[Main] Force with lease push completed successfully');
      return result.stdout || 'Force push with lease completed successfully';
    } catch (error: any) {
      logger.error('[Main] git-push-force-lease failed:', error);
      throw error;
    }
  });

  // Push custom command
  ipcMain.handle('git-push-custom', async (_event, command: string) => {
    logger.info('[Main] git-push-custom IPC called with:', command);
    if (!gitManager) {
      throw new Error('No folder open');
    }
    
    // Security check - ensure command starts with "git push"
    if (!command.trim().startsWith('git push')) {
      throw new Error('Custom command must start with "git push" for security');
    }
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      let repoPath: string;
      if ('getRepoPath' in gitManager && typeof gitManager.getRepoPath === 'function') {
        repoPath = gitManager.getRepoPath();
      } else {
        repoPath = (gitManager as any).repoPath;
      }
      
      logger.info('[Main] Executing custom push command:', command);
      const result = await execAsync(command, { 
        cwd: repoPath,
        maxBuffer: 10 * 1024 * 1024,
        timeout: 600000 // 10 minute timeout for large pushes
      });
      
      logger.info('[Main] Custom push completed successfully');
      return result.stdout || 'Custom push completed successfully';
    } catch (error: any) {
      logger.error('[Main] git-push-custom failed:', error);
      throw error;
    }
  });

  // Push dry run
  ipcMain.handle('git-push-dry-run', async (_event, options: any) => {
    logger.info('[Main] git-push-dry-run IPC called with:', options);
    if (!gitManager) {
      throw new Error('No folder open');
    }
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      let repoPath: string;
      if ('getRepoPath' in gitManager && typeof gitManager.getRepoPath === 'function') {
        repoPath = gitManager.getRepoPath();
      } else {
        repoPath = (gitManager as any).repoPath;
      }
      
      let command: string;
      
      // Check if we have a custom command
      if (options?.customCommand) {
        command = options.customCommand;
        // Add --dry-run if not already present
        if (!command.includes('--dry-run')) {
          command += ' --dry-run';
        }
        // Add --porcelain for consistent output
        if (!command.includes('--porcelain')) {
          command += ' --porcelain';
        }
      } else {
        // Build command with --dry-run
        command = 'git push --dry-run --porcelain';
        
        if (options?.forceWithLease) {
          command += ' --force-with-lease';
        }
        if (options?.includeTags) {
          command += ' --tags';
        }
        if (options?.setUpstream) {
          const status = await gitManager.getStatus();
          const branch = status.current || 'main';
          command += ` -u origin ${branch}`;
        }
      }
      
      logger.info('[Main] Executing dry run:', command);
      const result = await execAsync(command, { cwd: repoPath });
      
      logger.info('[Main] Dry run completed');
      return result.stdout || 'Dry run completed - no changes made';
    } catch (error: any) {
      // Dry run often returns non-zero exit code, but that's OK
      if (error.stdout) {
        return error.stdout;
      }
      logger.error('[Main] git-push-dry-run failed:', error);
      throw error;
    }
  });

  ipcMain.handle('git-pull', async () => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    if (gitManager instanceof EnhancedGitManager) {
      const result = await gitManager.pull();
      if (!result.success) {
        throw new Error(result.error || 'Pull failed');
      }
      return result.output;
    } else {
      return await gitManager!.pull();
    }
  });

  ipcMain.handle('git-sync', async () => {
    logger.info('[Main] git-sync IPC called');
    if (!gitManager) {
      throw new Error('No folder open');
    }
    try {
      if (gitManager instanceof EnhancedGitManager) {
        const result = await gitManager.sync();
        logger.info('[Main] git-sync result:', result);
        if (!result.success) {
          throw new Error(result.error || 'Sync failed');
        }
        return result.output;
      } else if (gitManager instanceof GitManagerV2) {
        const result = await gitManager.sync();
        logger.info('[Main] git-sync completed successfully');
        return result;
      } else {
        // Fallback for old GitManager - do pull then push
        await gitManager!.pull();
        await gitManager!.push();
        logger.info('[Main] git-sync (pull+push) completed successfully');
        return;
      }
    } catch (error: any) {
      logger.error('[Main] git-sync failed:', error);
      throw error;
    }
  });

  ipcMain.handle('git-fetch', async () => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    if (gitManager instanceof EnhancedGitManager) {
      const result = await gitManager.fetch();
      if (!result.success) {
        throw new Error(result.error || 'Fetch failed');
      }
      return result.output;
    } else {
      return await gitManager!.fetch();
    }
  });

  ipcMain.handle('git-switch-branch', async (_, branchName: string) => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    return await gitManager.switchBranch(branchName);
  });

  ipcMain.handle('git-create-branch', async (_, branchName: string) => {
    if (!gitManager) {
      throw new Error('No folder open');
    }
    return await gitManager.createBranch(branchName);
  });

  ipcMain.handle('git-file-status', async (_, filePath: string) => {
    if (!gitManager) return null;
    const status = await gitManager.getStatus();
    const filesArray: any[] = Array.isArray(status.files) ? status.files : [];
    const file = filesArray.find((f: any) => f.path === filePath);
    if (file) {
      if (file.index !== ' ' && file.index !== '?') return 'staged';
      if (file.working === 'M') return 'modified';
      if (file.working === 'D') return 'deleted';
      if (file.working === '?') return 'untracked';
      if (file.working === 'A') return 'added';
    }
    return null;
  });
  
  // Initialize Git repository
  ipcMain.handle('git-init', async (_, repoPath: string) => {
    const git = new GitManager(repoPath);
    await git.initRepo();
    return { success: true };
  });
  
  // Get files changed in a commit
  ipcMain.handle('git-commit-files', async (_, hash: string) => {
    if (!gitManager) return [];
    return await gitManager.getCommitFiles(hash);
  });
  
  // Get diff for a specific file in a commit
  ipcMain.handle('git-file-diff', async (_, commitHash: string, filePath: string) => {
    if (!gitManager) return '';
    return await gitManager.getFileDiff(commitHash, filePath);
  });
  
  // Clone repository (enterprise auth via EnhancedGitManager)
  ipcMain.handle('git-clone', async (_,
    url: string,
    parentDirectory: string
  ) => {
    try {
      if (!url || !parentDirectory) {
        throw new Error('Missing repository URL or destination');
      }
      
      // Derive repo folder name from URL
      const repoNameMatch = url
        .replace(/\\\\/g, '/')
        .split('/')
        .pop() || 'repository';
      const normalizedName = repoNameMatch.replace(/\.git$/, '');
      const destination = path.join(parentDirectory, normalizedName);
      
      // Ensure parent exists
      if (!fs.existsSync(parentDirectory)) {
        fs.mkdirSync(parentDirectory, { recursive: true });
      }
      
      // If destination exists and is non-empty, fail fast to avoid overwriting
      if (fs.existsSync(destination)) {
        const listing = fs.readdirSync(destination);
        if (listing.length > 0) {
          throw new Error(`Destination already exists and is not empty: ${destination}`);
        }
      }
      
      // Use EnhancedGitManager for authenticated clone
      const cloneManager = new EnhancedGitManager(destination);
      const result = await cloneManager.clone(url, destination);
      
      if (!result.success) {
        throw new Error(result.error || 'Clone failed');
      }
      
      // Initialize git manager for this new repo path so UI can use Git features immediately
      await initGitManager(destination);
      
      return { success: true, destination, output: result.output };
    } catch (error: any) {
      logger.error('[Git] Clone failed:', error);
      return { success: false, error: error?.message || String(error) };
    }
  });
  
  // Update Git manager when folder changes
  ipcMain.handle('git-set-folder', async (_, folderPath: string) => {
    logger.info('[Git] Setting folder to:', folderPath || '(none)');
    
    // If empty string or null, clear the git manager
    if (!folderPath) {
      gitManager = null;
      logger.info('[Git] Cleared Git manager - no folder open');
      return { success: true };
    }
    
    // Initialize with the new folder
    await initGitManager(folderPath);
    return { success: true };
  });
  
  // Get submodule status
  ipcMain.handle('git-submodule-status', async (_, submodulePath: string) => {
    if (!gitManager) return '';
    try {
      // Create a new git instance for the submodule
      const simpleGit = (await import('simple-git')).default;
      const submoduleGit = simpleGit(submodulePath);
      const result = await submoduleGit.status();
      let statusText = '';
      
      // Format the status nicely
      if (result.ahead || result.behind) {
        statusText += `Your branch is ${result.ahead ? `ahead by ${result.ahead}` : ''} ${result.behind ? `behind by ${result.behind}` : ''}\n`;
      }
      
      // List modified files
      if (result.files && result.files.length > 0) {
        result.files.forEach((file: any) => {
          let status = '';
          // Check both index and working_dir for changes
          if (file.index === 'M' || file.working_dir === 'M') status = 'modified:';
          else if (file.index === 'A') status = 'new file:';
          else if (file.index === 'D' || file.working_dir === 'D') status = 'deleted:';
          else if (file.working_dir === '?' || file.index === '?') status = 'untracked:';
          
          if (status) {
            statusText += `${status}   ${file.path}\n`;
          }
        });
      }
      
      return statusText || 'Working directory clean';
    } catch (error) {
      logger.error('[Git] Failed to get submodule status:', error);
      return `Error: ${error}`;
    }
  });

  // Welcome analytics logging
  ipcMain.handle('db-welcome-analytics-log', async (_, action: string) => {
    return new Promise((resolve, reject) => {
      if (!db) { reject('Database not initialized'); return; }
      try {
        const safeAction = String(action || '').replace(/'/g, "''");
        db!.exec(`INSERT INTO welcome_analytics (action, timestamp) VALUES ('${safeAction}', CURRENT_TIMESTAMP);`);
        resolve({ success: true });
      } catch (err) {
        logger.error('[WelcomeAnalytics] Failed to log action', { action, error: err });
        reject(err);
      }
    });
  });

  // DB maintenance helpers
  ipcMain.handle('db-compact', async () => {
    return new Promise((resolve, reject) => {
      if (!db) { reject('Database not initialized'); return; }
      db.run('VACUUM', (err) => {
        if (err) reject(err); else resolve({ success: true });
      });
    });
  });
  ipcMain.handle('db-integrity-check', async () => {
    return new Promise((resolve, reject) => {
      if (!db) { reject('Database not initialized'); return; }
      db.get('PRAGMA integrity_check', (err, row: any) => {
        if (err) reject(err); else resolve({ result: row ? Object.values(row)[0] : 'unknown' });
      });
    });
  });

  // Backup database using VACUUM INTO for a consistent snapshot
  ipcMain.handle('db-backup', async (_evt, opts: any) => {
    return new Promise((resolve, reject) => {
      try {
        if (!db) { reject('Database not initialized'); return; }
        const destPath = typeof opts === 'string' ? opts : opts?.destPath;
        if (!destPath) { reject('Destination path required'); return; }
        const password: string | undefined = typeof opts === 'object' ? (opts.password || undefined) : undefined;
        const compress: boolean = !!(typeof opts === 'object' && opts.compress);
        // Produce a plain snapshot file first
        const safe = String(destPath).replace(/'/g, "''");
        const plainPath = password ? destPath + '.tmpplain' : destPath;
        const safePlain = String(plainPath).replace(/'/g, "''");
        db!.exec(`PRAGMA wal_checkpoint(TRUNCATE);`);
        db!.exec(`VACUUM INTO '${safePlain}';`);
        if (password) {
          // Encrypt plain snapshot into destPath
          try {
            const crypto = require('crypto');
            const salt = crypto.randomBytes(16);
            const iv = crypto.randomBytes(12);
            const key = crypto.scryptSync(password, salt, 32);
            const cipher = crypto.createCipheriv('aes-256-gcm', key, iv);
            let data = fs.readFileSync(plainPath);
            // optional compression before encryption
            const header = Buffer.from(compress ? 'HIVEENC2' : 'HIVEENC1');
            if (compress) {
              data = zlib.gzipSync(data);
            }
            const enc = Buffer.concat([cipher.update(data), cipher.final()]);
            const tag = cipher.getAuthTag();
            const out = Buffer.concat([header, salt, iv, tag, enc]);
            fs.writeFileSync(destPath, out);
            fs.unlinkSync(plainPath);
          } catch (e) {
            try { if (fs.existsSync(plainPath)) fs.unlinkSync(plainPath); } catch {}
            reject(e);
            return;
          }
        } else if (compress) {
          // gzip the plain snapshot
          try {
            const data = fs.readFileSync(plainPath);
            const gz = zlib.gzipSync(data);
            fs.writeFileSync(destPath, gz);
            fs.unlinkSync(plainPath);
          } catch (e) {
            try { if (fs.existsSync(plainPath)) fs.unlinkSync(plainPath); } catch {}
            reject(e);
            return;
          }
        }
        resolve({ success: true, path: destPath, encrypted: !!password, compressed: compress });
      } catch (err) {
        logger.error('[DB] Backup failed', { error: err });
        reject(err);
      }
    });
  });

  // Restore database from a provided snapshot
  ipcMain.handle('db-restore', async (_evt, opts: any) => {
    return new Promise((resolve, reject) => {
      try {
        const srcPath = typeof opts === 'string' ? opts : opts?.srcPath;
        const password: string | undefined = typeof opts === 'object' ? (opts.password || undefined) : undefined;
        if (!srcPath) { reject('Source path required'); return; }
        if (!db) { reject('Database not initialized'); return; }
        const targetPath = (db as any).filename as string;
        const { Database: SqliteDatabase } = require('sqlite3');
        // If encrypted, decrypt to temp
        let candidatePath = srcPath;
        try {
          const fd = fs.openSync(srcPath, 'r');
          const header = Buffer.alloc(8);
          fs.readSync(fd, header, 0, 8, 0);
          fs.closeSync(fd);
          if (header.toString() === 'HIVEENC1' || header.toString() === 'HIVEENC2') {
            if (!password) {
              reject(new Error('Encrypted backup requires password'));
              return;
            }
            const blob = fs.readFileSync(srcPath);
            const salt = blob.subarray(8, 24);
            const iv = blob.subarray(24, 36);
            const tag = blob.subarray(36, 52);
            const enc = blob.subarray(52);
            const crypto = require('crypto');
            const key = crypto.scryptSync(password, salt, 32);
            const decipher = crypto.createDecipheriv('aes-256-gcm', key, iv);
            decipher.setAuthTag(tag);
            let dec = Buffer.concat([decipher.update(enc), decipher.final()]);
            if (header.toString() === 'HIVEENC2') {
              dec = zlib.gunzipSync(dec);
            }
            const tmp = targetPath + '.tmprestore';
            fs.writeFileSync(tmp, dec);
            candidatePath = tmp;
          } else if (header[0] === 0x1f && header[1] === 0x8b) { // gzip magic
            const blob = fs.readFileSync(srcPath);
            const dec = zlib.gunzipSync(blob);
            const tmp = targetPath + '.tmprestore';
            fs.writeFileSync(tmp, dec);
            candidatePath = tmp;
          }
        } catch (e) {
          reject(e);
          return;
        }
        // Validate candidate DB integrity
        const srcDb = new SqliteDatabase(candidatePath);
        srcDb.get('PRAGMA integrity_check', (err: any, row: any) => {
          if (err) {
            srcDb.close();
            reject(err);
            return;
          }
          const result = row ? Object.values(row)[0] : 'unknown';
          if (String(result).toLowerCase() !== 'ok') {
            srcDb.close();
            reject(new Error('Integrity check failed for backup file'));
            return;
          }
          // Close both DBs, copy file, re-init
          srcDb.close();
          (db as any).close((closeErr: any) => {
            if (closeErr) {
              reject(closeErr);
              return;
            }
            try {
              fs.copyFileSync(candidatePath, targetPath);
              if (candidatePath.endsWith('.tmprestore')) { try { fs.unlinkSync(candidatePath); } catch {} }
              // Reopen DB
              initDatabase();
              resolve({ success: true, path: targetPath });
            } catch (copyErr) {
              reject(copyErr);
            }
          });
        });
      } catch (err) {
        logger.error('[DB] Restore failed', { error: err });
        reject(err);
      }
    });
  });
  
  // Get submodule diff
  ipcMain.handle('git-submodule-diff', async (_, submodulePath: string) => {
    if (!gitManager) return '';
    try {
      // Create a new git instance for the submodule
      const simpleGit = (await import('simple-git')).default;
      const submoduleGit = simpleGit(submodulePath);
      const diff = await submoduleGit.diff();
      return diff;
    } catch (error) {
      logger.error('[Git] Failed to get submodule diff:', error);
      return '';
    }
  });
};

const registerDialogHandlers = () => {
  // Dialog IPC handlers
  ipcMain.handle('show-open-dialog', async (_, options: any) => {
    const result = await dialog.showOpenDialog(mainWindow!, options);
    return result;
  });
  
  ipcMain.handle('show-save-dialog', async (_, options: any) => {
    const result = await dialog.showSaveDialog(mainWindow!, options);
    return result;
  });
  
  ipcMain.handle('show-message-box', async (_, options: any) => {
    const result = await dialog.showMessageBox(mainWindow!, options);
    return result;
  });
  
  ipcMain.handle('open-external', async (_, url: string) => {
    try {
      await shell.openExternal(url);
      return true;
    } catch (error) {
      console.error('Failed to open external URL:', error);
      return false;
    }
  });

  // Reveal a file in OS file manager
  ipcMain.handle('reveal-in-folder', async (_evt, targetPath: string) => {
    try {
      shell.showItemInFolder(targetPath);
      return true;
    } catch (e) {
      logger.error('[Reveal] Failed', { error: e });
      return false;
    }
  });
  // Open a path (file or folder) with OS default
  ipcMain.handle('open-path', async (_evt, targetPath: string) => {
    try {
      const res = await shell.openPath(targetPath);
      return res === '';
    } catch (e) {
      logger.error('[OpenPath] Failed', { error: e });
      return false;
    }
  });
  // List backups in configured backup dir
  ipcMain.handle('list-backups', async () => {
    try {
      // Determine backup dir using same logic as performBackupWithRetention
      let dirSetting: string | null = await new Promise((resolve) => {
        db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.dir' ], (err: any, row: any) => resolve(err ? null : (row ? row.value : null)));
      });
      if (!dirSetting || dirSetting.trim() === '') dirSetting = process.env.HIVE_BACKUP_DIR || null;
      const dir = dirSetting && dirSetting.trim() !== '' ? dirSetting : getBackupDir();
      if (!fs.existsSync(dir)) return [];
      const entries = fs.readdirSync(dir)
        .filter(f => f.endsWith('.sqlite') || f.endsWith('.sqlite.gz'))
        .map(f => {
          const p = path.join(dir, f);
          const s = fs.statSync(p);
          return { name: f, path: p, size: s.size, mtimeMs: s.mtimeMs };
        })
        .sort((a, b) => b.mtimeMs - a.mtimeMs);
      return entries;
    } catch (e) {
      logger.error('[Backups] list failed', { error: e });
      return [];
    }
  });
  ipcMain.handle('delete-backup', async (_evt, filePath: string) => {
    try {
      if (filePath && fs.existsSync(filePath)) fs.unlinkSync(filePath);
      return true;
    } catch (e) {
      logger.error('[Backups] delete failed', { error: e });
      return false;
    }
  });
  
  ipcMain.handle('show-input-dialog', async (_, title: string, defaultValue?: string) => {
    // For now, use a simple prompt-like dialog
    // In a real app, you'd create a custom dialog
    const result = await dialog.showMessageBox(mainWindow!, {
      type: 'question',
      buttons: ['OK', 'Cancel'],
      defaultId: 0,
      title: title,
      message: title,
      detail: defaultValue || ''
    });
    
    if (result.response === 0) {
      // In a real implementation, you'd get the actual input value
      // For now, return a placeholder
      return 'https://github.com/user/repo.git';
    }
    return null;
  });
  
  ipcMain.handle('set-title', (_, title: string) => {
    if (mainWindow) {
      mainWindow.setTitle(title);
    }
  });
};

const registerFileSystemHandlers = () => {
  // File System IPC handlers
  ipcMain.handle('fs-get-tree', async (_, rootPath?: string) => {
    if (!fileSystemManager) initFileSystemManager();
    // Only return files if a root path is explicitly provided
    if (!rootPath) {
      logger.info('[Main] fs-get-tree called without root path, returning empty');
      return [];
    }
    logger.info('[Main] fs-get-tree called with root:', rootPath);
    const result = await fileSystemManager!.getFileTree(rootPath);
    logger.info(`[Main] fs-get-tree returning ${result?.length || 0} items`);
    return result;
  });

  ipcMain.handle('fs-get-directory', async (_, dirPath: string) => {
    if (!fileSystemManager) initFileSystemManager();
    logger.info('[Main] fs-get-directory called for:', dirPath);
    const result = await fileSystemManager!.getDirectoryContents(dirPath);
    logger.info(`[Main] fs-get-directory returning ${result?.length || 0} items for ${dirPath}`);
    return result;
  });

  ipcMain.handle('fs-read-file', async (_, filePath: string) => {
    if (!fileSystemManager) initFileSystemManager();
    return await fileSystemManager!.readFile(filePath);
  });

  ipcMain.handle('fs-write-file', async (_, filePath: string, content: string) => {
    if (!fileSystemManager) initFileSystemManager();
    return await fileSystemManager!.writeFileContent(filePath, content);
  });

  ipcMain.handle('fs-watch-file', async (_, filePath: string) => {
    if (!fileSystemManager) initFileSystemManager();
    fileSystemManager!.watchFile(filePath, () => {
      // Send file change event to renderer
      if (mainWindow) {
        mainWindow.webContents.send('file-changed', filePath);
      }
    });
    return true; // Must return something when using ipcMain.handle
  });

  ipcMain.handle('fs-unwatch-file', async (_, filePath: string) => {
    if (!fileSystemManager) initFileSystemManager();
    fileSystemManager!.unwatchFile(filePath);
    return true; // Must return something when using ipcMain.handle
  });

  ipcMain.handle('fs-search', async (_, rootPath: string, pattern: string) => {
    if (!fileSystemManager) initFileSystemManager();
    return await fileSystemManager!.searchFiles(rootPath, pattern);
  });

  ipcMain.handle('fs-stats', async (_, filePath: string) => {
    if (!fileSystemManager) initFileSystemManager();
    return await fileSystemManager!.getFileStats(filePath);
  });
  
  ipcMain.handle('fs-create-file', async (_, dirPath: string, fileName: string) => {
    try {
      const fs = require('fs').promises;
      const path = require('path');
      const filePath = path.join(dirPath, fileName);
      logger.info('[Main] Creating file:', filePath);
      await fs.writeFile(filePath, '', 'utf8');
      logger.info('[Main] File created successfully:', filePath);
      return true;
    } catch (error) {
      logger.error('[Main] Failed to create file:', error);
      throw error;
    }
  });
  
  ipcMain.handle('fs-create-folder', async (_, dirPath: string, folderName: string) => {
    try {
      const fs = require('fs').promises;
      const path = require('path');
      const folderPath = path.join(dirPath, folderName);
      logger.info('[Main] Creating folder:', folderPath);
      await fs.mkdir(folderPath, { recursive: true });
      logger.info('[Main] Folder created successfully:', folderPath);
      return true;
    } catch (error) {
      logger.error('[Main] Failed to create folder:', error);
      throw error;
    }
  });
  
  ipcMain.handle('fs-move-file', async (_, sourcePath: string, targetPath: string) => {
    try {
      const fs = require('fs').promises;
      logger.info(`[Main] Moving: ${sourcePath} to ${targetPath}`);
      await fs.rename(sourcePath, targetPath);
      logger.info('[Main] Move successful');
      return true;
    } catch (error) {
      logger.error('[Main] Failed to move file:', error);
      throw error;
    }
  });
  
  ipcMain.handle('fs-file-exists', async (_, filePath: string) => {
    try {
      const fs = require('fs').promises;
      await fs.access(filePath);
      return true;
    } catch {
      return false;
    }
  });
};

const createApplicationMenu = () => {
  const template: any[] = [
    {
      label: 'File',
      submenu: [
        {
          label: 'New File',
          accelerator: 'CmdOrCtrl+N',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-new-file');
            }
          }
        },
        {
          label: 'Open File',
          accelerator: 'CmdOrCtrl+O',
          click: async () => {
            const result = await dialog.showOpenDialog(mainWindow!, {
              properties: ['openFile'],
              filters: [
                { name: 'All Files', extensions: ['*'] },
                { name: 'JavaScript', extensions: ['js', 'jsx'] },
                { name: 'TypeScript', extensions: ['ts', 'tsx'] },
                { name: 'HTML', extensions: ['html', 'htm'] },
                { name: 'CSS', extensions: ['css', 'scss', 'less'] },
                { name: 'JSON', extensions: ['json'] },
                { name: 'Markdown', extensions: ['md'] }
              ]
            });
            
            if (!result.canceled && result.filePaths.length > 0) {
              if (mainWindow) {
                mainWindow.webContents.send('menu-open-file', result.filePaths[0]);
              }
            }
          }
        },
        {
          label: 'Open Folder',
          accelerator: 'CmdOrCtrl+K CmdOrCtrl+O',
          click: async () => {
            const result = await dialog.showOpenDialog(mainWindow!, {
              properties: ['openDirectory']
            });
            
            if (!result.canceled && result.filePaths.length > 0) {
              if (mainWindow) {
                mainWindow.webContents.send('menu-open-folder', result.filePaths[0]);
              }
            }
          }
        },
        {
          label: 'Close Folder',
          accelerator: 'CmdOrCtrl+K F',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-close-folder');
            }
          }
        },
        { type: 'separator' },
        {
          label: 'Save',
          accelerator: 'CmdOrCtrl+S',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-save');
            }
          }
        },
        {
          label: 'Save As...',
          accelerator: 'CmdOrCtrl+Shift+S',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-save-as');
            }
          }
        },
        { type: 'separator' },
        {
          label: 'Auto Save',
          type: 'checkbox',
          checked: false,
          click: (menuItem: any) => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-toggle-auto-save', menuItem.checked);
            }
          }
        },
        { type: 'separator' },
        {
          label: 'Close Tab',
          accelerator: 'CmdOrCtrl+W',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-close-tab');
            }
          }
        },
        {
          label: 'Close All Tabs',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-close-all-tabs');
            }
          }
        },
        { type: 'separator' },
        {
          label: 'Exit',
          accelerator: process.platform === 'darwin' ? 'Cmd+Q' : 'Ctrl+Q',
          click: () => {
            app.quit();
          }
        }
      ]
    },
    {
      label: 'Edit',
      submenu: [
        { label: 'Undo', accelerator: 'CmdOrCtrl+Z', role: 'undo' },
        { label: 'Redo', accelerator: 'CmdOrCtrl+Y', role: 'redo' },
        { type: 'separator' },
        { label: 'Cut', accelerator: 'CmdOrCtrl+X', role: 'cut' },
        { label: 'Copy', accelerator: 'CmdOrCtrl+C', role: 'copy' },
        { label: 'Paste', accelerator: 'CmdOrCtrl+V', role: 'paste' },
        { type: 'separator' },
        { label: 'Select All', accelerator: 'CmdOrCtrl+A', role: 'selectAll' },
        { type: 'separator' },
        {
          label: 'Find',
          accelerator: 'CmdOrCtrl+F',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-find');
            }
          }
        },
        {
          label: 'Replace',
          accelerator: 'CmdOrCtrl+H',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-replace');
            }
          }
        }
      ]
    },
    {
      label: 'View',
      submenu: [
        {
          label: 'Toggle File Explorer',
          accelerator: 'CmdOrCtrl+B',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-toggle-explorer');
            }
          }
        },
        {
          label: 'Toggle Source Control',
          accelerator: 'CmdOrCtrl+Shift+G',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-toggle-git');
            }
          }
        },
        {
          label: 'Toggle Terminal',
          accelerator: 'CmdOrCtrl+`',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-toggle-terminal');
            }
          }
        },
        { type: 'separator' },
        { 
          label: 'Reload', 
          accelerator: 'CmdOrCtrl+R', 
          click: () => {
            if (mainWindow) {
              logger.info('[Menu] Reloading with state reset...');
              // Clear Git folder state before reload
              mainWindow.webContents.send('menu-reset-state');
              // Give it a moment to clear state, then reload
              setTimeout(() => {
                mainWindow.webContents.reload();
              }, 100);
            }
          }
        },
        { label: 'Force Reload', accelerator: 'CmdOrCtrl+Shift+R', role: 'forceReload' },
        { label: 'Toggle Developer Tools', accelerator: 'F12', role: 'toggleDevTools' },
        { type: 'separator' },
        { label: 'Actual Size', accelerator: 'CmdOrCtrl+0', role: 'resetZoom' },
        { label: 'Zoom In', accelerator: 'CmdOrCtrl+Plus', role: 'zoomIn' },
        { label: 'Zoom Out', accelerator: 'CmdOrCtrl+-', role: 'zoomOut' },
        { type: 'separator' },
        { label: 'Toggle Fullscreen', accelerator: 'F11', role: 'togglefullscreen' }
      ]
    },
    {
      label: 'Go',
      submenu: [
        {
          label: 'Go to File...',
          accelerator: 'CmdOrCtrl+P',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-go-to-file');
            }
          }
        },
        {
          label: 'Go to Line...',
          accelerator: 'CmdOrCtrl+G',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-go-to-line');
            }
          }
        }
      ]
    },
    {
      label: 'Window',
      submenu: [
        { label: 'Minimize', accelerator: 'CmdOrCtrl+M', role: 'minimize' },
        { label: 'Close', accelerator: 'CmdOrCtrl+W', role: 'close' }
      ]
    },
    {
      label: 'Help',
      submenu: [
        {
          label: 'Show Welcome',
          accelerator: 'CmdOrCtrl+Shift+W',
          click: () => {
            mainWindow?.webContents.send('menu-show-welcome');
          }
        },
        { type: 'separator' },
        {
          label: 'Documentation',
          accelerator: 'CmdOrCtrl+/',
          click: () => {
            mainWindow?.webContents.send('menu-help-documentation');
          }
        },
        { type: 'separator' },
        {
          label: 'About',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('menu-about');
            }
          }
        }
      ]
    }
  ];

  // macOS specific menu adjustments
  if (process.platform === 'darwin') {
    template.unshift({
      label: app.getName(),
      submenu: [
        { label: 'About ' + app.getName(), role: 'about' },
        { type: 'separator' },
        { label: 'Services', role: 'services', submenu: [] },
        { type: 'separator' },
        { label: 'Hide ' + app.getName(), accelerator: 'Command+H', role: 'hide' },
        { label: 'Hide Others', accelerator: 'Command+Shift+H', role: 'hideothers' },
        { label: 'Show All', role: 'unhide' },
        { type: 'separator' },
        { label: 'Quit', accelerator: 'Command+Q', click: () => app.quit() }
      ]
    });
  }

  const menu = Menu.buildFromTemplate(template);
  Menu.setApplicationMenu(menu);
};

// ===== Auto Backup Logic =====
function getBackupDir(): string {
  const overridePath = process.env.HIVE_BACKUP_DIR;
  if (overridePath) return overridePath;
  const dir = path.join(os.homedir(), '.hive', 'backups');
  if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
  return dir;
}

async function performBackupWithRetention(): Promise<string | null> {
  if (!db) return null;
  // Prefer user-configured backup.dir if set, else env/default
  let dirSetting: string | null = await new Promise((resolve) => {
    db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.dir' ], (err: any, row: any) => resolve(err ? null : (row ? row.value : null)));
  });
  if (!dirSetting || dirSetting.trim() === '') dirSetting = process.env.HIVE_BACKUP_DIR || null;
  const dir = dirSetting && dirSetting.trim() !== '' ? dirSetting : getBackupDir();
  if (!fs.existsSync(dir)) { try { fs.mkdirSync(dir, { recursive: true }); } catch {}
  }
  const alwaysCompress = await new Promise<string | null>((resolve) => {
    db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.alwaysCompress' ], (err: any, row: any) => resolve(err ? null : (row ? row.value : null)));
  });
  const compress = (alwaysCompress || '0') === '1';
  const ts = new Date().toISOString().replace(/[:.]/g, '-');
  const dest = path.join(dir, `hive-ai-backup-${ts}.sqlite${compress ? '.gz' : ''}`);
  // Use existing IPC handler logic but call locally
  try {
    // Checkpoint and vacuum into file
    db.exec('PRAGMA wal_checkpoint(TRUNCATE);');
    const tmp = compress ? dest.replace(/\.gz$/, '') : dest;
    db.exec(`VACUUM INTO '${tmp.replace(/'/g, "''")}';`);
    if (compress) {
      const data = fs.readFileSync(tmp);
      const gz = zlib.gzipSync(data);
      fs.writeFileSync(dest, gz);
      fs.unlinkSync(tmp);
    }
    // Retention: keep N most recent (default 7)
    const retentionVal = await new Promise<string | null>((resolve) => {
      db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.retentionCount' ], (err: any, row: any) => {
        resolve(err ? null : (row ? row.value : null));
      });
    });
    const retention = Math.max(1, parseInt(retentionVal || '7', 10));
    const files = fs.readdirSync(dir)
      .filter(f => f.endsWith('.sqlite') || f.endsWith('.sqlite.gz'))
      .map(f => ({ name: path.join(dir, f), mtimeMs: fs.statSync(path.join(dir, f)).mtimeMs }));
    const deletes = computeRetentionDeletes(files, retention);
    deletes.forEach(p => { try { fs.unlinkSync(p); } catch {} });
    // Update last backup time
    const nowIso = new Date().toISOString();
    db.run('INSERT OR REPLACE INTO settings (key, value, updated_at) VALUES (?, ?, CURRENT_TIMESTAMP)', ['backup.lastBackupAt', nowIso]);
    logger.info('[Backup] Completed', { dest, retention, removed: deletes.length });
    return dest;
  } catch (e) {
    logger.error('[Backup] Failed', { error: e });
    return null;
  }
}

async function scheduleAutoBackupIfDue() {
  if (!db) return;
  // Load auto backup settings
  const settings = await new Promise<Record<string, string | null>>((resolve) => {
    const result: Record<string, string | null> = {};
    db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.autoEnabled' ], (e1: any, r1: any) => {
      result.enabled = e1 ? null : (r1 ? r1.value : null);
      db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.frequency' ], (e2: any, r2: any) => {
        result.frequency = e2 ? null : (r2 ? r2.value : null);
        db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.lastBackupAt' ], (e3: any, r3: any) => {
          result.last = e3 ? null : (r3 ? r3.value : null);
          resolve(result as any);
        });
      });
    });
  });
  const autoEnabled = (settings.enabled || '0') === '1';
  const freq = (settings.frequency as any) || 'manual';
  if (!autoEnabled) return;
  if (freq === 'daily' || freq === 'weekly') {
    if (isBackupDue(settings.last, freq)) {
      await performBackupWithRetention();
    }
  }
  // Reminder if auto not enabled and last backup older than reminderDays
  const enabled = (settings.enabled || '0') === '1';
  if (!enabled) {
    const daysStr = await new Promise<string | null>((resolve) => {
      db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.reminderDays' ], (err: any, row: any) => resolve(err ? null : (row ? row.value : null)));
    });
    const days = Math.max(1, parseInt(daysStr || '7', 10));
    const lastIso = settings.last;
    const snoozeUntil = await new Promise<string | null>((resolve) => {
      db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.snoozeUntil' ], (err: any, row: any) => resolve(err ? null : (row ? row.value : null)));
    });
    if (snoozeUntil) {
      const snoozeDate = new Date(snoozeUntil);
      if (!isNaN(snoozeDate.getTime()) && Date.now() < snoozeDate.getTime()) {
        return; // snoozed
      }
    }
    const last = lastIso ? new Date(lastIso) : null;
    const ms = days * 24 * 60 * 60 * 1000;
    const overdue = !last || ((Date.now() - last.getTime()) >= ms);
    if (overdue && mainWindow) {
      const res = await dialog.showMessageBox(mainWindow, {
        type: 'question',
        buttons: ['Enable Auto Backup', 'Backup Now', 'Remind Me Later', 'Dismiss'],
        defaultId: 0,
        cancelId: 3,
        title: 'Backup Reminder',
        message: 'Protect your data: enable auto backup or create a backup now?',
        detail: 'Auto backups are currently disabled and your last backup appears to be older than recommended.'
      });
      if (res.response === 0) {
        // Enable weekly by default
        db!.run('INSERT OR REPLACE INTO settings (key, value, updated_at) VALUES (?, ?, CURRENT_TIMESTAMP)', ['backup.autoEnabled', '1']);
        db!.run('INSERT OR REPLACE INTO settings (key, value, updated_at) VALUES (?, ?, CURRENT_TIMESTAMP)', ['backup.frequency', 'weekly']);
      } else if (res.response === 1) {
        await performBackupWithRetention();
      } else if (res.response === 2) {
        const until = new Date(Date.now() + ms).toISOString();
        db!.run('INSERT OR REPLACE INTO settings (key, value, updated_at) VALUES (?, ?, CURRENT_TIMESTAMP)', ['backup.snoozeUntil', until]);
      }
    }
  }
}

app.on('before-quit', async (e) => {
  try {
    if (!db) return;
    // on-exit backup if enabled
    const enabled = await new Promise<string | null>((resolve) => {
      db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.autoEnabled' ], (err: any, row: any) => resolve(err ? null : (row ? row.value : null)));
    });
    const freq = await new Promise<string | null>((resolve) => {
      db!.get('SELECT value FROM settings WHERE key = ?',[ 'backup.frequency' ], (err: any, row: any) => resolve(err ? null : (row ? row.value : null)));
    });
    if (enabled === '1' && freq === 'on-exit') {
      await performBackupWithRetention();
    }
  } catch (err) {
    logger.warn('[Backup] before-quit backup skipped', { error: err });
  }
});

// ========== MEMORY SERVICE INTEGRATION ==========
// Memory Service management - uses the shared ProcessManager instance
// Ports are now fully dynamic - allocated by PortManager at runtime
// No hardcoded port values needed!

// CLI Tools Manager for AI CLI integration
// Note: The manager is now initialized as a singleton in registerCliToolHandlers()
// let cliToolsManager: CliToolsManager | null = null;  // DEPRECATED - using singleton pattern now



// Initialize ProcessManager and register all managed processes
const initializeProcessManager = () => {
  // Determine the correct path for Memory Service based on packaging
  let memoryServicePath: string;
  if (app.isPackaged) {
    // Production: Use memory-service from unpacked location
    // Since forge.config.ts now unpacks .webpack/main/memory-service/**
    // we can use it directly without extraction
    const unpackedPath = path.join(
      process.resourcesPath, 
      'app.asar.unpacked',
      '.webpack',
      'main',
      'memory-service',
      'index.js'
    );
    
    // Verify the unpacked file exists
    const fs = require('fs');
    if (fs.existsSync(unpackedPath)) {
      memoryServicePath = unpackedPath;
      logger.info(`[Main] Using unpacked Memory Service at: ${memoryServicePath}`);
    } else {
      // Fallback to extraction if unpacked version not found (shouldn't happen with v2.0 build)
      logger.warn('[Main] Unpacked Memory Service not found, falling back to extraction');
      const tempDir = path.join(app.getPath('temp'), 'hive-consensus', 'memory-service');
      
      if (!fs.existsSync(tempDir)) {
        fs.mkdirSync(tempDir, { recursive: true });
      }
      
      const sourceFile = path.join(app.getAppPath(), '.webpack', 'main', 'memory-service', 'index.js');
      const targetFile = path.join(tempDir, 'index.js');
      
      const content = fs.readFileSync(sourceFile, 'utf8');
      fs.writeFileSync(targetFile, content);
      
      memoryServicePath = targetFile;
      logger.info(`[Main] Memory Service extracted to: ${memoryServicePath}`);
    }
  } else {
    // Development: Use TypeScript version with ts-node
    memoryServicePath = path.join(app.getAppPath(), 'src', 'memory-service', 'index.ts');
  }
  
  // Register Memory Service configuration
  processManager.registerProcess({
    name: 'memory-service',
    scriptPath: memoryServicePath,
    args: [],
    env: {
      NODE_ENV: app.isPackaged ? 'production' : 'development',
      TS_NODE_TRANSPILE_ONLY: 'true'  // Use env var instead of arg (only for dev)
    },
    port: 1, // Just indicates this service needs a port - actual port allocated dynamically
    autoRestart: true,
    maxRestarts: 2, // Reduced for faster failure detection
    restartDelay: 500 // Reduced for faster recovery
    // Health checks disabled - causing startup issues
  });
  
  // Register WebSocket Consensus Backend with bundled Python support
  // In production, the backend server should be bundled with the app
  let consensusBackendPath: string;
  let bundledPythonPath: string;
  
  if (app.isPackaged) {
    // Production: Use bundled backend server and Python runtime
    const resourcesPath = process.resourcesPath;
    consensusBackendPath = path.join(resourcesPath, 'app.asar.unpacked', '.webpack', 'main', 'binaries', 'hive-backend-server-enhanced');
    // Use bundled Python runtime for AI Helpers
    const pythonRuntimePath = path.join(resourcesPath, 'app.asar.unpacked', '.webpack', 'main', 'resources', 'python-runtime', 'python');
    bundledPythonPath = process.platform === 'win32'
      ? path.join(pythonRuntimePath, 'python.exe')
      : path.join(pythonRuntimePath, 'bin', 'python3');
  } else {
    // Development: Use relative paths that work for any developer
    const hiveProjectRoot = path.resolve(__dirname, '..', '..', '..');
    consensusBackendPath = path.join(
      hiveProjectRoot,
      'target', 'debug', 'hive-backend-server-enhanced'
    );
    // Try to find Python in common locations
    const possiblePythonPaths = [
      path.join(hiveProjectRoot, 'venv', 'bin', 'python3'),
      path.join(hiveProjectRoot, '.venv', 'bin', 'python3'),
      '/usr/bin/python3',
      '/usr/local/bin/python3',
      'python3' // Fall back to system Python
    ];
    bundledPythonPath = possiblePythonPaths.find(p => {
      try {
        require('child_process').execFileSync(p, ['--version']);
        return true;
      } catch {
        return false;
      }
    }) || 'python3';
  }
  
  // Always register the backend - ProcessManager will handle errors gracefully
  registerWebSocketBackend();
  
  function registerWebSocketBackend() {
    logger.info('[ProcessManager] Registering WebSocket backend at:', consensusBackendPath);
    
    // In production, create symlinks to avoid spaces in Python paths
    let finalPythonPath = bundledPythonPath;
    let finalModelScript: string;
    
    if (app.isPackaged) {
      // Production: COPY Python runtime to /tmp to avoid dylib loading issues
      const fs = require('fs-extra');
      const pythonRuntimePath = path.join(process.resourcesPath, 'app.asar.unpacked', '.webpack', 'main', 'resources', 'python-runtime');
      const extractedBase = '/tmp/hive-python-runtime';
      
      try {
        // Check if we need to extract (or re-extract if app updated)
        const versionFile = path.join(extractedBase, '.version');
        const appVersion = app.getVersion();
        let needsExtraction = !fs.existsSync(extractedBase);
        
        if (!needsExtraction && fs.existsSync(versionFile)) {
          try {
            const extractedVersion = fs.readFileSync(versionFile, 'utf8').trim();
            needsExtraction = extractedVersion !== appVersion;
            if (needsExtraction) {
              logger.info(`[ProcessManager] App version changed (${extractedVersion} -> ${appVersion}), re-extracting Python runtime`);
            }
          } catch {
            needsExtraction = true;
          }
        }
        
        if (needsExtraction) {
          logger.info(`[ProcessManager] Extracting Python runtime to ${extractedBase}...`);
          
          // Remove old extraction if exists
          if (fs.existsSync(extractedBase)) {
            try { 
              fs.removeSync(extractedBase); 
            } catch (err) {
              logger.warn('[ProcessManager] Could not remove old extraction, will overwrite:', err);
            }
          }
          
          // Copy entire Python runtime directory
          fs.copySync(pythonRuntimePath, extractedBase, {
            overwrite: true,
            preserveTimestamps: true,
            dereference: true // Follow symlinks when copying
          });
          
          // Write version file
          fs.writeFileSync(versionFile, appVersion);
          
          // Ensure Python binary is executable
          const pythonBin = path.join(extractedBase, 'python', 'bin', 'python3');
          if (fs.existsSync(pythonBin)) {
            fs.chmodSync(pythonBin, 0o755);
          }
          
          logger.info(`[ProcessManager] Successfully extracted Python runtime to ${extractedBase}`);
        } else {
          logger.info(`[ProcessManager] Python runtime already extracted at ${extractedBase}`);
        }
        
        // Use extracted paths (no spaces, proper dylib loading)
        finalPythonPath = path.join(extractedBase, 'python', 'bin', 'python3');
        // Use model_service_wrapper.py for production (handles subprocess communication)
        finalModelScript = path.join(extractedBase, 'models', 'model_service_wrapper.py');
        
        logger.info('[ProcessManager] Using extracted Python path:', finalPythonPath);
        logger.info('[ProcessManager] Using extracted model script:', finalModelScript);
      } catch (err) {
        logger.error('[ProcessManager] Failed to extract Python runtime:', err);
        // Fallback to original paths (will likely fail with dylib issues)
        // Use model_service_wrapper.py for production (handles subprocess communication)
        finalModelScript = path.join(pythonRuntimePath, 'models', 'model_service_wrapper.py');
      }
    } else {
      // Development: use paths as-is
      // Use model_service_wrapper.py for production (handles subprocess communication)
      finalModelScript = path.join(app.getAppPath(), 'resources', 'python-runtime', 'models', 'model_service_wrapper.py');
    }
    
    logger.info('[ProcessManager] Final Python path:', finalPythonPath);
    logger.info('[ProcessManager] Final model script:', finalModelScript);
    
    processManager.registerProcess({
      name: 'websocket-backend',
      scriptPath: consensusBackendPath,
      args: [],
      env: {
        RUST_LOG: 'info',
        NODE_ENV: app.isPackaged ? 'production' : 'development',
        HIVE_BUNDLED_PYTHON: finalPythonPath,
        HIVE_BUNDLED_MODEL_SCRIPT: finalModelScript,
        // Pass the database location explicitly
        HIVE_HOME: path.join(os.homedir(), '.hive')
      },
      port: 1, // Just indicates this service needs a port - actual port allocated dynamically
      autoRestart: true,
      maxRestarts: 2, // Reduced for faster failure detection
      restartDelay: 1000 // Reduced for faster recovery
      // Health checks disabled - causing startup issues
    });
  }
  
  // Listen for process messages
  processManager.on('process:message', (name: string, msg: any) => {
    if (name === 'memory-service') {
      if (msg.type === 'ready') {
        logger.info('[Main] Memory Service ready on port:', msg.port);
        
        // Note: MCP configurations removed - using direct API integration instead
        const port = msg.port || processManager.getProcessStatus('memory-service')?.port;
        logger.info(`[Main] Memory Service available on port ${port} for direct API access`);
      } else if (msg.type === 'db-query') {
        handleMemoryServiceDbQuery(msg);
      }
    } else if (name === 'websocket-backend') {
      if (msg.type === 'ready') {
        logger.info('[Main] WebSocket backend ready on port:', msg.port);
        // Port is already stored in ProcessManager
      }
    }
  });
  
  // Listen for process status changes
  processManager.on('process:crashed', (name: string) => {
    logger.error(`[Main] Process ${name} crashed`);
    mainWindow?.webContents.send('process-status', { name, status: 'crashed' });
  });
  
  processManager.on('process:started', (name: string) => {
    logger.info(`[Main] Process ${name} started`);
    mainWindow?.webContents.send('process-status', { name, status: 'running' });
  });
  
  processManager.on('process:unhealthy', (name: string, error: any) => {
    logger.error(`[Main] Process ${name} health check failed:`, error.message);
    mainWindow?.webContents.send('process-health', { name, healthy: false, error: error.message });
  });
  
  // AI Helper specific events
  processManager.on('aihelper:error', (data: any) => {
    logger.error('[Main] AI Helper Error:', data);
    // Send to renderer for UI notification
    mainWindow?.webContents.send('aihelper-error', data);
    
    // Log to reporting system
    if (data.issue?.includes('model_service_wrapper.py')) {
      logger.error('[Main] CRITICAL: Wrong Python script configured - consensus will fail!');
      logger.error('[Main] Fix: Update model script path to use model_service_wrapper.py');
    }
  });
  
  processManager.on('aihelper:warning', (data: any) => {
    logger.warn('[Main] AI Helper Warning:', data);
    mainWindow?.webContents.send('aihelper-warning', data);
  });
  
  processManager.on('aihelper:ready', (data: any) => {
    logger.info('[Main] AI Helper Ready:', data);
    mainWindow?.webContents.send('aihelper-ready', data);
  });
  
  processManager.on('aihelper:validation:failed', (data: any) => {
    logger.error('[Main] AI Helper Validation Failed:', data);
    // Show critical error in UI
    mainWindow?.webContents.send('critical-error', {
      title: 'AI Helper Validation Failed',
      message: data.issue,
      details: `Process: ${data.process}\nTimestamp: ${data.timestamp}`,
      action: 'Consensus routing may not work. Check logs for details.'
    });
  });
  
  processManager.on('health:failed', (data: any) => {
    logger.error('[Main] Health Check Failed:', data);
    if (data.component === 'ai-helpers') {
      mainWindow?.webContents.send('critical-error', {
        title: 'AI Helper Health Check Failed',
        message: data.issue,
        details: `Process: ${data.process}\nComponent: ${data.component}\nTimestamp: ${data.timestamp}`,
        action: 'System attempting automatic recovery...'
      });
    }
  });
};

// IPC handler to get all process statuses
ipcMain.handle('process-manager-status', async () => {
  const processes = processManager.getAllProcesses();
  return processes.map(p => ({
    name: p.name,
    status: p.status,
    pid: p.pid,
    port: p.port,
    lastError: p.lastError,
    restartCount: p.restartCount
  }));
});

// IPC handler to get specific service port
ipcMain.handle('get-service-port', async (_, serviceName: string) => {
  const processInfo = processManager.getProcessStatus(serviceName);
  return processInfo?.port || null;
});

// IPC handler to get app version for About dialog
ipcMain.handle('get-app-version', async () => {
  const packageJson = require('../package.json');
  return packageJson.version;
});

// IPC handler to interrupt consensus
ipcMain.handle('interrupt-consensus', async () => {
  console.log('ðŸ›‘ Interrupt consensus requested');
  
  // Interrupt the active consensus engine if it exists
  if (consensusEngine && typeof consensusEngine.interrupt === 'function') {
    consensusEngine.interrupt();
    console.log('âœ… Consensus engine interrupted successfully');
  } else {
    console.log('âš ï¸ No active consensus engine to interrupt');
  }
  
  return true;
});

// IPC handler to get WebSocket backend port specifically
ipcMain.handle('get-websocket-port', async () => {
  const processInfo = processManager.getProcessStatus('websocket-backend');
  const port = processInfo?.port;
  if (!port) {
    throw new Error('WebSocket backend not running or port not allocated');
  }
  return port;
});

// IPC handler to get full process manager status report
ipcMain.handle('process-manager-full-status', async () => {
  return processManager.getFullStatus();
});

// IPC handler to debug a specific process
ipcMain.handle('process-manager-debug', async (_, processName: string) => {
  return await processManager.debugProcess(processName);
});

// IPC handler to log process manager status to console
ipcMain.handle('process-manager-log-status', async () => {
  processManager.logStatus();
  return { logged: true };
});

// Send message to Memory Service process
const sendToMemoryService = (message: any) => {
  const processInfo = processManager.getProcessStatus('memory-service');
  if (processInfo && processInfo.process && processInfo.process.send) {
    processInfo.process.send(message);
  } else {
    logger.error('[Main] Memory Service process not available for IPC');
  }
};

// Handle database queries from Memory Service
const handleMemoryServiceDbQuery = (msg: any) => {
  logger.info('[Main] Received db-query from Memory Service:', msg.sql);
  
  if (!db) {
    logger.error('[Main] Database not initialized');
    sendToMemoryService({
      type: 'db-result',
      id: msg.id,
      error: 'Database not initialized',
      data: null
    });
    return;
  }
  
  // Execute query with callback-based sqlite3
  db.all(msg.sql, msg.params, (error, rows) => {
    logger.info('[Main] Database query result:', error ? `Error: ${error.message}` : `${rows?.length || 0} rows`);
    
    sendToMemoryService({
      type: 'db-result',
      id: msg.id,
      error: error ? error.message : null,
      data: rows || []
    });
  });
};

// Register Memory Service IPC handlers
const registerMemoryServiceHandlers = () => {
  logger.info('[Main] Registering Memory Service IPC handlers');
  
  ipcMain.handle('memory-service-start', async () => {
    logger.info('[Main] IPC: memory-service-start');
    
    const status = processManager.getProcessStatus('memory-service');
    if (status && status.status === 'running') {
      logger.info('[Main] Memory Service already running');
      return true;
    }
    
    try {
      logger.info('[Main] Starting Memory Service as child process...');
      
      // Use ts-node to run TypeScript directly from source directory
      const scriptPath = path.join(app.getAppPath(), 'src', 'memory-service', 'index.ts');
      logger.info('[Main] Memory Service script path:', scriptPath);
      
      // Start using ProcessManager
      const started = await processManager.startProcess('memory-service');
      
      if (started) {
        // Port is now stored in ProcessManager - no need to track separately
        const processInfo = processManager.getProcessStatus('memory-service');
        if (processInfo?.port) {
          logger.info(`[Main] Memory Service started on dynamic port ${processInfo.port}`);
        }
      }
      
      return started;
      
    } catch (error) {
      logger.error('[Main] Failed to start Memory Service:', error);
      return false;
    }
  });

  ipcMain.handle('memory-service-stop', async () => {
    logger.info('[Main] IPC: memory-service-stop');
    return await processManager.stopProcess('memory-service');
  });

  ipcMain.handle('memory-service-status', async () => {
    const status = processManager.getProcessStatus('memory-service');
    const isRunning = status?.status === 'running';
    logger.info('[Main] IPC: memory-service-status, result:', isRunning);
    return isRunning;
  });

  ipcMain.handle('memory-service-stats', async () => {
    try {
      const port = processManager.getProcessStatus('memory-service')?.port;
      if (!port) throw new Error('Memory Service not running');
      const response = await fetch(`http://localhost:${port}/api/v1/memory/stats`);
      if (response.ok) {
        const stats = await response.json();
        
        // Override connectedTools count with accurate CLI Tools detector data
        const supportedTools = ['claude-code', 'gemini-cli', 'qwen-code', 'openai-codex', 'cline', 'grok'];
        let actualConnectedCount = 0;
        
        for (const toolId of supportedTools) {
          try {
            const toolStatus = await cliToolsDetector.detectTool(toolId);
            if (toolStatus.installed && toolStatus.memoryServiceConnected) {
              actualConnectedCount++;
            }
          } catch (error) {
            // Tool check failed, doesn't count as connected
          }
        }
        
        stats.connectedTools = actualConnectedCount;
        logger.debug(`[Main] Corrected connected tools count: ${actualConnectedCount}`);
        return stats;
      }
    } catch (error) {
      logger.error('[Main] Failed to get memory stats:', error);
    }
    
    // Return default stats if service is not available
    return {
      totalMemories: 0,
      queriesToday: 0,
      contributionsToday: 0,
      connectedTools: 0,
      hitRate: 0,
      avgResponseTime: 0
    };
  });

  ipcMain.handle('memory-service-tools', async () => {
    try {
      // Use working CLI Tools detector instead of broken Memory Service tracking
      const connectedTools = [];
      const supportedTools = ['claude-code', 'gemini-cli', 'qwen-code', 'openai-codex', 'cline', 'grok'];
      
      for (const toolId of supportedTools) {
        try {
          const toolStatus = await cliToolsDetector.detectTool(toolId);
          if (toolStatus.installed && toolStatus.memoryServiceConnected) {
            connectedTools.push({
              name: toolStatus.name || toolId,
              version: toolStatus.version,
              connectedAt: new Date().toISOString(), // Use current time as connected time
              queryCount: 0, // CLI detector doesn't track query count
              contributionCount: 0, // CLI detector doesn't track contributions  
              lastActivity: new Date().toISOString() // Use current time as last activity
            });
          }
        } catch (error) {
          logger.debug(`[Main] Error checking ${toolId}:`, error);
        }
      }
      
      logger.info(`[Main] Connected tools via CLI detector: ${connectedTools.length}`);
      return connectedTools;
    } catch (error) {
      logger.error('[Main] Failed to get connected tools via CLI detector:', error);
      return [];
    }
  });

  ipcMain.handle('memory-service-activity', async (_, limit: number = 50) => {
    try {
      const port = processManager.getProcessStatus('memory-service')?.port;
      if (!port) throw new Error('Memory Service not running');
      const response = await fetch(`http://localhost:${port}/api/v1/memory/activity?limit=${limit}`);
      if (response.ok) {
        const data = await response.json();
        return data.activity || [];
      }
    } catch (error) {
      logger.error('[Main] Failed to get activity stream:', error);
    }
    return [];
  });
  
  // Memory Service Export/Import functionality removed (replaced by Settings â†’ Advanced backup/restore)
};

// ========== CLI TOOLS MANAGEMENT (DEPRECATED - NOW IN registerSimpleCliToolHandlers) ==========
// Initialize CLI Tools Manager (DEPRECATED - using singleton pattern now)
/* DEPRECATED - Now using singleton pattern in registerSimpleCliToolHandlers()
const initializeCliToolsManager = () => {
  if (!db) {
    logger.error('[Main] Database not initialized for CLI Tools Manager');
    return;
  }
  
  cliToolsManager = new CliToolsManager(db);
  
  // Set up event listeners
  cliToolsManager.on('install-progress', (progress) => {
    // Forward progress to renderer
    if (mainWindow) {
      mainWindow.webContents.send('cli-install-progress', progress);
    }
  });
  
  cliToolsManager.on('update-available', (info) => {
    // Notify renderer about available updates
    if (mainWindow) {
      mainWindow.webContents.send('cli-update-available', info);
    }
  });
  
  // Start automatic update checking
  cliToolsManager.startAutoUpdateCheck();
  
  // Register IPC handlers
  registerCliToolsHandlers();
  
  logger.info('[Main] CLI Tools Manager initialized');
};
*/

// Register CLI Tools IPC handlers (DEPRECATED - duplicate handlers now exist below)
/* DEPRECATED - These handlers conflict with the new singleton implementation below
const registerCliToolsHandlers = () => {
  // Get all tool statuses
  ipcMain.handle('cli-tools-get-all-status', async () => {
    if (!cliToolsManager) return {};
    const statuses = await cliToolsManager.getAllStatuses();
    return Object.fromEntries(statuses);
  });
  
  // Get specific tool status
  ipcMain.handle('cli-tools-check-installed', async (_, toolId: string) => {
    if (!cliToolsManager) return false;
    return await cliToolsManager.checkInstalled(toolId);
  });
  
  // Note: The actual installation handler is 'cli-tool-install' (without 's')
  // This stub handler is not used and can be removed in future cleanup
  
  // Uninstall a tool
  ipcMain.handle('cli-tools-uninstall', async (_, toolId: string) => {
    if (!cliToolsManager) throw new Error('CLI Tools Manager not initialized');
    await cliToolsManager.uninstall(toolId);
    return { success: true };
  });
  
  // Update a tool
  ipcMain.handle('cli-tools-update', async (_, toolId: string) => {
    if (!cliToolsManager) throw new Error('CLI Tools Manager not initialized');
    await cliToolsManager.update(toolId);
    return { success: true };
  });
  
  // Check for updates for a single tool
  ipcMain.handle('cli-tools-check-update', async (_, toolId: string) => {
    if (!cliToolsManager) return false;
    return await cliToolsManager.checkForUpdates(toolId);
  });
  
  // Check for updates for all tools
  ipcMain.handle('cli-tools-check-all-updates', async () => {
    if (!cliToolsManager) return {};
    const updates = await cliToolsManager.checkAllUpdates();
    return Object.fromEntries(updates);
  });
  
  // Configure a tool (e.g., auth)
  ipcMain.handle('cli-tools-configure', async (_, toolId: string) => {
    if (!cliToolsManager) throw new Error('CLI Tools Manager not initialized');
    await cliToolsManager.configureTool(toolId);
    return { success: true };
  });
  
  // Cancel installation
  ipcMain.handle('cli-tools-cancel-install', async (_, toolId: string) => {
    if (!cliToolsManager) return;
    cliToolsManager.cancelInstallation(toolId);
    return { success: true };
  });
  
  // Get installation logs
  ipcMain.handle('cli-tools-get-logs', async (_, toolId: string) => {
    if (!cliToolsManager) return [];
    return cliToolsManager.getInstallationLogs(toolId);
  });
  
  // Update settings
  ipcMain.handle('cli-tools-update-settings', async (_, settings: any) => {
    if (!cliToolsManager) return;
    cliToolsManager.updateSettings(settings);
    return { success: true };
  });
  
  // Get tool configuration
  ipcMain.handle('cli-tools-get-config', async (_, toolId: string) => {
    if (!cliToolsManager) return null;
    return cliToolsManager.getTool(toolId);
  });
  
  // Get all tools
  ipcMain.handle('cli-tools-get-all', async () => {
    if (!cliToolsManager) return {};
    const tools = cliToolsManager.getAllTools();
    return Object.fromEntries(tools);
  });
  
  // Select directory (for custom install path)
  ipcMain.handle('select-directory', async () => {
    const result = await dialog.showOpenDialog({
      properties: ['openDirectory', 'createDirectory']
    });
    return result.canceled ? null : result.filePaths[0];
  });
  
  // Forward progress events to renderer
  if (cliToolsManager) {
    cliToolsManager.on('install-progress', (data: any) => {
      if (mainWindow) {
        mainWindow.webContents.send('cli-tool-progress', data);
      }
    });
    
    cliToolsManager.on('update-available', (data: any) => {
      if (mainWindow) {
        mainWindow.webContents.send('cli-tool-update-available', data);
      }
    });
  }
};
*/

// Simple CLI tool detection function - DEPRECATED, using cliToolsDetector instead
/* const detectCliToolSimple = async (toolId: string): Promise<any> => {
  const { exec } = require('child_process');
  const { promisify } = require('util');
  const execAsync = promisify(exec);
  
  // Map tool IDs to commands
  const toolCommands: Record<string, string> = {
    'claude-code': 'claude',
    'aider': 'aider',
    'cursor': 'cursor',
    'continue': 'continue',
    'codewhisperer': 'aws',
    'cody': 'cody',
    'qwen-code': 'qwen',
    'gemini-cli': 'gemini'
  };
  
  const command = toolCommands[toolId];
  if (!command) return null;
  
  try {
    // Add common paths to PATH for detection
    const pathAdditions = ['/opt/homebrew/bin', '/usr/local/bin', '/usr/bin', '/bin'];
    const enhancedPath = [...new Set([...pathAdditions, ...(process.env.PATH || '').split(':')])].join(':');
    
    // Try to detect the tool with enhanced PATH
    const { stdout } = await execAsync(`which ${command}`, { env: { ...process.env, PATH: enhancedPath } });
    const path = stdout.trim();
    
    // Try to get version
    let version = 'unknown';
    try {
      const { stdout: versionOut } = await execAsync(`${command} --version 2>&1`, { env: { ...process.env, PATH: enhancedPath } });
      // Extract version from output (different tools have different formats)
      const versionMatch = versionOut.match(/\d+\.\d+\.\d+/) || versionOut.match(/\d+\.\d+/);
      if (versionMatch) {
        version = versionMatch[0];
      } else if (versionOut.includes('(Claude Code)')) {
        // Special handling for Claude Code
        const match = versionOut.match(/^([\d.]+)/);
        if (match) version = match[1];
      }
      logger.info(`[CLI Detector] ${toolId} version output: ${versionOut.substring(0, 100)}`);
      logger.info(`[CLI Detector] Detected version: ${version}`);
    } catch (e) {
      // Version command failed, but tool exists
    }
    
    return {
      id: toolId,
      name: toolId.replace(/-/g, ' ').replace(/\b\w/g, l => l.toUpperCase()),
      installed: true,
      version,
      path,
      memoryServiceConnected: false
    };
  } catch (error) {
    // Tool not found
    return {
      id: toolId,
      name: toolId.replace(/-/g, ' ').replace(/\b\w/g, l => l.toUpperCase()),
      installed: false
    };
  }
}; */

// Register simple CLI tool detection handlers (without the complex CliToolsManager)
const registerSimpleCliToolHandlers = () => {
  logger.info('[Main] Registering simple CLI tool detection handlers');
  
  // CLI Tool Detection Handlers
  ipcMain.handle('cli-tool-detect', async (_, toolId: string) => {
    logger.info(`[Main] Detecting CLI tool: ${toolId}`);
    try {
      const status = await cliToolsDetector.detectTool(toolId);
      return status;
    } catch (error) {
      logger.error(`[Main] Error detecting CLI tool ${toolId}:`, error);
      return null;
    }
  });

  ipcMain.handle('cli-tools-detect-all', async () => {
    logger.info('[Main] Detecting all CLI tools...');
    try {
      const results = await cliToolsDetector.detectAllTools();
      return results;
    } catch (error) {
      logger.error('[Main] Error detecting CLI tools:', error);
      return [];
    }
  });
  
  // Install CLI tool
  ipcMain.handle('cli-tool-install', async (_, toolId: string) => {
    logger.info(`[Main] Installing CLI tool: ${toolId}`);
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      // Get tool configuration from registry
      const toolConfig = CLI_TOOLS_REGISTRY[toolId];
      
      if (!toolConfig) {
        logger.error(`[Main] Unknown tool ID for installation: ${toolId}`);
        return { success: false, error: `Unknown tool: ${toolId}` };
      }
      
      if (!toolConfig.installCommand) {
        logger.error(`[Main] No installation command defined for: ${toolId}`);
        return { success: false, error: `Installation not available for ${toolConfig.name}` };
      }
      
      // Enhanced PATH for finding package managers
      const enhancedPath = `/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:${process.env.PATH}`;
      
      logger.info(`[Main] Running installation command: ${toolConfig.installCommand}`);
      
      try {
        // Run the installation command
        const { stdout, stderr } = await execAsync(toolConfig.installCommand, {
          env: { ...process.env, PATH: enhancedPath },
          timeout: 120000 // 2 minutes timeout for installation
        });
        
        logger.info(`[Main] Installation output: ${stdout}`);
        if (stderr && !stderr.includes('WARN') && !stderr.includes('warning')) {
          logger.warn(`[Main] Installation stderr: ${stderr}`);
        }
        
        // Verify installation by checking if command exists
        let version = 'Unknown';
        try {
          if (toolConfig.versionCommand) {
            const versionResult = await execAsync(toolConfig.versionCommand, {
              env: { ...process.env, PATH: enhancedPath },
              timeout: 5000
            });
            
            // Extract version based on tool
            if (toolId === 'gemini-cli') {
              const match = versionResult.stdout.match(/(?:gemini-cli\/|v?)(\d+\.\d+\.\d+)/);
              version = match ? match[1] : 'Unknown';
            } else if (toolId === 'claude-code') {
              const match = versionResult.stdout.match(/claude-code\/(\d+\.\d+\.\d+)/);
              version = match ? match[1] : 'Unknown';
            } else if (toolId === 'qwen-code') {
              const match = versionResult.stdout.match(/(?:qwen\/|v?)(\d+\.\d+\.\d+)/);
              version = match ? match[1] : 'Unknown';
            } else if (toolId === 'openai-codex') {
              const match = versionResult.stdout.match(/codex-cli (\d+\.\d+\.\d+)/);
              version = match ? match[1] : 'Unknown';
            } else if (toolId === 'cline') {
              // Cline outputs just version number like "0.0.1"
              const match = versionResult.stdout.match(/(\d+\.\d+\.\d+)/);
              version = match ? match[1] : 'Unknown';
            } else if (toolId === 'grok') {
              // Grok CLI outputs version number like "0.0.23"
              const match = versionResult.stdout.match(/(\d+\.\d+\.\d+)/);
              version = match ? match[1] : 'Unknown';
            } else {
              // Generic version extraction
              const match = versionResult.stdout.match(/(\d+\.\d+\.\d+)/);
              version = match ? match[1] : 'Unknown';
            }
          }
        } catch (versionError) {
          logger.warn(`[Main] Could not get version after installation:`, versionError);
        }
        
        // CRITICAL FIX: Clear the detector cache for this tool so UI refresh works
        logger.info(`[Main] Clearing detector cache for ${toolId} after successful install`);
        cliToolsDetector.clearCache(toolId);
        
        // SEAMLESS CONFIGURATION: Automatically configure the tool after installation
        logger.info(`[Main] Automatically configuring ${toolId} after installation...`);
        
        // 1. Special configuration for Cline - set up OpenRouter API key
        if (toolId === 'cline') {
          logger.info('[Main] Configuring Cline with OpenRouter API key from Hive');
          
          if (db) {
            const apiKeyRow = await new Promise<any>((resolve) => {
              db!.get('SELECT value FROM configurations WHERE key = ?', ['openrouter_api_key'], (err, row) => {
                resolve(row);
              });
            });
            
            if (apiKeyRow && apiKeyRow.value) {
              const openrouterKey = apiKeyRow.value;
              const clineConfigDir = path.join(os.homedir(), '.cline_cli');
              
              if (!fs.existsSync(clineConfigDir)) {
                fs.mkdirSync(clineConfigDir, { recursive: true });
              }
              
              // Create Cline settings file
              const clineSettingsPath = path.join(clineConfigDir, 'cline_cli_settings.json');
              const clineSettings = {
                globalState: {
                  apiProvider: 'openrouter',
                  openRouterApiKey: openrouterKey,
                  apiModelId: '',  // Let user choose model
                  autoApprovalSettings: {
                    enabled: false,
                    actions: {
                      readFiles: false,
                      editFiles: false,
                      executeSafeCommands: false,
                      useMcp: false
                    },
                    maxRequests: 20
                  }
                },
                settings: {
                  'cline.enableCheckpoints': false
                }
              };
              
              fs.writeFileSync(clineSettingsPath, JSON.stringify(clineSettings, null, 2));
              
              // Create keys file
              const keysPath = path.join(clineConfigDir, 'keys.json');
              fs.writeFileSync(keysPath, JSON.stringify({ openRouterApiKey: openrouterKey }, null, 2));
              
              // Create storage directory
              const storageDir = path.join(clineConfigDir, 'storage');
              if (!fs.existsSync(storageDir)) {
                fs.mkdirSync(storageDir, { recursive: true });
              }
              
              logger.info('[Main] Cline configured with OpenRouter API key');
            }
          }
        }
        
        // 2. Register with Memory Service for all tools (except those that don't need it)
        const toolsWithoutMemoryService = ['cursor', 'continue', 'codewhisperer', 'cody'];
        
        if (!toolsWithoutMemoryService.includes(toolId)) {
          logger.info(`[Main] Registering ${toolId} with Memory Service`);
          
          try {
            // Get memory service configuration
            const memoryServicePort = processManager.getProcessStatus('memory-service')?.port;
            if (!memoryServicePort) {
              logger.error('[Main] Memory service port not allocated');
              return { success: false, error: 'Memory service not running' };
            }
            // Generate authentication token for direct API access
            const token = crypto.randomBytes(32).toString('hex');
            
            // Get dynamic Memory Service port for direct API integration
            const memoryStatus = processManager.getProcessStatus('memory-service');
            const dynamicEndpoint = memoryStatus?.port ? `http://localhost:${memoryStatus.port}` : 'http://localhost:3000';
            
            logger.info(`[Main] Setting up direct API integration for ${toolId} with endpoint: ${dynamicEndpoint}`);
            
            // Save the token to cli-tools-config.json for all tools
            const configPath = path.join(os.homedir(), '.hive', 'cli-tools-config.json');
            let cliConfig: any = {};
            
            if (fs.existsSync(configPath)) {
              try {
                cliConfig = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
              } catch {
                cliConfig = {};
              }
            }
            
            // Store the token for this tool
            cliConfig[toolId] = cliConfig[toolId] || {};
            cliConfig[toolId].memoryService = {
              token: token,
              configuredAt: new Date().toISOString()
            };
            
            fs.writeFileSync(configPath, JSON.stringify(cliConfig, null, 2));
            
            logger.info(`[Main] Successfully registered ${toolId} with Memory Service`);
          } catch (configError) {
            logger.warn(`[Main] Could not configure Memory Service for ${toolId}:`, configError);
            // Non-fatal error - tool is still installed
          }
        }
        
        // Note: Direct API integration configured - no MCP setup needed
        
        // Create symlinks for database and memory guide access
        try {
          // 1. Database symlink
          const actualDbPath = path.join(os.homedir(), '.hive', 'hive-ai.db');
          const symlinkPath = path.join(os.homedir(), '.hive-ai.db');
          
          logger.info(`[Main] Creating database symlink for ${toolId} access`);
          
          // Check if symlink already exists and is valid
          let needsSymlink = true;
          if (fs.existsSync(symlinkPath)) {
            try {
              const stats = fs.lstatSync(symlinkPath);
              if (stats.isSymbolicLink()) {
                const target = fs.readlinkSync(symlinkPath);
                if (target === actualDbPath) {
                  logger.info(`[Main] Database symlink already exists and is correct`);
                  needsSymlink = false;
                } else {
                  // Remove incorrect symlink
                  logger.info(`[Main] Removing incorrect symlink pointing to ${target}`);
                  fs.unlinkSync(symlinkPath);
                }
              } else {
                // Remove file that's not a symlink (e.g., empty file)
                logger.info(`[Main] Removing non-symlink file at ${symlinkPath} (size: ${stats.size} bytes)`);
                fs.unlinkSync(symlinkPath);
              }
            } catch (err) {
              logger.debug(`[Main] Could not check/remove existing file at ${symlinkPath}: ${err}`);
            }
          }
          
          // Create symlink if needed
          if (needsSymlink) {
            fs.symlinkSync(actualDbPath, symlinkPath, 'file');
            logger.info(`[Main] Created ~/.hive-ai.db symlink pointing to ${actualDbPath}`);
          }
          
          // 2. MEMORY.md guide symlink
          const memoryGuidePath = app.isPackaged 
            ? path.join(process.resourcesPath, 'app', 'resources', 'MEMORY.md')
            : path.join(__dirname, '..', 'resources', 'MEMORY.md');
          const memorySymlinkPath = path.join(os.homedir(), '.MEMORY.md');
          
          logger.info(`[Main] Creating MEMORY.md symlink for ${toolId} context guide`);
          
          // Check if MEMORY.md symlink needs creation
          let needsMemorySymlink = true;
          if (fs.existsSync(memorySymlinkPath)) {
            try {
              const stats = fs.lstatSync(memorySymlinkPath);
              if (stats.isSymbolicLink()) {
                const target = fs.readlinkSync(memorySymlinkPath);
                if (target === memoryGuidePath) {
                  logger.info(`[Main] MEMORY.md symlink already exists and is correct`);
                  needsMemorySymlink = false;
                } else {
                  logger.info(`[Main] Removing incorrect MEMORY.md symlink`);
                  fs.unlinkSync(memorySymlinkPath);
                }
              } else {
                logger.info(`[Main] Removing non-symlink MEMORY.md file`);
                fs.unlinkSync(memorySymlinkPath);
              }
            } catch (err) {
              logger.debug(`[Main] Could not check/remove MEMORY.md: ${err}`);
            }
          }
          
          // Create MEMORY.md symlink if needed
          if (needsMemorySymlink) {
            fs.symlinkSync(memoryGuidePath, memorySymlinkPath, 'file');
            logger.info(`[Main] Created ~/.MEMORY.md symlink for AI context guide`);
          }
        } catch (symlinkError) {
          logger.warn(`[Main] Could not create symlinks for ${toolId}:`, symlinkError);
          // Non-fatal - installation still succeeded
        }
        
        logger.info(`[Main] ${toolConfig.name} installed and configured successfully with intelligent memory integration, version: ${version}`);
        return { success: true, version, message: `Installed ${toolConfig.name} version ${version} with Hive intelligence` };
        
      } catch (error: any) {
        logger.error(`[Main] Failed to install ${toolConfig.name}:`, error);
        
        // Check for specific error conditions
        if (error.message?.includes('EACCES') || error.message?.includes('permission')) {
          return { 
            success: false, 
            error: `Permission denied. Try running: sudo ${toolConfig.installCommand}` 
          };
        }
        
        if (error.message?.includes('npm: command not found')) {
          return { 
            success: false, 
            error: 'npm not found. Please install Node.js first.' 
          };
        }
        
        if (error.message?.includes('pip: command not found')) {
          return { 
            success: false, 
            error: 'pip not found. Please install Python first.' 
          };
        }
        
        return { success: false, error: error.message || 'Installation failed' };
      }
      
    } catch (error: any) {
      logger.error(`[Main] Unexpected error installing ${toolId}:`, error);
      return { success: false, error: error.message || 'Unexpected error occurred' };
    }
  });
  
  // Update CLI tool
  ipcMain.handle('cli-tool-update', async (_, toolId: string) => {
    logger.info(`[Main] Updating CLI tool: ${toolId}`);
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      // Map tool IDs to their NPM packages
      const npmPackages: Record<string, string> = {
        'claude-code': '@anthropic-ai/claude-code',
        'gemini-cli': '@google/gemini-cli',
        'qwen-code': '@qwen-code/qwen-code',
        'openai-codex': '@openai/codex',
        'cline': '@yaegaki/cline-cli',
        'grok': '@vibe-kit/grok-cli'
      };
      
      const packageName = npmPackages[toolId];
      if (!packageName) {
        logger.error(`[Main] Unknown tool ID for update: ${toolId}`);
        return { success: false, error: `Unknown tool: ${toolId}` };
      }
      
      // For Python-based tools like aider, use pip
      if (toolId === 'aider') {
        logger.info(`[Main] Updating ${toolId} via pip...`);
        const command = 'pip install --upgrade aider-chat';
        
        try {
          const { stdout, stderr } = await execAsync(command, {
            env: { ...process.env, PATH: `/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:${process.env.PATH}` }
          });
          
          logger.info(`[Main] Pip update output: ${stdout}`);
          if (stderr && !stderr.includes('WARNING')) {
            logger.warn(`[Main] Pip update stderr: ${stderr}`);
          }
          
          // Get updated version
          const versionResult = await execAsync('aider --version', {
            env: { ...process.env, PATH: `/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:${process.env.PATH}` }
          });
          
          const version = versionResult.stdout.trim().match(/\d+\.\d+\.\d+/)?.[0] || 'Unknown';
          
          logger.info(`[Main] ${toolId} updated successfully to version ${version}`);
          return { success: true, version, message: `Updated to version ${version}` };
        } catch (error: any) {
          logger.error(`[Main] Failed to update ${toolId}:`, error);
          return { success: false, error: error.message || 'Update failed' };
        }
      }
      
      // For NPM-based tools
      logger.info(`[Main] Updating ${toolId} via npm...`);
      
      // Robust multi-strategy npm update
      const enhancedEnv = { ...process.env, PATH: `/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:${process.env.PATH}` };
      
      // Strategy 1: Standard npm update
      let updateSucceeded = false;
      let strategyUsed = '';
      
      try {
        logger.info(`[Main] Strategy 1: Standard npm update for ${toolId}`);
        const updateCommand = `npm update -g ${packageName}`;
        logger.info(`[Main] Running: ${updateCommand}`);
        
        const { stdout, stderr } = await execAsync(updateCommand, { env: enhancedEnv });
        logger.info(`[Main] Strategy 1 SUCCESS: ${stdout}`);
        if (stderr && !stderr.includes('npm WARN')) {
          logger.warn(`[Main] Non-critical stderr: ${stderr}`);
        }
        updateSucceeded = true;
        strategyUsed = 'standard update';
        
      } catch (error: any) {
        logger.warn(`[Main] Strategy 1 failed:`, error.message);
        
        if (error.message.includes('ENOTEMPTY') || error.message.includes('rename') || error.message.includes('directory not empty')) {
          // Strategy 2: Clear cache + force update
          try {
            logger.info(`[Main] Strategy 2: Clear cache + force update for ${toolId}`);
            await execAsync('npm cache clean --force', { env: enhancedEnv });
            
            const forceCommand = `npm update -g ${packageName} --force`;
            const { stdout } = await execAsync(forceCommand, { env: enhancedEnv });
            logger.info(`[Main] Strategy 2 SUCCESS: ${stdout}`);
            updateSucceeded = true;
            strategyUsed = 'cache clear + force';
            
          } catch (forceError: any) {
            logger.warn(`[Main] Strategy 2 failed:`, forceError.message);
            
            // Strategy 3: Nuclear option - uninstall + reinstall
            try {
              logger.info(`[Main] Strategy 3: Nuclear uninstall + reinstall for ${toolId}`);
              
              // Uninstall
              try {
                await execAsync(`npm uninstall -g ${packageName}`, { env: enhancedEnv });
                logger.info(`[Main] Uninstalled ${toolId}`);
              } catch (uninstallError) {
                logger.warn(`[Main] Uninstall warning (continuing):`, uninstallError);
              }
              
              // Wait for cleanup
              await new Promise(resolve => setTimeout(resolve, 2000));
              
              // Reinstall
              const { stdout } = await execAsync(`npm install -g ${packageName}`, { env: enhancedEnv });
              logger.info(`[Main] Strategy 3 SUCCESS: ${stdout}`);
              updateSucceeded = true;
              strategyUsed = 'uninstall + reinstall';
              
            } catch (reinstallError: any) {
              logger.warn(`[Main] Strategy 3 failed, trying Strategy 4: Manual cleanup for ${toolId}:`, reinstallError.message);
              
              // Strategy 4: Manual directory cleanup + reinstall
              if (reinstallError.message.includes('ENOTEMPTY')) {
                try {
                  logger.info(`[Main] Strategy 4: Manual cleanup for ${toolId}`);
                  
                  // Comprehensive manual cleanup based on Gemini CLI GitHub issues
                  logger.info(`[Main] Performing comprehensive cleanup for ${toolId}`);
                  
                  const fs = require('fs').promises;
                  const cleanupPaths = [
                    // NPM package directory
                    '/opt/homebrew/lib/node_modules/@google/gemini-cli',
                    // NPM bin files  
                    '/opt/homebrew/bin/gemini',
                    // Alternative locations
                    '/usr/local/lib/node_modules/@google/gemini-cli',
                    '/usr/local/bin/gemini',
                    // User npm directories
                    path.join(os.homedir(), '.npm', '_npx'),
                    // Any temp npm directories with gemini in name
                  ];
                  
                  for (const cleanupPath of cleanupPaths) {
                    try {
                      await fs.rm(cleanupPath, { recursive: true, force: true });
                      logger.info(`[Main] Removed: ${cleanupPath}`);
                    } catch (removeError) {
                      // Expected to fail for non-existent paths
                      logger.debug(`[Main] Path doesn't exist: ${cleanupPath}`);
                    }
                  }
                  
                  // Also try to find and remove any temp directories with gemini-cli pattern
                  try {
                    const globalDir = '/opt/homebrew/lib/node_modules/@google';
                    const files = await fs.readdir(globalDir);
                    for (const file of files) {
                      if (file.includes('gemini-cli') || file.includes('.gemini-cli-')) {
                        const tempPath = path.join(globalDir, file);
                        await fs.rm(tempPath, { recursive: true, force: true });
                        logger.info(`[Main] Removed temp directory: ${tempPath}`);
                      }
                    }
                  } catch (tempCleanupError) {
                    logger.debug(`[Main] Temp cleanup had issues:`, tempCleanupError);
                  }
                  
                  // Wait longer for filesystem
                  await new Promise(resolve => setTimeout(resolve, 3000));
                  
                  // Try reinstall again
                  const { stdout } = await execAsync(`npm install -g ${packageName}`, { env: enhancedEnv });
                  logger.info(`[Main] Strategy 4 SUCCESS: ${stdout}`);
                  updateSucceeded = true;
                  strategyUsed = 'manual cleanup + reinstall';
                  
                } catch (manualError: any) {
                  logger.error(`[Main] All 4 strategies failed for ${toolId}:`, manualError.message);
                  
                  // Provide helpful manual instructions
                  const manualInstructions = `
Manual update required for ${toolId}:
1. Run: sudo rm -rf /opt/homebrew/lib/node_modules/@google/gemini-cli
2. Run: npm cache clean --force  
3. Run: npm install -g ${packageName}

Or try: npm install -g ${packageName} --force --no-cache
                  `.trim();
                  
                  throw new Error(`All automated strategies failed. ${manualInstructions}`);
                }
              } else {
                throw reinstallError;
              }
            }
          }
        } else {
          throw error;
        }
      }
      
      // Get the updated version after successful update
      let version = 'Unknown';
      if (updateSucceeded) {
        try {
          // For Claude Code, use claude --version
          if (toolId === 'claude-code') {
            const versionResult = await execAsync('claude --version', { env: enhancedEnv });
            const match = versionResult.stdout.match(/claude-code\/(\d+\.\d+\.\d+)/);
            version = match ? match[1] : 'Unknown';
          } else if (toolId === 'gemini-cli') {
            const versionResult = await execAsync('gemini --version', { env: enhancedEnv });
            const match = versionResult.stdout.match(/(?:gemini-cli\/|v?)(\d+\.\d+\.\d+)/);
            version = match ? match[1] : 'Unknown';
          } else if (toolId === 'qwen-code') {
            const versionResult = await execAsync('qwen --version', { env: enhancedEnv });
            const match = versionResult.stdout.match(/(?:qwen\/|v?)(\d+\.\d+\.\d+)/);
            version = match ? match[1] : 'Unknown';
          } else if (toolId === 'openai-codex') {
            const versionResult = await execAsync('codex --version', { env: enhancedEnv });
            const match = versionResult.stdout.match(/codex-cli (\d+\.\d+\.\d+)/);
            version = match ? match[1] : 'Unknown';
          } else if (toolId === 'cline') {
            const versionResult = await execAsync('cline-cli --version', { env: enhancedEnv });
            const match = versionResult.stdout.match(/(\d+\.\d+\.\d+)/);
            version = match ? match[1] : 'Unknown';
          } else if (toolId === 'grok') {
            const versionResult = await execAsync('grok --version', { env: enhancedEnv });
            const match = versionResult.stdout.match(/(\d+\.\d+\.\d+)/);
            version = match ? match[1] : 'Unknown';
          }
        } catch (versionError) {
          logger.warn(`[Main] Could not get version for ${toolId}:`, versionError);
        }
        
        // Clear detector cache for UI refresh
        logger.info(`[Main] Clearing detector cache for ${toolId} after successful update`);
        cliToolsDetector.clearCache(toolId);
        
        logger.info(`[Main] ${toolId} updated successfully using ${strategyUsed} to version ${version}`);
        return { success: true, version, message: `Updated to version ${version} (${strategyUsed})` };
      } else {
        throw new Error('Update failed - no strategy succeeded');
      }
      
    } catch (error: any) {
      logger.error(`[Main] Failed to update ${toolId}:`, error);
      
      // Check if it's a permission error
      if (error.message?.includes('EACCES') || error.message?.includes('permission')) {
        return { 
          success: false, 
          error: 'Permission denied. Try running the app with elevated permissions or update manually.' 
        };
      }
      
      // Check if npm is not found
      if (error.message?.includes('npm: command not found')) {
        return { 
          success: false, 
          error: 'npm not found. Please ensure Node.js and npm are installed.' 
        };
      }
      
      return { success: false, error: error.message || 'Update failed' };
    }
  });
  
  // Uninstall CLI tool
  ipcMain.handle('cli-tool-uninstall', async (_, toolId: string) => {
    logger.info(`[Main] Uninstalling CLI tool: ${toolId}`);
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      // Get tool configuration from registry
      const toolConfig = CLI_TOOLS_REGISTRY[toolId];
      
      if (!toolConfig) {
        logger.error(`[Main] Unknown tool ID for uninstall: ${toolId}`);
        return { success: false, error: `Unknown tool: ${toolId}` };
      }
      
      // Map tool IDs to npm package names
      const npmPackages: Record<string, string> = {
        'claude-code': '@anthropic-ai/claude-code',
        'gemini-cli': '@google/gemini-cli',
        'qwen-code': '@qwen-code/qwen-code',
        'openai-codex': '@openai/codex',
        'cline': '@yaegaki/cline-cli',
        'grok': '@vibe-kit/grok-cli'
      };
      
      const packageName = npmPackages[toolId];
      
      if (!packageName) {
        logger.error(`[Main] No package mapping for tool: ${toolId}`);
        return { success: false, error: `Cannot uninstall ${toolConfig.name}: package mapping not found` };
      }
      
      // Enhanced PATH for finding npm
      const enhancedPath = `/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:${process.env.PATH}`;
      
      logger.info(`[Main] Running uninstall command: npm uninstall -g ${packageName}`);
      
      try {
        // Run the uninstall command
        const { stdout, stderr } = await execAsync(`npm uninstall -g ${packageName}`, {
          env: { ...process.env, PATH: enhancedPath },
          timeout: 60000 // 1 minute timeout for uninstall
        });
        
        logger.info(`[Main] Uninstall output: ${stdout}`);
        if (stderr && !stderr.includes('WARN') && !stderr.includes('warning')) {
          logger.warn(`[Main] Uninstall stderr: ${stderr}`);
        }
        
        // Verify uninstallation by checking if command still exists
        try {
          await execAsync(`which ${toolConfig.command}`, {
            env: { ...process.env, PATH: enhancedPath },
            timeout: 5000
          });
          
          // If we get here, the command still exists - uninstall may have failed
          logger.warn(`[Main] Command ${toolConfig.command} still exists after uninstall`);
          
          // Try to determine if it's a different installation
          const { stdout: pathOutput } = await execAsync(`which ${toolConfig.command}`, {
            env: { ...process.env, PATH: enhancedPath }
          });
          
          if (pathOutput.includes('/usr/local/bin') || pathOutput.includes('/opt/homebrew/bin')) {
            // It's still in a global location, uninstall might have failed
            return { 
              success: false, 
              error: `Tool appears to still be installed at ${pathOutput.trim()}. You may need to uninstall manually.` 
            };
          }
        } catch {
          // Command not found - uninstall was successful
          logger.info(`[Main] Command ${toolConfig.command} no longer exists - uninstall successful`);
        }
        
        // CRITICAL FIX: Clear the detector cache for this tool so UI refresh works
        logger.info(`[Main] Clearing detector cache for ${toolId} after successful uninstall`);
        cliToolsDetector.clearCache(toolId);
        
        // Also clean up any configuration files if they exist
        if (toolId === 'cline') {
          // Clean up Cline configuration
          const clineConfigDir = path.join(os.homedir(), '.cline_cli');
          if (fs.existsSync(clineConfigDir)) {
            logger.info(`[Main] Removing Cline configuration directory: ${clineConfigDir}`);
            try {
              fs.rmSync(clineConfigDir, { recursive: true, force: true });
            } catch (e) {
              logger.warn(`[Main] Could not remove Cline config directory:`, e);
            }
          }
        } else if (toolId === 'grok') {
          // Optionally clean up Grok configuration (but keep API key for reinstall)
          logger.info(`[Main] Keeping Grok configuration at ~/.grok for potential reinstall`);
        }
        
        logger.info(`[Main] ${toolConfig.name} uninstalled successfully`);
        return { success: true, message: `${toolConfig.name} has been uninstalled` };
        
      } catch (error: any) {
        logger.error(`[Main] Failed to uninstall ${toolConfig.name}:`, error);
        
        // Check for specific error conditions
        if (error.message?.includes('EACCES') || error.message?.includes('permission')) {
          return { 
            success: false, 
            error: 'Permission denied. Try running the app with elevated permissions or uninstall manually with: npm uninstall -g ' + packageName 
          };
        }
        
        // Check if npm is not found
        if (error.message?.includes('npm: command not found')) {
          return { 
            success: false, 
            error: 'npm not found. Please ensure Node.js and npm are installed.' 
          };
        }
        
        // Check if package is not installed
        if (error.message?.includes('not found') || error.message?.includes('missing')) {
          // This might actually be a success case - tool is already not installed
          logger.info(`[Main] Tool may already be uninstalled: ${error.message}`);
          cliToolsDetector.clearCache(toolId);
          return { success: true, message: `${toolConfig.name} was not installed or has been removed` };
        }
        
        return { success: false, error: error.message || 'Uninstall failed' };
      }
      
    } catch (error: any) {
      logger.error(`[Main] Unexpected error uninstalling ${toolId}:`, error);
      return { success: false, error: error.message || 'Unexpected error occurred' };
    }
  });
  
  // Configure CLI tool
  ipcMain.handle('cli-tool-configure', async (_, toolId: string) => {
    logger.info(`[Main] Configuring CLI tool: ${toolId}`);
    
    try {
      // Special handling for Cline - automatically configure with OpenRouter API key
      if (toolId === 'cline') {
        logger.info('[Main] Special configuration for Cline - using OpenRouter API key from Hive');
        
        // Get OpenRouter API key from Hive's database
        if (!db) {
          logger.error('[Main] Database not initialized');
          return {
            success: false,
            error: 'Database not initialized. Please restart the application.'
          };
        }
        
        const apiKeyRow = await new Promise<any>((resolve, reject) => {
          db!.get('SELECT value FROM configurations WHERE key = ?', ['openrouter_api_key'], (err, row) => {
            if (err) reject(err);
            else resolve(row);
          });
        });
        
        if (!apiKeyRow || !apiKeyRow.value) {
          logger.error('[Main] No OpenRouter API key found in Hive configuration');
          return {
            success: false,
            error: 'OpenRouter API key not configured in Hive. Please configure it in Settings first.'
          };
        }
        
        const openrouterKey = apiKeyRow.value;
        logger.info('[Main] Found OpenRouter API key in Hive configuration');
        
        // Create Cline configuration directory if it doesn't exist
        const clineConfigDir = path.join(os.homedir(), '.cline_cli');
        if (!fs.existsSync(clineConfigDir)) {
          fs.mkdirSync(clineConfigDir, { recursive: true });
        }
        
        // Create Cline settings file with OpenRouter configuration
        const clineSettingsPath = path.join(clineConfigDir, 'cline_cli_settings.json');
        
        // Read existing settings if they exist to preserve user preferences
        let existingSettings: any = {};
        if (fs.existsSync(clineSettingsPath)) {
          try {
            existingSettings = JSON.parse(fs.readFileSync(clineSettingsPath, 'utf-8'));
          } catch (e) {
            logger.warn('[Main] Could not parse existing Cline settings, creating new');
          }
        }
        
        const clineSettings = {
          globalState: {
            ...existingSettings.globalState,
            apiProvider: 'openrouter',
            apiModelId: '',  // Let user choose model in Cline
            openRouterApiKey: openrouterKey,  // Add the actual API key here
            awsRegion: '',
            awsUseCrossRegionInference: '',
            awsBedrockUsePromptCache: '',
            awsBedrockEndpoint: '',
            awsProfile: '',
            awsUseProfile: '',
            vertexProjectId: '',
            vertexRegion: '',
            openAiBaseUrl: '',
            openAiModelId: '',
            openAiModelInfo: '',
            ollamaModelId: '',
            ollamaBaseUrl: '',
            ollamaApiOptionsCtxNum: '',
            lmStudioModelId: '',
            lmStudioBaseUrl: '',
            anthropicBaseUrl: '',
            azureApiVersion: '',
            openRouterModelId: '',  // Don't hardcode model - OpenRouter has 400+ models
            openRouterModelInfo: '',
            openRouterProviderSorting: '',
            liteLlmBaseUrl: '',
            liteLlmModelId: '',
            qwenApiLine: '',
            requestyModelId: '',
            requestyModelInfo: '',
            togetherModelId: '',
            asksageApiUrl: '',
            thinkingBudgetTokens: '',
            reasoningEffort: '',
            favoritedModelIds: '',
            autoApprovalSettings: {
              enabled: false,
              actions: {
                readFiles: false,
                editFiles: false,
                executeSafeCommands: false,
                useMcp: false
              },
              maxRequests: 20
            }
          },
          settings: {
            'cline.enableCheckpoints': false
          }
        };
        
        // Write the configuration file
        fs.writeFileSync(clineSettingsPath, JSON.stringify(clineSettings, null, 2));
        
        // Create a keys file for Cline with the OpenRouter API key
        // Cline reads API keys from a separate keys file
        const keysPath = path.join(clineConfigDir, 'keys.json');
        const keysContent = {
          openRouterApiKey: openrouterKey
        };
        fs.writeFileSync(keysPath, JSON.stringify(keysContent, null, 2));
        
        // Also create storage directory if it doesn't exist
        const storageDir = path.join(clineConfigDir, 'storage');
        if (!fs.existsSync(storageDir)) {
          fs.mkdirSync(storageDir, { recursive: true });
        }
        
        logger.info('[Main] Successfully configured Cline with OpenRouter API key from Hive');
        
        // Continue with Memory Service configuration for all tools
      }
      
      // 1. Get Memory Service port from ProcessManager (fully dynamic)
      const memoryServiceInfo = processManager.getProcessStatus('memory-service');
      const memoryServicePort = memoryServiceInfo?.port;
      if (!memoryServicePort) {
        throw new Error('Memory Service not running - cannot configure MCP');
      }
      const memoryServiceEndpoint = `http://localhost:${memoryServicePort}`;
      
      // 2. Register with Memory Service to get a token
      const http = require('http');
      const crypto = require('crypto');
      
      const registerPromise = new Promise<{ token: string }>((resolve, reject) => {
        const postData = JSON.stringify({
          toolName: toolId
        });
        
        const options = {
          hostname: 'localhost',
          port: memoryServicePort,
          path: '/api/v1/memory/register',
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Content-Length': Buffer.byteLength(postData)
          }
        };
        
        const req = http.request(options, (res: any) => {
          let data = '';
          res.on('data', (chunk: any) => data += chunk);
          res.on('end', () => {
            try {
              const result = JSON.parse(data);
              if (result.token) {
                resolve(result);
              } else {
                reject(new Error('No token received from Memory Service'));
              }
            } catch (e) {
              reject(e);
            }
          });
        });
        
        req.on('error', reject);
        req.write(postData);
        req.end();
      });
      
      const registrationResult = await registerPromise;
      const token = registrationResult.token;
      
      // 3. Save token to cli-tools-config.json
      const configPath = path.join(os.homedir(), '.hive', 'cli-tools-config.json');
      let config: any = {};
      
      if (fs.existsSync(configPath)) {
        config = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
      }
      
      config[toolId] = {
        ...config[toolId],
        memoryService: {
          token: token,  // Only store authentication - NO ENDPOINTS!
          connectedAt: new Date().toISOString()
        }
      };
      
      fs.writeFileSync(configPath, JSON.stringify(config, null, 2));
      
      // 4. Configure direct API access for the tool
      // Note: Token already saved to cli-tools-config.json above
      // Tools will use direct HTTP API calls instead of MCP wrapper
      logger.info(`[Main] Configured ${toolId} for direct API access with endpoint: ${memoryServiceEndpoint}`);
      
      
      logger.info(`[Main] Successfully configured ${toolId} with Memory Service`);
      return { 
        success: true, 
        message: `${toolId} successfully connected to Memory Service`,
        token: token.substring(0, 8) + '...' // Show partial token for confirmation
      };
      
    } catch (error: any) {
      logger.error(`[Main] Failed to configure ${toolId}:`, error);
      return { 
        success: false, 
        error: `Failed to configure: ${error.message || error}` 
      };
    }
  });
  
  // Check for updates
  ipcMain.handle('cli-tools-check-updates', async () => {
    logger.info('[Main] Checking for CLI tool updates');
    // TODO: Implement update checking logic
    return [];
  });
  
  // Launch CLI tool with folder selection (no symlink creation)
  ipcMain.handle('cli-tool-launch', async (_, toolId: string, projectPath?: string) => {
    logger.info(`[Main] Launching CLI tool: ${toolId}${projectPath ? ` in ${projectPath}` : ''}`);
    
    try {
      // Ask user to select a directory if not provided
      let selectedPath = projectPath;
      if (!selectedPath) {
        const result = await dialog.showOpenDialog({
          title: 'Select Project Directory',
          defaultPath: path.join(os.homedir(), 'Developer'),
          properties: ['openDirectory', 'createDirectory'],
          message: 'Choose a directory to launch the AI CLI tool in'
        });
        
        if (result.canceled || !result.filePaths.length) {
          logger.info(`[Main] User canceled directory selection`);
          return { canceled: true };
        }
        
        selectedPath = result.filePaths[0];
      }
      
      logger.info(`[Main] Launch directory: ${selectedPath}`);
      
      // Get the AI tools database instance with unified database connection
      logger.info(`[Main] Getting AIToolsDatabase instance with unified database...`);
      let aiToolsDb: any;
      try {
        // Pass the existing database connection to AIToolsDatabase
        aiToolsDb = AIToolsDatabase.getInstance(db);
        logger.info(`[Main] AIToolsDatabase instance obtained with unified hive-ai.db`);
      } catch (dbError: any) {
        logger.error(`[Main] Failed to get AIToolsDatabase instance:`, dbError);
        logger.error(`[Main] AIToolsDatabase error message:`, dbError?.message);
        logger.error(`[Main] AIToolsDatabase error stack:`, dbError?.stack);
        // Continue without the database - just don't track launches
        aiToolsDb = null;
      }
      
      // Check if tool has been launched before (for --resume flag)
      let hasBeenLaunched = false;
      if (aiToolsDb) {
        hasBeenLaunched = aiToolsDb.hasBeenLaunchedBefore(toolId, selectedPath);
        logger.info(`[Main] Database check - Tool: ${toolId}, Path: ${selectedPath}, Previously launched: ${hasBeenLaunched}`);
        
        // Get launch info for debugging
        const launchInfo = aiToolsDb.getLaunchInfo(toolId, selectedPath);
        if (launchInfo) {
          logger.info(`[Main] Previous launch info: Count: ${launchInfo.launch_count}, Last: ${launchInfo.last_launched_at}`);
        }
      } else {
        logger.warn(`[Main] AIToolsDatabase not available, skipping launch tracking`);
      }
      
      // Determine the command to run
      let command: string;
      let apiKeyRow: any = null;  // Store API key for Cline
      
      if (toolId === 'claude-code') {
        command = hasBeenLaunched ? 'claude --resume' : 'claude';
      } else if (toolId === 'gemini-cli') {
        // Gemini CLI doesn't support --resume, always use base command
        command = 'gemini';
      } else if (toolId === 'qwen-code') {
        command = 'qwen';
      } else if (toolId === 'openai-codex') {
        command = 'codex';
      } else if (toolId === 'grok') {
        // SMART GROK LAUNCH: Check if API key is configured
        // Grok stores config in ~/.grok/user-settings.json
        const grokConfigPath = path.join(os.homedir(), '.grok', 'user-settings.json');
        let hasGrokApiKey = false;
        
        if (fs.existsSync(grokConfigPath)) {
          try {
            const grokConfig = JSON.parse(fs.readFileSync(grokConfigPath, 'utf-8'));
            hasGrokApiKey = !!(grokConfig.apiKey || process.env.GROK_API_KEY);
          } catch {
            // Config exists but couldn't be parsed
          }
        }
        
        // Check environment variable as fallback
        if (!hasGrokApiKey && process.env.GROK_API_KEY) {
          hasGrokApiKey = true;
        }
        
        if (!hasGrokApiKey) {
          // First-time launch: We'll create a setup wizard in the terminal
          logger.info('[Main] Grok API key not configured, will launch setup wizard');
          // We'll handle this in the terminal creation with a special flag
          command = 'grok:setup';  // Special command to trigger our setup wizard
        } else {
          // Normal launch - API key is configured
          command = 'grok';
        }
      } else if (toolId === 'cline') {
        // Always sync Cline configuration with latest OpenRouter API key from Hive
        apiKeyRow = await new Promise<any>((resolve) => {
          if (!db) {
            resolve(null);
            return;
          }
          db.get('SELECT value FROM configurations WHERE key = ?', ['openrouter_api_key'], (err, row) => {
            resolve(row);
          });
        });
        
        if (apiKeyRow && apiKeyRow.value) {
          // Update Cline configuration with current API key
          const clineConfigDir = path.join(os.homedir(), '.cline_cli');
          const clineSettingsPath = path.join(clineConfigDir, 'cline_cli_settings.json');
          const keysPath = path.join(clineConfigDir, 'keys.json');
          
          // Ensure directories exist
          if (!fs.existsSync(clineConfigDir)) {
            fs.mkdirSync(clineConfigDir, { recursive: true });
          }
          
          // Read existing settings to preserve user preferences
          let existingSettings: any = {};
          if (fs.existsSync(clineSettingsPath)) {
            try {
              existingSettings = JSON.parse(fs.readFileSync(clineSettingsPath, 'utf-8'));
            } catch (e) {
              logger.warn('[Main] Could not parse existing Cline settings');
            }
          }
          
          // Update or create settings file
          const clineSettings = {
            globalState: {
              ...existingSettings.globalState,
              apiProvider: 'openrouter',
              apiModelId: '',  // Let user choose from 400+ models
              openRouterApiKey: apiKeyRow.value,  // Include the actual API key
              openRouterModelId: '',  // Don't hardcode model
              openRouterModelInfo: '',
              autoApprovalSettings: {
                enabled: false,
                actions: {
                  readFiles: false,
                  editFiles: false,
                  executeSafeCommands: false,
                  useMcp: false
                },
                maxRequests: 20
              }
            },
            settings: {
              'cline.enableCheckpoints': false
            }
          };
          
          // Fill in other empty fields
          const fields = ['awsRegion', 'awsUseCrossRegionInference', 'awsBedrockUsePromptCache', 
                          'awsBedrockEndpoint', 'awsProfile', 'awsUseProfile', 'vertexProjectId',
                          'vertexRegion', 'openAiBaseUrl', 'openAiModelId', 'openAiModelInfo',
                          'ollamaModelId', 'ollamaBaseUrl', 'ollamaApiOptionsCtxNum', 'lmStudioModelId',
                          'lmStudioBaseUrl', 'anthropicBaseUrl', 'azureApiVersion', 'openRouterProviderSorting',
                          'liteLlmBaseUrl', 'liteLlmModelId', 'qwenApiLine', 'requestyModelId',
                          'requestyModelInfo', 'togetherModelId', 'asksageApiUrl', 'thinkingBudgetTokens',
                          'reasoningEffort', 'favoritedModelIds'];
          
          fields.forEach(field => {
            if (!(field in clineSettings.globalState)) {
              (clineSettings.globalState as any)[field] = '';
            }
          });
          
          fs.writeFileSync(clineSettingsPath, JSON.stringify(clineSettings, null, 2));
          
          // Update keys file with current API key
          const keysContent = {
            openRouterApiKey: apiKeyRow.value
          };
          fs.writeFileSync(keysPath, JSON.stringify(keysContent, null, 2));
          
          logger.info('[Main] Updated Cline config with current OpenRouter API key from Hive');
        }
        
        // We'll pass the API key through environment variables in the terminal creation
        // Use the correct command from the registry
        const clineConfig = CLI_TOOLS_REGISTRY['cline'];
        command = clineConfig && clineConfig.command ? `${clineConfig.command} task` : 'cline-cli task';
      } else {
        // For other tools, use the command from the registry
        const toolConfig = CLI_TOOLS_REGISTRY[toolId];
        if (toolConfig && toolConfig.command) {
          command = toolConfig.command;
        } else {
          // Fallback to just the toolId if not found in registry
          command = toolId.replace('-cli', '').replace('-code', '');
        }
      }
      
      logger.info(`[Main] Using command: ${command} (previously launched: ${hasBeenLaunched})`);
      
      // Record this launch in the database
      if (aiToolsDb) {
        aiToolsDb.recordLaunch(toolId, selectedPath, {
          context: {
            resumeUsed: hasBeenLaunched,
            launchTime: new Date().toISOString()
          }
        });
      }
      
      // Send IPC to renderer to create a terminal tab with the tool
      if (mainWindow && !mainWindow.isDestroyed()) {
        // FIRST: Update the global folder context to the selected path
        // This ensures Explorer, Source Control, and Status Bar all update
        logger.info(`[Main] Sending menu-open-folder event for: ${selectedPath}`);
        logger.info(`[Main] MainWindow exists: ${!!mainWindow}, isDestroyed: ${mainWindow?.isDestroyed()}`);
        mainWindow.webContents.send('menu-open-folder', selectedPath);
        
        // THEN: After a small delay to ensure folder context is set, launch the terminal
        setTimeout(async () => {
          // Get proper tool name from registry
          const toolConfig = CLI_TOOLS_REGISTRY[toolId];
          const toolName = toolConfig ? toolConfig.name : toolId;
          
          // Prepare environment variables for tools if needed
          // Start with the current process environment
          let env: Record<string, string> = { ...process.env };
          
          // Add npm global bin directories to PATH for CLI tools
          const npmGlobalPaths = [
            '/opt/homebrew/bin',  // Homebrew on Apple Silicon
            '/usr/local/bin',     // Standard location
            '/Users/' + process.env.USER + '/.npm-global/bin',  // User npm global
            process.env.HOME + '/.npm/bin',  // Alternative user npm location
            '/usr/bin',
            '/bin'
          ];
          
          // Combine with existing PATH
          const enhancedPath = [...npmGlobalPaths, ...(process.env.PATH || '').split(':')].filter(Boolean).join(':');
          env.PATH = enhancedPath;
          
          logger.info(`[Main] Enhanced PATH for AI tool: ${enhancedPath}`);
          
          // Cline needs OpenRouter API key (special case - we manage its API key)
          if (toolId === 'cline') {
            // Fetch the OpenRouter API key from database
            try {
              const apiKeyRow = await new Promise<any>((resolve, reject) => {
                if (!db) {
                  reject(new Error('Database not initialized'));
                  return;
                }
                db.get('SELECT value FROM configurations WHERE key = ?', ['openrouter_api_key'], (err, row) => {
                  if (err) reject(err);
                  else resolve(row);
                });
              });
              
              if (apiKeyRow && apiKeyRow.value) {
                // Cline CLI seems to be looking for OPENAI_API_KEY even when configured for OpenRouter
                // This appears to be a bug in Cline CLI, so we'll set both variables
                env.OPENAI_API_KEY = apiKeyRow.value;  // Work around Cline CLI bug
                env.OPEN_ROUTER_API_KEY = apiKeyRow.value;
                env.OPENROUTER_API_KEY = apiKeyRow.value; // Try different variations
                logger.info('[Main] Adding OpenRouter API key to environment for Cline (multiple env vars for compatibility)');
              } else {
                logger.warn('[Main] No OpenRouter API key found for Cline');
              }
            } catch (error) {
              logger.error('[Main] Error fetching OpenRouter API key for Cline:', error);
            }
          }
          
          logger.info(`[Main] Sending launch-ai-tool-terminal event with command: ${command}`);
          logger.info(`[Main] Event data:`, {
            toolId: toolId,
            toolName: toolName,
            command: command,
            cwd: selectedPath,
            hasEnv: !!env
          });
          
          // Check if mainWindow is ready
          if (!mainWindow.webContents.isLoading()) {
            logger.info(`[Main] Window is ready, sending event now`);
            mainWindow.webContents.send('launch-ai-tool-terminal', {
              toolId: toolId,
              toolName: toolName,
              command: command,
              cwd: selectedPath,
              env: env  // Pass environment variables
            });
            logger.info(`[Main] Event sent successfully`);
          } else {
            logger.warn(`[Main] Window is still loading, waiting for ready...`);
            mainWindow.webContents.once('did-finish-load', () => {
              logger.info(`[Main] Window finished loading, sending event now`);
              mainWindow.webContents.send('launch-ai-tool-terminal', {
                toolId: toolId,
                toolName: toolName,
                command: command,
                cwd: selectedPath,
                env: env  // Pass environment variables
              });
              logger.info(`[Main] Event sent successfully after wait`);
            });
          }
        }, 100); // Small delay to ensure folder opens first
      }
      
      logger.info(`[Main] Completed launch sequence for ${toolId} in ${selectedPath}`);
      return { success: true, path: selectedPath, command: command };
    } catch (error: any) {
      logger.error(`[Main] Failed to launch ${toolId}:`, error);
      logger.error(`[Main] Error message:`, error?.message);
      logger.error(`[Main] Error stack:`, error?.stack);
      return { success: false, error: error?.message || String(error) };
    }
  });
  
  // TODO: Implement progress events when installation logic is added
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on('ready', async () => {
  try {
    // Use StartupOrchestrator for clean, visual startup
    const orchestrator = new StartupOrchestrator({
      initDatabase,
      initializeProcessManager,
      registerMemoryServiceHandlers,
      registerGitHandlers,
      registerFileSystemHandlers,
      registerDialogHandlers,
      registerSimpleCliToolHandlers,
      registerConsensusHandlers,  // Add consensus handlers registration
      processManager
    });
    
    // The orchestrator will handle all initialization and show splash screen
    const result = await orchestrator.showSplashAndInitialize(createWindow);
    
    if (!result.success) {
      logger.error('[Main] Startup failed:', result.error);
      dialog.showErrorBox(
        'Startup Failed',
        `Unable to initialize required services.\n\n${result.error?.message || 'Unknown error'}`
      );
      app.quit();
      return;
    }
    
    // Success - app is now running with main window shown
    logger.info('[Main] âœ… Application started successfully');
    
  } catch (error) {
    logger.error('[Main] Unexpected startup error:', error);
    dialog.showErrorBox(
      'Startup Error',
      `An unexpected error occurred during startup.\n\n${error}`
    );
    app.quit();
  }
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', async () => {
  // Clean up all processes before quitting
  await processManager.cleanup();
  
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// Track cleanup state to prevent duplicate cleanup
let isCleaningUp = false;

// Unified cleanup function
async function performCleanup(reason: string) {
  if (isCleaningUp) {
    logger.info(`[Main] Cleanup already in progress (triggered by ${reason})`);
    return;
  }
  
  isCleaningUp = true;
  logger.info(`[Main] Starting cleanup (reason: ${reason})...`);
  
  try {
    // Clean up all terminals first
    cleanupTerminals();
    
    // Stop memory service if running
    await processManager.stopProcess('memory-service');
    
    // Clean up all other processes
    await processManager.cleanup();
    
    logger.info('[Main] Cleanup completed successfully');
  } catch (error) {
    logger.error('[Main] Error during cleanup:', error);
  }
}

// Clean up processes on app quit
app.on('before-quit', async (event) => {
  event.preventDefault();
  await performCleanup('before-quit');
  app.exit(0);
});

// Handle unexpected termination
process.on('SIGINT', async () => {
  await performCleanup('SIGINT');
  process.exit(0);
});

process.on('SIGTERM', async () => {
  await performCleanup('SIGTERM');
  process.exit(0);
});

// Handle uncaught exceptions and unhandled rejections
process.on('uncaughtException', async (error) => {
  logger.error('[Main] Uncaught exception:', error);
  await performCleanup('uncaughtException');
  process.exit(1);
});

process.on('unhandledRejection', async (reason) => {
  logger.error('[Main] Unhandled rejection:', reason);
  await performCleanup('unhandledRejection');
  process.exit(1);
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.

// REMOVED: backend-health handler - no longer needed with DirectConsensusEngine

ipcMain.handle('backend-test', async () => {
  try {
    // DirectConsensusEngine runs in main process - no separate backend needed
    return { 
      status: 'connected',
      engine: 'DirectConsensusEngine',
      message: 'Consensus engine ready (main process)',
      database: db ? 'initialized' : 'not initialized'
    };
  } catch (error) {
    throw error;
  }
});

// Import DirectConsensusEngine at top of file - will add after testing
let consensusEngine: any = null;

// Function to register consensus handlers AFTER database is initialized
const registerConsensusHandlers = () => {
  console.log('ðŸ”¥ Registering consensus IPC handlers with database:', db ? 'initialized' : 'NULL');
  logger.info('ðŸ”¥ðŸ”¥ðŸ”¥ CONSENSUS HANDLERS REGISTRATION STARTED');
  
  // First handler: backend-consensus
  ipcMain.handle('backend-consensus', async (_, query: string) => {
    try {
      console.log('DirectConsensusEngine: backend-consensus called with query:', query);
      logger.error('ðŸ”´ðŸ”´ðŸ”´ backend-consensus CALLED with query:', query);
      
      // Initialize consensus engine if not exists (reuse existing database connection)
      if (!consensusEngine) {
        console.log('ðŸ”¥ Database at handler time:', db ? 'initialized' : 'NULL');
        const { DirectConsensusEngine } = require('./consensus/DirectConsensusEngine');
        consensusEngine = new DirectConsensusEngine(db);
        console.log('DirectConsensusEngine: Initialized new consensus engine');
        
        // DirectConsensusEngine now sends ALL updates directly via IPC
        // No event listeners needed - it uses BrowserWindow.send() directly
    }

    // Use existing memory retrieval logic (already in codebase) 
    const memories: any[] = []; // Keep simple per architecture principles
    
    const request = {
      query,
      context: 'Current conversation context',
      memories,
      requestId: Date.now().toString()
    };

    console.log('DirectConsensusEngine: Starting consensus processing...');
    // Event listeners already set up when engine was created
    
    const result = await consensusEngine.processConsensus(request);
    console.log('DirectConsensusEngine: Consensus completed successfully');
    return result;
  } catch (error) {
    console.error('DirectConsensusEngine: IPC handler error:', error);
    throw error;
  }
  });

  // Second handler: backend-consensus-quick (THE SIMPLE ONE WE WANT TO TEST)
  logger.info('ðŸ”¥ðŸ”¥ðŸ”¥ Registering backend-consensus-quick handler');
  console.log('ðŸ”¥ðŸ”¥ðŸ”¥ HANDLER REGISTRATION: backend-consensus-quick');
  
  ipcMain.handle('backend-consensus-quick', async (_, data: {query: string, profile?: string}) => {
    console.log('ðŸš€ðŸš€ðŸš€ HANDLER INVOKED: backend-consensus-quick');
    console.log('ðŸš€ CONSENSUS CALL - Query:', data.query);
    console.log('ðŸš€ Using profile:', data.profile || 'default');
    logger.info(`ðŸš€ðŸš€ðŸš€ backend-consensus-quick CALLED with query: ${data.query}, profile: ${data.profile}`);
    
    try {
      // USE SIMPLECONSENSUSENGINE for basic API calls
      if (!consensusEngine) {
        console.log('ðŸ”¥ Creating new SimpleConsensusEngine instance');
        consensusEngine = new SimpleConsensusEngine(db);
        console.log('ðŸ”¥ SimpleConsensusEngine created successfully');
      }

      const request: any = {
        query: data.query,
        context: '',
        memories: [],
        requestId: Date.now().toString(),
        profileName: data.profile
      };

      console.log('ðŸ”¥ Calling DirectConsensusEngine.processConsensus...');
      const result = await consensusEngine.processConsensus(request);
      console.log('ðŸ”¥ DirectConsensusEngine returned:', result);
      
      return result;
      
      /* COMMENTED OUT - Using DirectConsensusEngine instead
      // SIMPLE APPROACH - Just make 4 sequential API calls with the profile's models
      
      // Get API key from database
      const apiKey = await new Promise<string>((resolve, reject) => {
        db.get('SELECT value FROM configurations WHERE key = ?', ['openrouter_api_key'], (err: any, row: any) => {
          if (err || !row) {
            reject(new Error('No API key found'));
          } else {
            resolve(row.value);
          }
        });
      });
      
      // Get the profile's models from database - no fallback
      const profileName = data.profile;
      if (!profileName) {
        throw new Error('No profile specified');
      }
      console.log('ðŸŽ¯ Getting profile models for:', profileName);
      
      const profile = await new Promise<any>((resolve, reject) => {
        db.get(`
          SELECT generator_model, refiner_model, validator_model, curator_model, profile_name
          FROM consensus_profiles
          WHERE profile_name = ?
        `, [profileName], (err: any, row: any) => {
          if (err || !row) {
            console.error('Profile not found:', profileName);
            reject(new Error(`Profile "${profileName}" not found in database`));
          } else {
            console.log('âœ… Found profile:', row.profile_name);
            resolve(row);
          }
        });
      });
      
      console.log('Using models:', {
        generator: profile.generator_model,
        refiner: profile.refiner_model,
        validator: profile.validator_model,
        curator: profile.curator_model
      });
      
      // Make 4 sequential API calls for consensus
      let currentResponse = data.query;
      
      // 1. Generator
      console.log('ðŸ“¡ Stage 1: Generator with', profile.generator_model);
      const generatorResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': 'https://hivetechs.io',
          'X-Title': 'Hive Consensus'
        },
        body: JSON.stringify({
          model: profile.generator_model,
          messages: [{ role: 'user', content: `Please provide a comprehensive response to: "${data.query}"` }],
          stream: false,
          temperature: 0.7,
          max_tokens: 1000
        })
      });
      const generatorResult = await generatorResponse.json();
      currentResponse = generatorResult.choices?.[0]?.message?.content || currentResponse;
      
      // 2. Refiner
      console.log('ðŸ“¡ Stage 2: Refiner with', profile.refiner_model);
      const refinerResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': 'https://hivetechs.io',
          'X-Title': 'Hive Consensus'
        },
        body: JSON.stringify({
          model: profile.refiner_model,
          messages: [{ role: 'user', content: `Please refine and improve this response: "${currentResponse}"` }],
          stream: false,
          temperature: 0.7,
          max_tokens: 1000
        })
      });
      const refinerResult = await refinerResponse.json();
      currentResponse = refinerResult.choices?.[0]?.message?.content || currentResponse;
      
      // 3. Validator
      console.log('ðŸ“¡ Stage 3: Validator with', profile.validator_model);
      const validatorResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': 'https://hivetechs.io',
          'X-Title': 'Hive Consensus'
        },
        body: JSON.stringify({
          model: profile.validator_model,
          messages: [{ role: 'user', content: `Please fact-check and validate this response: "${currentResponse}"` }],
          stream: false,
          temperature: 0.7,
          max_tokens: 1000
        })
      });
      const validatorResult = await validatorResponse.json();
      currentResponse = validatorResult.choices?.[0]?.message?.content || currentResponse;
      
      // 4. Curator
      console.log('ðŸ“¡ Stage 4: Curator with', profile.curator_model);
      const curatorResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': 'https://hivetechs.io',
          'X-Title': 'Hive Consensus'
        },
        body: JSON.stringify({
          model: profile.curator_model,
          messages: [{ role: 'user', content: `Please provide a final polished version of this response: "${currentResponse}"` }],
          stream: false,
          temperature: 0.7,
          max_tokens: 1000
        })
      });
      const curatorResult = await curatorResponse.json();
      const finalResponse = curatorResult.choices?.[0]?.message?.content || currentResponse;
      
      console.log('âœ… Consensus complete with 4 stages');
      
      // Calculate total tokens and cost
      const totalTokens = (generatorResult.usage?.total_tokens || 0) +
                         (refinerResult.usage?.total_tokens || 0) +
                         (validatorResult.usage?.total_tokens || 0) +
                         (curatorResult.usage?.total_tokens || 0);
      
      // Return the final curated response
      console.log('ðŸŽ¯ðŸŽ¯ðŸŽ¯ RETURNING CONSENSUS RESPONSE TO RENDERER');
      return {
        response: finalResponse,
        result: finalResponse,
        success: true,
        mode: 'consensus',
        stages_completed: ['generator', 'refiner', 'validator', 'curator'],
        tokens_used: totalTokens,
        cost: 0, // TODO: Calculate cost based on models
        duration_ms: Date.now() - Date.now()
      };
    */
      
    } catch (error: any) {
      console.error('DirectConsensusEngine failed:', error);
      logger.error('ðŸ”´ðŸ”´ðŸ”´ CONSENSUS ENGINE ERROR:', error.message);
      
      // Return error in a format the renderer can display
      return {
        result: `Error: ${error.message}`,
        response: `Error: ${error.message}`,
        error: error.message,
        success: false,
        mode: 'error'
      };
    }
  });

  /* OLD COMPLEX VERSION - COMMENTED OUT FOR SIMPLICITY
  console.log('ðŸš¨ðŸš¨ðŸš¨ CLAUDE DEBUG: IPC HANDLER CALLED: backend-consensus-quick with query:', data.query);
  console.log('ðŸš¨ðŸš¨ðŸš¨ CLAUDE DEBUG: This proves the IPC handler is being executed!');
  logger.error('ðŸ”´ðŸ”´ðŸ”´ backend-consensus-quick CALLED with query:', data.query);
  try {
    // Use same DirectConsensusEngine for quick consensus (reuse existing code)
    if (!consensusEngine) {
      console.log('ðŸ”¥ Creating new DirectConsensusEngine instance');
      const { DirectConsensusEngine } = require('./consensus/DirectConsensusEngine');
      consensusEngine = new DirectConsensusEngine(db);
      console.log('ðŸ”¥ DirectConsensusEngine created successfully');
      
      // Event listeners are already set up in the first handler
      // Removed duplicate listeners to prevent double events
    }

    // Use existing memory retrieval logic (already in codebase)
    const memories: any[] = []; // TODO: Connect to existing memory search
    
    const request = {
      query: data.query,
      context: 'Current conversation context',
      memories,
      requestId: Date.now().toString()
    };

    // Event listeners already set up when engine was created

    const result = await consensusEngine.processConsensus(request);
    return result;
  } catch (error) {
    logger.error('Quick consensus error:', error);
    throw error;
  }
  });
  */ // END OF OLD COMPLEX VERSION

  // TEST: Simple test handler to prove IPC mechanism works
  ipcMain.handle('test-claude-debug', async (_, message: string) => {
    console.log('ðŸŸ¢ TEST HANDLER WORKS:', message);
    return { result: `Test response: ${message}`, success: true };
  });
  
  logger.info('ðŸ”¥ðŸ”¥ðŸ”¥ CONSENSUS HANDLERS REGISTRATION COMPLETED - All handlers registered!');
  console.log('ðŸ”¥ðŸ”¥ðŸ”¥ CONSENSUS HANDLERS REGISTRATION COMPLETED');
};

// WebSocket proxy - main process handles WebSocket connection
const WebSocket = require('ws');
let wsConnection: any = null;
let wsCallbacks: Map<string, Function> = new Map();

ipcMain.handle('websocket-connect', async (event, url: string) => {
  return new Promise((resolve, reject) => {
    try {
      if (wsConnection) {
        wsConnection.close();
      }
      
      // Always use dynamic port for backend WebSocket connections
      const backendInfo = processManager.getProcessStatus('websocket-backend');
      const backendPort = backendInfo?.port;
      
      if (!backendPort) {
        logger.error('[Main] No WebSocket backend port allocated!');
        reject(new Error('WebSocket backend not running or port not allocated'));
        return;
      }
      
      // Replace any legacy hardcoded ports with dynamic port
      if (url.includes(':8765')) {
        url = url.replace(':8765', `:${backendPort}`);
        logger.info(`[Main] Replaced hardcoded port with dynamic port: ${backendPort}`);
      }
      
      wsConnection = new WebSocket(url);
      
      wsConnection.on('open', () => {
        logger.info('WebSocket connected in main process');
        resolve({ connected: true });
      });
      
      wsConnection.on('message', (data: any) => {
        // Forward message to renderer
        event.sender.send('websocket-message', data.toString());
      });
      
      wsConnection.on('error', (error: any) => {
        logger.error('WebSocket error in main:', error);
        event.sender.send('websocket-error', error.message);
        reject(error);
      });
      
      wsConnection.on('close', () => {
        logger.info('WebSocket closed in main process');
        event.sender.send('websocket-closed');
        wsConnection = null;
      });
      
    } catch (error) {
      reject(error);
    }
  });
});

ipcMain.handle('websocket-send', async (_, message: string) => {
  // Check if WebSocket is open
  if (wsConnection && wsConnection.readyState === WebSocket.OPEN) {
    wsConnection.send(message);
    return { sent: true };
  }
  
  // If not connected, try to reconnect once
  logger.info('WebSocket not ready, attempting reconnection...');
  try {
    await new Promise((resolve, reject) => {
      const timeout = setTimeout(() => reject('Connection timeout'), 3000);
      
      if (!wsConnection || wsConnection.readyState === WebSocket.CLOSED) {
        // Get the actual backend port dynamically
        const backendInfo = processManager.getProcessStatus('websocket-backend');
        const backendPort = backendInfo?.port;
        
        if (!backendPort) {
          reject(new Error('WebSocket backend not running or port not allocated'));
          return;
        }
        
        // Reconnect to WebSocket using dynamic port
        wsConnection = new WebSocket(`ws://127.0.0.1:${backendPort}/ws`);
        
        wsConnection.once('open', () => {
          clearTimeout(timeout);
          logger.info('WebSocket reconnected successfully');
          resolve(true);
        });
        
        wsConnection.once('error', (err: any) => {
          clearTimeout(timeout);
          reject(err);
        });
        
        // Re-attach message handler for all windows
        wsConnection.on('message', (data: any) => {
          // Send to all windows
          BrowserWindow.getAllWindows().forEach(window => {
            window.webContents.send('websocket-message', data.toString());
          });
        });
      } else if (wsConnection.readyState === WebSocket.CONNECTING) {
        // Wait for existing connection
        wsConnection.once('open', () => {
          clearTimeout(timeout);
          resolve(true);
        });
      } else {
        reject('Unknown WebSocket state');
      }
    });
    
    // Now send the message
    wsConnection.send(message);
    return { sent: true };
  } catch (error) {
    logger.error('Failed to reconnect WebSocket:', error);
    throw new Error('WebSocket not connected and reconnection failed');
  }
});

ipcMain.handle('websocket-close', async () => {
  if (wsConnection) {
    wsConnection.close();
    wsConnection = null;
  }
  return { closed: true };
});

// Database settings handlers for simple key-value preferences
ipcMain.handle('db-get-setting', async (_, key: string) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    db.get('SELECT value FROM settings WHERE key = ?', [key], (err, row: any) => {
      if (err) {
        reject(err);
      } else {
        resolve(row ? row.value : null);
      }
    });
  });
});

ipcMain.handle('db-set-setting', async (_, key: string, value: string) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    const timestamp = new Date().toISOString();
    db.run(
      'INSERT OR REPLACE INTO settings (key, value, updated_at) VALUES (?, ?, ?)',
      [key, value, timestamp],
      (err) => {
        if (err) {
          reject(err);
        } else {
          resolve({ success: true });
        }
      }
    );
  });
});

// Session persistence handlers
ipcMain.handle('db-save-session', async (_, folderPath: string, tabs: any[], activeTab: string | null) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    const timestamp = new Date().toISOString();
    const tabsJson = JSON.stringify(tabs);
    
    db.run(
      `INSERT OR REPLACE INTO sessions (folder_path, tabs, active_tab, updated_at) 
       VALUES (?, ?, ?, ?)`,
      [folderPath, tabsJson, activeTab, timestamp],
      (err) => {
        if (err) {
          logger.error('[Session] Failed to save session:', err);
          reject(err);
        } else {
          logger.info(`[Session] Saved session for ${folderPath} with ${tabs.length} tabs`);
          resolve({ success: true });
        }
      }
    );
  });
});

ipcMain.handle('db-load-session', async (_, folderPath: string) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    db.get(
      'SELECT tabs, active_tab FROM sessions WHERE folder_path = ?',
      [folderPath],
      (err, row: any) => {
        if (err) {
          logger.error('[Session] Failed to load session:', err);
          reject(err);
        } else if (row) {
          try {
            const tabs = JSON.parse(row.tabs);
            logger.info(`[Session] Loaded session for ${folderPath} with ${tabs.length} tabs`);
            resolve({ tabs, activeTab: row.active_tab });
          } catch (parseErr) {
            logger.error('[Session] Failed to parse session data:', parseErr);
            resolve(null);
          }
        } else {
          logger.info(`[Session] No session found for ${folderPath}`);
          resolve(null);
        }
      }
    );
  });
});

ipcMain.handle('db-clear-session', async (_, folderPath: string) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    db.run(
      'DELETE FROM sessions WHERE folder_path = ?',
      [folderPath],
      (err) => {
        if (err) {
          logger.error('[Session] Failed to clear session:', err);
          reject(err);
        } else {
          logger.info(`[Session] Cleared session for ${folderPath}`);
          resolve({ success: true });
        }
      }
    );
  });
});

// Recent folders handlers
ipcMain.handle('db-add-recent-folder', async (_, folderPath: string, tabCount: number = 0) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    const timestamp = new Date().toISOString();
    
    db.run(
      `INSERT OR REPLACE INTO recent_folders (folder_path, last_opened, tab_count) 
       VALUES (?, ?, ?)`,
      [folderPath, timestamp, tabCount],
      (err) => {
        if (err) {
          logger.error('[Recent] Failed to add recent folder:', err);
          reject(err);
        } else {
          logger.info(`[Recent] Added folder ${folderPath} to recent list`);
          resolve({ success: true });
        }
      }
    );
  });
});

ipcMain.handle('db-get-recent-folders', async () => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    db.all(
      `SELECT folder_path, last_opened, tab_count 
       FROM recent_folders 
       ORDER BY last_opened DESC 
       LIMIT 20`,
      [],
      (err, rows) => {
        if (err) {
          logger.error('[Recent] Failed to get recent folders:', err);
          reject(err);
        } else {
          resolve(rows || []);
        }
      }
    );
  });
});

ipcMain.handle('db-remove-recent-folder', async (_, folderPath: string) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    
    db.run(
      'DELETE FROM recent_folders WHERE folder_path = ?',
      [folderPath],
      (err) => {
        if (err) {
          logger.error('[Recent] Failed to remove recent folder:', err);
          reject(err);
        } else {
          logger.info(`[Recent] Removed folder ${folderPath} from recent list`);
          resolve({ success: true });
        }
      }
    );
  });
});

// Clear all recent folders
ipcMain.handle('db-clear-recent-folders', async () => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }
    db.run('DELETE FROM recent_folders', [], (err) => {
      if (err) {
        logger.error('[Recent] Failed to clear recent folders:', err);
        reject(err);
      } else {
        logger.info('[Recent] Cleared all recent folders');
        resolve({ success: true });
      }
    });
  });
});

// Settings API handlers
ipcMain.handle('settings-load', async () => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    const settings: any = {};
    
    // Load API keys from configurations table (matching Rust implementation)
    db.get('SELECT value FROM configurations WHERE key = ?', ['openrouter_api_key'], (err, row: any) => {
      if (row) settings.openrouterKey = row.value;
      
      db.get('SELECT value FROM configurations WHERE key = ?', ['hive_license_key'], (err2, row2: any) => {
        if (row2) settings.hiveKey = row2.value;
        
        // Load active profile from consensus_settings table (matching Rust implementation)
        db.get('SELECT value FROM consensus_settings WHERE key = ?', ['active_profile_id'], (err3, row3: any) => {
          if (row3) {
            settings.activeProfileId = row3.value;
            // Also get the profile name for better matching
            db.get('SELECT profile_name FROM consensus_profiles WHERE id = ?', [row3.value], (errName, rowName: any) => {
              if (rowName) settings.activeProfileName = rowName.profile_name;
            });
          }
          
          // Load license tier and usage information
          db.get('SELECT value FROM configurations WHERE key = ?', ['hive_tier'], (errTier, rowTier: any) => {
            if (rowTier) settings.hiveTier = rowTier.value;
            
            db.get('SELECT value FROM configurations WHERE key = ?', ['hive_daily_limit'], (errLimit, rowLimit: any) => {
              if (rowLimit) settings.hiveDailyLimit = parseInt(rowLimit.value);
              
              db.get('SELECT value FROM configurations WHERE key = ?', ['hive_remaining'], (errRemaining, rowRemaining: any) => {
                if (rowRemaining) settings.hiveRemaining = parseInt(rowRemaining.value);
                
                // Load other settings
                db.get('SELECT value FROM configurations WHERE key = ?', ['auto_save'], (err4, row4: any) => {
                  if (row4) settings.autoSave = row4.value === 'true';
                  
                  db.get('SELECT value FROM configurations WHERE key = ?', ['show_costs'], (err5, row5: any) => {
                    if (row5) settings.showCosts = row5.value === 'true';
                    
                  db.get('SELECT value FROM configurations WHERE key = ?', ['max_daily_conversations'], (err6, row6: any) => {
                    if (row6) settings.maxDailyConversations = row6.value;
                      // Load Git preference
                      db.get('SELECT value FROM configurations WHERE key = ?', ['git_prefer_opened_folder_root'], (err7, row7: any) => {
                        if (row7) settings.gitPreferOpenedFolderRoot = row7.value === 'true';
                        resolve(settings);
                      });
                  });
                  });
                });
              });
            });
          });
        });
      });
    });
  });
});

ipcMain.handle('settings-test-keys', async (_, { openrouterKey, hiveKey }) => {
  const result: any = { openrouterValid: false, hiveValid: false, licenseInfo: null };
  
  // Test OpenRouter key
  if (openrouterKey && openrouterKey.startsWith('sk-or-')) {
    try {
      const response = await fetch('https://openrouter.ai/api/v1/models', {
        headers: {
          'Authorization': `Bearer ${openrouterKey}`,
          'HTTP-Referer': 'https://hivetechs.io',
          'X-Title': 'hive-ai'
        }
      });
      result.openrouterValid = response.status === 200;
    } catch (error) {
      logger.error('Failed to test OpenRouter key:', error);
    }
  }
  
  // Test Hive key - real D1 authentication
  if (hiveKey) {
    const upperKey = hiveKey.toUpperCase();
    if (upperKey.startsWith('HIVE-')) {
      const parts = upperKey.split('-');
      // Validate format first (HIVE-XXXX-XXXX-XXXX or longer)
      if (parts.length >= 4 && parts.slice(1).every((segment: string) => 
        segment.length === 4 && /^[A-Z0-9]{4}$/.test(segment)
      )) {
        try {
          // Create device fingerprint (matching Rust implementation)
          const crypto = require('crypto');
          const hostname = os.hostname();
          const username = os.userInfo().username;
          const platform = os.platform();
          const arch = os.arch();
          const release = os.release();
          const cpus = os.cpus().length;
          const memory = Math.floor(os.totalmem() / 1024 / 1024); // MB
          
          const deviceData = {
            platform,
            arch,
            release,
            cpus,
            memory
          };
          
          const deviceString = JSON.stringify(deviceData);
          const fingerprint = crypto.createHash('sha256')
            .update(deviceString)
            .digest('hex')
            .substring(0, 32);
          
          // Make request to Cloudflare D1 gateway
          const response = await fetch('https://gateway.hivetechs.io/v1/session/validate', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${upperKey}`,
              'Content-Type': 'application/json',
              'User-Agent': 'hive-electron/2.0.0'
            },
            body: JSON.stringify({
              client_id: 'hive-tools',
              session_token: upperKey,
              fingerprint: fingerprint,
              nonce: String(Date.now())
            })
          });
          
          if (response.ok) {
            const data = await response.json();
            
            // Log the D1 response to understand what fields are available
            logger.info('D1 validation response:', JSON.stringify(data, null, 2));
            
            if (data.valid) {
              // Parse tier information
              const tier = data.tier || data.user?.subscription_tier || 'free';
              const dailyLimit = data.daily_limit || data.limits?.daily || 10;
              const email = data.email || data.user?.email || '';
              const userId = data.user_id || data.user?.id || '';
              
              // Check if D1 returned usage information
              let remaining = undefined;
              let dailyUsed = undefined;
              
              // D1 is the source of truth for usage - only use if provided
              if (data.usage) {
                // D1 returned usage info - this is authoritative
                remaining = data.usage.remaining;
                const limit = data.usage.limit || dailyLimit;
                
                // Calculate used from remaining (D1 tracks this)
                if (remaining !== undefined && limit !== undefined) {
                  // Handle "unlimited" case where remaining might be max value
                  if (remaining === 4294967295 || remaining === 2147483647) {
                    dailyUsed = 0;
                    remaining = 'unlimited';
                  } else {
                    dailyUsed = Math.max(0, limit - remaining);
                  }
                }
              }
              
              // Build license info object
              const licenseInfo: any = {
                valid: true,
                tier: tier.charAt(0).toUpperCase() + tier.slice(1).toLowerCase(),
                dailyLimit: dailyLimit,
                email: email,
                userId: userId,
                features: data.features || ['consensus']
              };
              
              // Only include usage data if D1 provided it
              if (remaining !== undefined) {
                licenseInfo.remaining = remaining;
              }
              if (dailyUsed !== undefined) {
                licenseInfo.dailyUsed = dailyUsed;
              }
              
              result.hiveValid = true;
              result.licenseInfo = licenseInfo;
              
              // Store validated license info in database
              if (db) {
                const timestamp = new Date().toISOString();
                db.run(
                  `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
                   VALUES (?, ?, ?, ?, ?, ?)
                   ON CONFLICT(key) DO UPDATE SET
                   value = excluded.value,
                   updated_at = excluded.updated_at`,
                  ['hive_tier', tier, 0, userId || 'default', timestamp, timestamp]
                );
                
                db.run(
                  `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
                   VALUES (?, ?, ?, ?, ?, ?)
                   ON CONFLICT(key) DO UPDATE SET
                   value = excluded.value,
                   updated_at = excluded.updated_at`,
                  ['hive_daily_limit', String(dailyLimit), 0, userId || 'default', timestamp, timestamp]
                );
                
                // Only store remaining if D1 provided it
                if (remaining !== undefined) {
                  db.run(
                    `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
                     VALUES (?, ?, ?, ?, ?, ?)
                     ON CONFLICT(key) DO UPDATE SET
                     value = excluded.value,
                     updated_at = excluded.updated_at`,
                    ['hive_remaining', String(remaining), 0, userId || 'default', timestamp, timestamp]
                  );
                }
              }
            } else {
              result.hiveValid = false;
              result.licenseInfo = {
                valid: false,
                error: data.error || 'Invalid license key'
              };
            }
          } else {
            // Handle error responses
            const errorText = await response.text();
            logger.error(`License validation failed: ${response.status} - ${errorText}`);
            
            result.hiveValid = false;
            result.licenseInfo = {
              valid: false,
              error: `Validation failed: ${response.status}`
            };
          }
        } catch (error) {
          logger.error('Failed to validate Hive license:', error);
          result.hiveValid = false;
          result.licenseInfo = {
            valid: false,
            error: 'Network error - unable to validate license'
          };
        }
      } else {
        result.hiveValid = false;
        result.licenseInfo = {
          valid: false,
          error: 'Invalid license key format'
        };
      }
    } else {
      result.hiveValid = false;
      result.licenseInfo = {
        valid: false,
        error: 'License key must start with HIVE-'
      };
    }
  }
  
  return result;
});

ipcMain.handle('settings-save-keys', async (_, { openrouterKey, hiveKey }) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    const timestamp = new Date().toISOString();
    
    // Save OpenRouter key
    if (openrouterKey) {
      db.run(
        'INSERT OR REPLACE INTO configurations (key, value, updated_at) VALUES (?, ?, ?)',
        ['openrouter_api_key', openrouterKey, timestamp],
        (err) => {
          if (err) {
            reject(err);
            return;
          }
          
          // Save Hive key
          if (hiveKey) {
            db.run(
              'INSERT OR REPLACE INTO configurations (key, value, updated_at) VALUES (?, ?, ?)',
              ['hive_license_key', hiveKey, timestamp],
              (err2) => {
                if (err2) {
                  reject(err2);
                } else {
                  resolve(true);
                }
              }
            );
          } else {
            resolve(true);
          }
        }
      );
    } else if (hiveKey) {
      db.run(
        'INSERT OR REPLACE INTO configuration (key, value, updated_at) VALUES (?, ?, ?)',
        ['hive_license_key', hiveKey, timestamp],
        (err) => {
          if (err) {
            reject(err);
          } else {
            resolve(true);
          }
        }
      );
    } else {
      resolve(true);
    }
  });
});

ipcMain.handle('settings-save-profile', async (_, profile) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    const timestamp = new Date().toISOString();
    
    // Insert or update the profile (no is_default column in actual database)
    db.run(
      `INSERT OR REPLACE INTO consensus_profiles 
       (id, profile_name, generator_model, refiner_model, validator_model, curator_model, updated_at) 
       VALUES (?, ?, ?, ?, ?, ?, ?)`,
      [profile.id, profile.name, profile.generator, profile.refiner, profile.validator, profile.curator, timestamp],
      (err2) => {
        if (err2) {
          reject(err2);
        } else {
          // Save to consensus_settings table (matching Rust implementation)
          db.run(
            `INSERT INTO consensus_settings (key, value, updated_at) 
             VALUES (?, ?, ?)
             ON CONFLICT(key) DO UPDATE SET
             value = excluded.value,
             updated_at = excluded.updated_at`,
            ['active_profile_id', profile.id, timestamp],
            (err3) => {
              if (err3) {
                reject(err3);
              } else {
                resolve(true);
              }
            }
          );
        }
      }
    );
  });
});

// Get a single profile by name
ipcMain.handle('settings-get-profile', async (_, profileName) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    db.get(
      'SELECT * FROM consensus_profiles WHERE profile_name = ?',
      [profileName],
      (err, row) => {
        if (err) {
          reject(err);
        } else {
          resolve(row);
        }
      }
    );
  });
});

// Update max consensus rounds for a profile
ipcMain.handle('settings-update-profile-max-rounds', async (_, profileName, maxRounds) => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    db.run(
      'UPDATE consensus_profiles SET max_consensus_rounds = ? WHERE profile_name = ?',
      [maxRounds, profileName],
      (err) => {
        if (err) {
          reject(err);
        } else {
          console.log(`âœ… Updated max_consensus_rounds to ${maxRounds} for profile: ${profileName}`);
          resolve(true);
        }
      }
    );
  });
});

ipcMain.handle('settings-save-all', async (_, settings) => {
  return new Promise(async (resolve, reject) => {
    try {
      const timestamp = new Date().toISOString();
      const userId = 'default';
      
      // Save API keys to configurations table (matching Rust implementation)
      if (settings.openrouterKey || settings.hiveKey) {
        if (settings.openrouterKey) {
          db.run(
            `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
             VALUES (?, ?, ?, ?, ?, ?)
             ON CONFLICT(key) DO UPDATE SET
             value = excluded.value,
             updated_at = excluded.updated_at`,
            ['openrouter_api_key', settings.openrouterKey, 0, userId, timestamp, timestamp]
          );
        }
        if (settings.hiveKey) {
          db.run(
            `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
             VALUES (?, ?, ?, ?, ?, ?)
             ON CONFLICT(key) DO UPDATE SET
             value = excluded.value,
             updated_at = excluded.updated_at`,
            ['hive_license_key', settings.hiveKey, 0, userId, timestamp, timestamp]
          );
        }
      }
      
      // Save profile to consensus_settings (matching Rust implementation)
      if (settings.selectedProfile) {
        // Save to consensus_settings table
        db.run(
          `INSERT INTO consensus_settings (key, value, updated_at) 
           VALUES (?, ?, ?)
           ON CONFLICT(key) DO UPDATE SET
           value = excluded.value,
           updated_at = excluded.updated_at`,
          ['active_profile_id', settings.selectedProfile, timestamp],
          (err) => {
            if (err) logger.error('Failed to save active profile:', err);
          }
        );
        
        // Note: No is_default column in actual consensus_profiles table
      }
      
      // Save other settings to configurations table
      if (settings.autoSave !== undefined) {
        db.run(
          `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
           VALUES (?, ?, ?, ?, ?, ?)
           ON CONFLICT(key) DO UPDATE SET
           value = excluded.value,
           updated_at = excluded.updated_at`,
          ['auto_save', settings.autoSave.toString(), 0, userId, timestamp, timestamp]
        );
      }
      if (settings.showCosts !== undefined) {
        db.run(
          `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
           VALUES (?, ?, ?, ?, ?, ?)
           ON CONFLICT(key) DO UPDATE SET
           value = excluded.value,
           updated_at = excluded.updated_at`,
          ['show_costs', settings.showCosts.toString(), 0, userId, timestamp, timestamp]
        );
      }
      if (settings.maxDailyConversations !== undefined) {
        db.run(
          `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
           VALUES (?, ?, ?, ?, ?, ?)
           ON CONFLICT(key) DO UPDATE SET
           value = excluded.value,
           updated_at = excluded.updated_at`,
          ['max_daily_conversations', settings.maxDailyConversations.toString(), 0, userId, timestamp, timestamp]
        );
      }
      if (settings.gitPreferOpenedFolderRoot !== undefined) {
        db.run(
          `INSERT INTO configurations (key, value, encrypted, user_id, created_at, updated_at) 
           VALUES (?, ?, ?, ?, ?, ?)
           ON CONFLICT(key) DO UPDATE SET
           value = excluded.value,
           updated_at = excluded.updated_at`,
          ['git_prefer_opened_folder_root', settings.gitPreferOpenedFolderRoot ? 'true' : 'false', 0, userId, timestamp, timestamp]
        );
      }
      
      resolve(true);
    } catch (error) {
      reject(error);
    }
  });
});

ipcMain.handle('settings-load-profiles', async () => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    db.all(
      'SELECT * FROM consensus_profiles ORDER BY profile_name',
      [],
      (err, rows) => {
        if (err) {
          reject(err);
        } else {
          // Map to expected format
          const profiles = rows.map((row: any) => ({
            id: row.id,
            name: row.profile_name,
            generator: row.generator_model,
            refiner: row.refiner_model,
            validator: row.validator_model,
            curator: row.curator_model
          }));
          resolve(profiles);
        }
      }
    );
  });
});

ipcMain.handle('settings-load-models', async () => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    // First check if openrouter_models table exists
    db.get(
      "SELECT name FROM sqlite_master WHERE type='table' AND name='openrouter_models'",
      [],
      (err, row) => {
        if (err || !row) {
          // Table doesn't exist, return empty array
          resolve([]);
          return;
        }

        // Load all active models from database
        db.all(
          `SELECT internal_id, openrouter_id, name, provider_name, description,
                  context_window, pricing_input, pricing_output, is_active
           FROM openrouter_models
           WHERE is_active = 1
           ORDER BY provider_name, name`,
          [],
          (err2, rows) => {
            if (err2) {
              reject(err2);
            } else {
              // Map to format expected by frontend
              const models = rows.map((row: any) => ({
                value: row.openrouter_id,
                label: row.name,
                provider: row.provider_name,
                description: row.description,
                contextWindow: row.context_window,
                pricingInput: row.pricing_input,
                pricingOutput: row.pricing_output,
                internalId: row.internal_id
              }));
              resolve(models);
            }
          }
        );
      }
    );
  });
});

ipcMain.handle('settings-reset', async () => {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('Database not initialized');
      return;
    }

    // Clear configuration except essential items
    db.run('DELETE FROM configuration WHERE key NOT IN ("openrouter_api_key", "hive_license_key")', (err) => {
      if (err) {
        reject(err);
      } else {
        // Reset profile to default
        // Set balanced-performer as the active profile in consensus_settings
        db.run(
          `INSERT INTO consensus_settings (key, value, updated_at) 
           VALUES (?, ?, ?)
           ON CONFLICT(key) DO UPDATE SET
           value = excluded.value,
           updated_at = excluded.updated_at`,
          ['active_profile_id', 'balanced-performer', new Date().toISOString()],
          () => {
            resolve(true);
          }
        );
      }
    });
  });
});

// Analytics data handler - fetch real consensus metrics from database
// Save conversation to database
ipcMain.handle('save-conversation', async (_, data: {
  conversationId: string;
  question: string;
  answer: string;
  totalCost: number;
  totalTokens: number;
  inputTokens: number;
  outputTokens: number;
  model?: string;
  duration?: number;
}) => {
  return new Promise((resolve) => {
    if (!db) {
      logger.error('Database not initialized for saving conversation');
      resolve(false);
      return;
    }
    
    logger.info('ðŸ“ Saving conversation to database:', {
      id: data.conversationId,
      cost: data.totalCost,
      tokens: data.totalTokens
    });
    
    const userId = '3034c561-e193-4968-a575-f1b165d31a5b'; // sales@hivetechs.io
    const timestamp = new Date().toISOString();
    
    // Upsert into conversations table (update totals if row exists)
    db.run(`
      INSERT INTO conversations (
        id, user_id, title, total_cost, total_tokens_input, total_tokens_output, 
        created_at, updated_at
      ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
      ON CONFLICT(id) DO UPDATE SET
        title = excluded.title,
        total_cost = excluded.total_cost,
        total_tokens_input = excluded.total_tokens_input,
        total_tokens_output = excluded.total_tokens_output,
        updated_at = excluded.updated_at
    `, [
      data.conversationId,
      userId,
      data.question?.substring(0, 100) || 'Consensus Query',
      data.totalCost,
      data.inputTokens,
      data.outputTokens,
      timestamp,
      timestamp
    ], (err1) => {
      if (err1) {
        logger.error('Error saving conversation:', err1);
        resolve(false);
        return;
      }
      
      // Insert into knowledge_conversations
      db.run(`
        INSERT INTO knowledge_conversations (
          conversation_id, question, final_answer, source_of_truth, created_at
        ) VALUES (?, ?, ?, ?, ?)
        ON CONFLICT(conversation_id) DO UPDATE SET
          question = excluded.question,
          final_answer = excluded.final_answer,
          source_of_truth = excluded.source_of_truth
      `, [
        data.conversationId,
        data.question,
        data.answer,
        data.answer, // Using answer as source of truth for now
        timestamp
      ], (err2) => {
        if (err2) logger.error('Error saving to knowledge_conversations:', err2);
      });
      
      // Insert into conversation_usage for tracking
      db.run(`
        INSERT INTO conversation_usage (
          user_id, conversation_id, timestamp
        ) VALUES (?, ?, ?)
      `, [userId, data.conversationId, timestamp], (err3) => {
        if (err3) logger.error('Error saving to conversation_usage:', err3);
      });
      
      // Track model usage for each stage using the active profile
      // Get the active profile to know which models were used
      db.get(`
        SELECT cp.generator_model, cp.refiner_model, cp.validator_model, cp.curator_model 
        FROM consensus_settings cs
        JOIN consensus_profiles cp ON cs.value = cp.id
        WHERE cs.key = 'active_profile_id'
      `, [], (errProfile, profile: any) => {
        if (!errProfile && profile) {
          // Insert stage outputs for tracking
          const stages = [
            { name: 'Generator', model: profile.generator_model },
            { name: 'Refiner', model: profile.refiner_model },
            { name: 'Validator', model: profile.validator_model },
            { name: 'Curator', model: profile.curator_model }
          ];
          
          stages.forEach(stage => {
            // Estimate tokens and cost per stage (divide by 4)
            const stageTokens = Math.floor((data.totalTokens || 0) / 4);
            const stageCost = (data.totalCost || 0) / 4;
            
            db.run(`
              INSERT INTO stage_outputs (
                conversation_id, stage_name, model, tokens_used, cost, created_at
              ) VALUES (?, ?, ?, ?, ?, ?)
            `, [data.conversationId, stage.name, stage.model, stageTokens, stageCost, timestamp]);
          });
        }
      });
      
      // Insert into performance_metrics if duration provided
      if (data.duration) {
      db.run(`
        INSERT INTO performance_metrics (
          conversation_id, timestamp, total_duration, total_cost, created_at
        ) VALUES (?, ?, ?, ?, ?)
        ON CONFLICT(conversation_id) DO UPDATE SET
          timestamp = excluded.timestamp,
          total_duration = excluded.total_duration,
          total_cost = excluded.total_cost,
          created_at = excluded.created_at
      `, [data.conversationId, timestamp, data.duration, data.totalCost || 0, timestamp], (err4) => {
        if (err4) logger.error('Error saving performance metrics:', err4);
      });
      }
      
      // Insert into cost_analytics
      db.run(`
        INSERT INTO cost_analytics (
          conversation_id, total_cost, cost_per_token, model_costs, optimization_potential, created_at
        ) VALUES (?, ?, ?, ?, ?, ?)
      `, [
        data.conversationId,
        data.totalCost,
        data.totalCost / (data.totalTokens || 1),
        JSON.stringify({ [data.model || 'consensus']: data.totalCost }),
        0,
        timestamp
      ], (err5) => {
        if (err5) logger.error('Error saving cost analytics:', err5);
      });
      
      logger.info(`âœ… Saved conversation ${data.conversationId} to database`);
      resolve(true);
    });
  });
});

// Get user's daily usage count
ipcMain.handle('get-usage-count', async () => {
  return new Promise((resolve) => {
    if (!db) {
      resolve({ used: 0, limit: 999999, remaining: 999999 });
      return;
    }
    
    const userId = '3034c561-e193-4968-a575-f1b165d31a5b';
    const todayStart = new Date();
    todayStart.setHours(0, 0, 0, 0);
    
    db.get(`
      SELECT COUNT(*) as count 
      FROM conversation_usage 
      WHERE user_id = ? 
      AND date(timestamp, 'localtime') = date('now', 'localtime')
    `, [userId], (err, row: any) => {
      if (err) {
        logger.error('Error getting usage count:', err);
        resolve({ used: 0, limit: 999999, remaining: 999999 });
        return;
      }
      
      const used = row?.count || 0;
      const limit = 999999; // Unlimited for this user
      const remaining = limit - used;
      
      logger.info(`Usage count for user ${userId}: ${used} / ${limit}`);
      resolve({ used, limit, remaining });
    });
  });
});

ipcMain.handle('get-analytics', async (_e, period?: '24h' | '7d' | '30d') => {
  return new Promise((resolve) => {
    if (!db) {
      logger.error('Database not initialized for analytics');
      resolve(null);
      return;
    }

    const analyticsData: any = {};
    
    // Period window clause for SQLite ISO timestamps
    const p = period || '24h';
    const windowClause = p === '7d'
      ? `datetime(timestamp) >= datetime('now','-7 days')`
      : p === '30d'
      ? `datetime(timestamp) >= datetime('now','-30 days')`
      : `datetime(timestamp) >= datetime('now','-24 hours')`;
    
    // Get user-specific data - using the logged-in user's ID
    // This comes from the D1 validation response stored earlier
    const userId = '3034c561-e193-4968-a575-f1b165d31a5b'; // sales@hivetechs.io user ID
    
    // Get period queries for this user from conversation_usage table
    db.get(`
      SELECT COUNT(*) as count 
      FROM conversation_usage 
      WHERE ${windowClause}
      AND user_id = ?
    `, [userId], (err1, row1: any) => {
      if (err1) {
        logger.error('Error getting conversation count:', err1);
        resolve(null);
        return;
      }
      
      logger.info('Analytics - Today queries for user:', row1?.count);
      analyticsData.todayQueries = row1?.count || 0;
      
      // Get all-time total queries for this user
      db.get(`
        SELECT COUNT(*) as count 
        FROM conversation_usage 
        WHERE user_id = ?
      `, [userId], (errTotal, rowTotal: any) => {
        logger.info('Analytics - Total queries for user:', rowTotal?.count);
        analyticsData.totalQueries = rowTotal?.count || 0;
      
      // Get period cost and token usage - join with conversation_usage for user filtering
        db.get(`
          SELECT 
            SUM(c.total_cost) as total_cost,
            SUM(c.total_tokens_input) as total_input,
            SUM(c.total_tokens_output) as total_output,
            AVG(pm.total_duration / 1000.0) as avg_time
          FROM conversations c
          INNER JOIN conversation_usage cu ON c.id = cu.conversation_id
          LEFT JOIN performance_metrics pm ON c.id = pm.conversation_id
          WHERE ${p === '7d' ? `datetime(cu.timestamp) >= datetime('now','-7 days')` : p === '30d' ? `datetime(cu.timestamp) >= datetime('now','-30 days')` : `datetime(cu.timestamp) >= datetime('now','-24 hours')`}
          AND cu.user_id = ?
        `, [userId], (err2, row2: any) => {
        if (err2) logger.error('Error getting today cost data:', err2);
        
          logger.info('Analytics - Today cost data:', row2);
          analyticsData.todayCost = row2?.total_cost || 0;
          analyticsData.todayAvgResponseTime = row2?.avg_time || 0;
          analyticsData.todayTokenUsage = {
            total: (row2?.total_input || 0) + (row2?.total_output || 0),
            input: row2?.total_input || 0,
            output: row2?.total_output || 0
          };
        
          // Get all-time totals - join with conversation_usage for user filtering
          db.get(`
            SELECT 
              SUM(c.total_cost) as total_cost,
              SUM(c.total_tokens_input) as total_input,
              SUM(c.total_tokens_output) as total_output,
              AVG(pm.total_duration / 1000.0) as avg_time
            FROM conversations c
            INNER JOIN conversation_usage cu ON c.id = cu.conversation_id
            LEFT JOIN performance_metrics pm ON c.id = pm.conversation_id
            WHERE cu.user_id = ?
          `, [userId], (errAllTime, rowAllTime: any) => {
            if (errAllTime) logger.error('Error getting all-time cost data:', errAllTime);
            logger.info('Analytics - All-time cost data:', rowAllTime);
            analyticsData.totalCost = rowAllTime?.total_cost || 0;
            analyticsData.avgResponseTime = rowAllTime?.avg_time || 0;
            analyticsData.tokenUsage = {
              total: (rowAllTime?.total_input || 0) + (rowAllTime?.total_output || 0),
              input: rowAllTime?.total_input || 0,
              output: rowAllTime?.total_output || 0
            };
        
        // Get recent activity - join with conversation_usage for user filtering
        db.all(`
          SELECT 
            c.id as conversation_id,
            kc.question,
            c.total_cost as cost,
            c.total_tokens_input,
            c.total_tokens_output,
            pm.total_duration as duration,
            cu.timestamp
          FROM conversation_usage cu
          INNER JOIN conversations c ON c.id = cu.conversation_id
          LEFT JOIN knowledge_conversations kc ON c.id = kc.conversation_id
          LEFT JOIN performance_metrics pm ON c.id = pm.conversation_id
          WHERE cu.user_id = ?
          ORDER BY cu.timestamp DESC 
          LIMIT 10
        `, [userId], (err3, rows3: any[]) => {
          if (err3) logger.error('Error getting recent activity:', err3);
          
          logger.info('Recent activity rows:', rows3?.slice(0, 2)); // Log first 2 rows
          
          analyticsData.recentActivity = (rows3 || []).map((row: any) => ({
            timestamp: row.timestamp,
            question: row.question || 'Query', // Fixed fallback text
            model: 'consensus-pipeline',
            cost: row.cost || 0,
            duration: (row.duration || 0) / 1000, // Convert to seconds
            status: 'completed',
            tokens: (row.total_tokens_input || 0) + (row.total_tokens_output || 0),
            conversationId: row.conversation_id
          }));
          
          // Get model usage from stage_outputs table (tracks all 4 models per conversation)
          db.all(`
            SELECT 
              so.model,
              COUNT(*) as count,
              SUM(so.cost) as totalCost
            FROM stage_outputs so
            INNER JOIN conversation_usage cu ON so.conversation_id = cu.conversation_id
            WHERE cu.user_id = ?
            GROUP BY so.model
            ORDER BY totalCost DESC
          `, [userId], (err4, rows4: any[]) => {
            if (err4) {
              logger.error('Error getting model usage from stage_outputs:', err4);
              // Fallback: Get models from consensus_profiles if stage_outputs is empty
              db.all(`
                SELECT 
                  cp.generator_model as model,
                  COUNT(c.id) as count,
                  SUM(c.total_cost * 0.25) as totalCost
                FROM conversations c
                INNER JOIN conversation_usage cu ON c.id = cu.conversation_id
                LEFT JOIN consensus_profiles cp ON c.profile_id = cp.id
                WHERE cu.user_id = ? AND cp.generator_model IS NOT NULL
                GROUP BY cp.generator_model
                UNION ALL
                SELECT 
                  cp.refiner_model as model,
                  COUNT(c.id) as count,
                  SUM(c.total_cost * 0.25) as totalCost
                FROM conversations c
                INNER JOIN conversation_usage cu ON c.id = cu.conversation_id
                LEFT JOIN consensus_profiles cp ON c.profile_id = cp.id
                WHERE cu.user_id = ? AND cp.refiner_model IS NOT NULL
                GROUP BY cp.refiner_model
                UNION ALL
                SELECT 
                  cp.validator_model as model,
                  COUNT(c.id) as count,
                  SUM(c.total_cost * 0.25) as totalCost
                FROM conversations c
                INNER JOIN conversation_usage cu ON c.id = cu.conversation_id
                LEFT JOIN consensus_profiles cp ON c.profile_id = cp.id
                WHERE cu.user_id = ? AND cp.validator_model IS NOT NULL
                GROUP BY cp.validator_model
                UNION ALL
                SELECT 
                  cp.curator_model as model,
                  COUNT(c.id) as count,
                  SUM(c.total_cost * 0.25) as totalCost
                FROM conversations c
                INNER JOIN conversation_usage cu ON c.id = cu.conversation_id
                LEFT JOIN consensus_profiles cp ON c.profile_id = cp.id
                WHERE cu.user_id = ? AND cp.curator_model IS NOT NULL
                GROUP BY cp.curator_model
              `, [userId, userId, userId, userId], (err5, rows5: any[]) => {
                const modelUsage: { [model: string]: number } = {};
                const modelCosts: { [model: string]: number } = {};
                
                // Aggregate the model data
                (rows5 || []).forEach((row: any) => {
                  const modelName = row.model?.split('/').pop() || row.model; // Simplify model names
                  if (!modelUsage[modelName]) {
                    modelUsage[modelName] = 0;
                    modelCosts[modelName] = 0;
                  }
                  modelUsage[modelName] += row.count || 0;
                  modelCosts[modelName] += row.totalCost || 0;
                });
                
                analyticsData.modelUsage = modelUsage;
                analyticsData.costByModel = modelCosts;
                continueProcessing();
              });
              return;
            }
            
            const modelUsage: { [model: string]: number } = {};
            const modelCosts: { [model: string]: number } = {};
            
            // Process the results from stage_outputs
            (rows4 || []).forEach((row: any) => {
              const modelName = row.model?.split('/').pop() || row.model; // Simplify model names
              if (row.count > 0) {
                modelUsage[modelName] = row.count;
                modelCosts[modelName] = row.totalCost || 0;
              }
            });
            
            analyticsData.modelUsage = modelUsage;
            analyticsData.costByModel = modelCosts;
            continueProcessing();
          });
          
          function continueProcessing() {
            // Calculate hourly stats for last 24 hours
            const hourlyStats: any[] = [];
            const now = new Date();
            
            const processHour = (i: number) => {
              if (i < 0) {
                // All hours processed
                analyticsData.hourlyStats = hourlyStats;
                analyticsData.successRate = analyticsData.totalQueries > 0 ? 100 : 0;
                
                // Add alerts
                analyticsData.alerts = [{
                  type: 'info',
                  message: `Database contains ${analyticsData.totalQueries} consensus queries`,
                  timestamp: new Date().toISOString()
                }];
                
                // Resolve with complete data
                logger.info('Analytics - Complete data:', JSON.stringify(analyticsData, null, 2));
                resolve(analyticsData);
                return;
              }
              
              const hourStart = new Date(now.getTime() - (i + 1) * 60 * 60 * 1000);
              const hourEnd = new Date(now.getTime() - i * 60 * 60 * 1000);
              
              db.get(`
                SELECT 
                  COUNT(DISTINCT cu.conversation_id) as queries,
                  SUM(c.total_cost) as cost,
                  AVG(pm.total_duration / 1000.0) as avg_time
                FROM conversation_usage cu
                LEFT JOIN conversations c ON c.id = cu.conversation_id
                LEFT JOIN performance_metrics pm ON c.id = pm.conversation_id
                WHERE cu.timestamp >= ? AND cu.timestamp < ?
                AND cu.user_id = ?
              `, [hourStart.toISOString(), hourEnd.toISOString(), userId], (err5, row5: any) => {
                if (err5) {
                  logger.error('Error getting hourly stats:', err5);
                  // Continue with default values even if error
                  hourlyStats.push({
                    hour: hourStart.getHours().toString().padStart(2, '0') + ':00',
                    queries: 0,
                    cost: 0,
                    avgTime: 0
                  });
                  processHour(i - 1);
                  return;
                }
                
                hourlyStats.push({
                  hour: hourStart.getHours().toString().padStart(2, '0') + ':00',
                  queries: row5?.queries || 0,
                  cost: row5?.cost || 0,
                  avgTime: row5?.avg_time || 0
                });
                
                // Process next hour
                processHour(i - 1);
              });
            };
            
            // Start processing hours from 23 to 0
            processHour(23);
          }
        });
      });
      });
    });
  });
});

// Read-only analytics computation using a separate DB handle
ipcMain.handle('get-analytics-ro', async (_e, period?: '24h' | '7d' | '30d') => {
  try {
    if (!dbFilePath) throw new Error('DB path not set');
    const ro = new Database(dbFilePath, (Database as any).OPEN_READONLY || undefined);
    const userId = '3034c561-e193-4968-a575-f1b165d31a5b';
    let data = await computeAnalytics(ro, userId, period || '24h');
    // Fallback: if zero queries in period for this user, aggregate across all users
    if (!data || data.todayQueries === 0) {
      const aggregated = await computeAnalytics(ro, '*', period || '24h');
      if (aggregated.todayQueries > 0) {
        aggregated.alerts = (aggregated.alerts || []).concat([{
          type: 'info',
          message: 'No data for current user; showing aggregated analytics',
          timestamp: new Date().toISOString()
        }]);
        data = aggregated;
      }
    }
    ro.close?.();
    return data;
  } catch (e) {
    logger.error('get-analytics-ro failed:', e);
    return null;
  }
});

// Memory Service is now managed entirely by ProcessManager
// Use processManager.startProcess('memory-service') and processManager.stopProcess('memory-service')


// Memory service cleanup is now handled in the unified performCleanup function

// Store reference to main window
app.on('browser-window-created', (_, window) => {
  if (!mainWindow) {
    mainWindow = window;
  }
});
});
