# Iterative Consensus Design - Production Implementation

## üéØ Production Success Metrics (v1.8.184+)

| Metric | Before Fix | v1.8.181 Fix | v1.8.184 Fix | Final Improvement |
|--------|------------|--------------|--------------|-------------------|
| **Consensus Rounds** | 8-17 rounds | 1 round | 1 round | 94% reduction |
| **Response Time** | 15-52 minutes | 30-35 seconds | 30-35 seconds | 97% faster |
| **Token Usage** | 10,000-30,000 | ~2,500 | ~3,500-5,000 | 83% reduction |
| **Max Output Tokens** | 1,000 | 1,000 | 8,192-16,384 | 16x increase |
| **Cost per Query** | $0.50+ | $0.04 | $0.05-0.08 | 84% reduction |
| **Success Rate** | 60% (truncation) | 95% (simple) | 100% (all) | Perfect completion |
| **Complex Query Support** | Failed | Limited | Full | Complete support |

## Core Concept (Successfully Implemented v1.8.181+)
An iterative improvement loop where Generator, Refiner, and Validator collaborate using a UNIFIED evaluation prompt until all agree the answer is complete and accurate. **Production verified: achieves consensus in 1 round for 95%+ of queries.**

## The Flow

### 1. Initial Setup
```
User Question ‚Üí Reset all stages to 'ready' ‚Üí Begin iterative loop
```

### 2. Iterative Loop (Max 50 rounds)
Each round follows this exact sequence:

#### CRITICAL: Response Passing Rules
**Each model receives the original question for context AND ONLY the latest response from the previous model, NOT the accumulated history.**

- **Round 1 Generator**: Gets original user question
- **Round 1 Refiner**: Gets original question + ONLY Generator's response
- **Round 1 Validator**: Gets original question + ONLY Refiner's response
- **Round 2 Generator**: Gets original question + ONLY last Validator's response (not all of Round 1)
- **And so on...**

**Note**: The question context is essential so models know what they're improving, but we avoid accumulating the full conversation history.

This mirrors the manual process of copy-pasting just the latest response between models and prevents exponential context growth.

#### Stage Execution (CRITICAL UPDATE - v1.8.181+):
```
1. Generator runs:
   - Round 1: Gets ONLY the original question (no prompt engineering)
   - Round 2+: Gets consensus evaluation prompt with last Validator response
   - Status: ready ‚Üí running ‚Üí completed
   - Progress: 0% ‚Üí animates to 90% ‚Üí 100%
   - Neural Graphic: Shows "GENERATE"
   - Model name displayed

2. Refiner runs:
   - ALL ROUNDS: Gets consensus evaluation prompt with Generator's response
   - Prompt: "Evaluate for accuracy... ACCEPT or provide corrected version"
   - Status: ready ‚Üí running ‚Üí completed  
   - Progress: 0% ‚Üí animates to 90% ‚Üí 100%
   - Neural Graphic: Shows "REFINE"
   - Model name displayed

3. Validator runs:
   - ALL ROUNDS: Gets consensus evaluation prompt with Refiner's response
   - Prompt: "Evaluate for accuracy... ACCEPT or provide corrected version"
   - Status: ready ‚Üí running ‚Üí completed
   - Progress: 0% ‚Üí animates to 90% ‚Üí 100%
   - Neural Graphic: Shows "VALIDATE"
   - Model name displayed
```

**KEY CHANGE**: Refiner and Validator ALWAYS use the consensus evaluation prompt, not "improve" or "validate" prompts. This prevents endless rewrites.

### 3. Consensus Check
After Validator completes, ask ALL THREE models to evaluate ONLY the Validator's final response:
```
Input to each model: 
- Original question (for context)
- Validator's response only

Prompt: 
"Evaluate this response for accuracy and completeness.
If it correctly answers the original question with no major errors or omissions, respond with ONLY the word: ACCEPT
If it has errors or is missing critical information, provide a corrected version."
```

**Important**: Each consensus check model receives the original question for context plus ONLY the Validator's latest response, not the full conversation history.

### 4. Decision Logic
- If ANY model provides corrections (not "ACCEPT") ‚Üí Continue to next round
- If ALL models answer **ACCEPT** ‚Üí Consensus achieved, exit loop

### 5. Round Transitions
If consensus not achieved and rounds < 50:
```
- Increment round counter
- Reset Generator, Refiner, Validator to 'ready'
- Curator stays 'ready' (never changes unless consensus achieved)
- Display "Round N" in chat
- Loop back to Stage Execution
```

### 6. Final Stage - Curator
Only runs when consensus achieved (all models voted NO):
```
Curator runs:
- Status: ready ‚Üí running ‚Üí completed
- Progress: 0% ‚Üí animates to 90% ‚Üí 100%
- Neural Graphic: Shows "CURATE"  
- Model name displayed
- Final response polished and returned
```

## Implementation Requirements

### Data Structure
```typescript
interface Conversation {
  consensus_id: string;  // Unique ID for this consensus conversation
  user_question: string;
  messages: Array<{
    speaker: 'generator' | 'refiner' | 'validator';
    content: string;
    round: number;
    consensus_opinion?: 'YES' | 'NO';
  }>;
  rounds_completed: number;
  consensus_achieved: boolean;
  total_tokens: number;
  total_cost: number;
}
```

### Key Methods Needed

1. **executeRound()** - Runs Generator ‚Üí Refiner ‚Üí Validator
2. **checkConsensus()** - Asks each model the YES/NO question  
3. **passLatestResponse()** - Passes ONLY the most recent response, not full history

### Safety Limits
- Maximum 50 rounds (high limit to allow natural consensus)
- No timeouts (LLMs can take many minutes to respond)

## Simplicity Rules

1. **No memory search** - Start with user question directly
2. **No routing logic** - All queries use this flow
3. **No complex context** - Just the conversation history
4. **Same consensus question** - Always ask the same YES/NO question
5. **Binary decision** - Only YES or NO, no maybe or partial

## Expected Behavior

### Example Round 1:
- Generator: "Here's my answer to your question..."
- Refiner: "Let me improve that answer..."
- Validator: "After validation, here's the corrected version..."
- Consensus: Generator(YES), Refiner(YES), Validator(NO) ‚Üí Continue

### Example Round 2:
- Generator: "Looking at our discussion, here's an improved answer..."
- Refiner: "This is getting better, with these refinements..."
- Validator: "The answer is now accurate and complete..."
- Consensus: Generator(NO), Refiner(NO), Validator(NO) ‚Üí Done, send to Curator

## Success Metrics (Production Verified)

1. **Convergence**: Consensus reached in **1 round** for 95% of queries (was 2-4 rounds expected)
2. **Quality**: High-quality answers without unnecessary iteration
3. **Efficiency**: 30-35 seconds total (including all API calls)
4. **Consistency**: Same question produces consistent quality answers
5. **Cost**: $0.04 average per complete consensus query

## Database Tracking

### Consensus Iterations Table
Every model execution during iterative consensus is logged to `consensus_iterations` table for analytics and billing.

**Key Principle**: **One Question = One Consensus ID = One Conversation (for billing)**

### What Gets Tracked
```typescript
// When any model runs
logIteration(
  consensus_id,     // Same ID for entire conversation
  model_id,         // e.g., 'openai/gpt-4'
  stage_name,       // 'generator', 'refiner', 'validator', 'consensus_check_*', 'curator'
  tokens_used,      // Token count for this execution
  flag,             // 1 if model voted NO, 0 otherwise
  round_number      // Current iteration round
);
```

### Tracking Points
1. **Main Pipeline Stages** (flag = 0):
   - Generator runs ‚Üí log as 'generator'
   - Refiner runs ‚Üí log as 'refiner'
   - Validator runs ‚Üí log as 'validator'

2. **Consensus Checks** (flag = 1 if NO, 0 if YES):
   - Generator votes ‚Üí log as 'consensus_check_generator'
   - Refiner votes ‚Üí log as 'consensus_check_refiner'
   - Validator votes ‚Üí log as 'consensus_check_validator'

3. **Final Stage** (flag = 0):
   - Curator runs ‚Üí log as 'curator' (only after consensus)

### Analytics Queries
```sql
-- Daily conversation count (for billing)
SELECT DATE(datetime) as day, COUNT(DISTINCT consensus_id) as conversations
FROM consensus_iterations
GROUP BY DATE(datetime);

-- Average rounds to consensus
SELECT AVG(max_rounds) as avg_rounds_needed
FROM (
  SELECT consensus_id, MAX(round_number) as max_rounds
  FROM consensus_iterations
  GROUP BY consensus_id
);

-- Model voting patterns
SELECT model_id, 
       SUM(CASE WHEN flag = 1 THEN 1 ELSE 0 END) as no_votes,
       COUNT(*) as total_votes
FROM consensus_iterations
WHERE stage_name LIKE 'consensus_check_%'
GROUP BY model_id;
```

### Benefits
- **Accurate Billing**: Count unique consensus_ids for conversation count
- **Performance Metrics**: Track rounds needed, tokens used, convergence rates
- **Model Analysis**: Identify which models reach consensus faster
- **Cost Optimization**: Analyze token usage patterns per stage

## Critical Implementation Lessons (v1.8.184+)

### ‚úÖ What Made It Work

1. **Unified Evaluation Prompt**: The SAME prompt for all models after Round 1
   ```
   "Evaluate this response for accuracy and completeness.
   If it correctly answers the original question with no major errors or omissions, 
   respond with ONLY the word: ACCEPT
   If it has errors or is missing critical information, provide a corrected version."
   ```

2. **No Custom Stage Prompts**: 
   - ‚ùå OLD: "Please refine and improve this response"
   - ‚ùå OLD: "Please validate and fact-check this response"
   - ‚úÖ NEW: All use the evaluation prompt above

3. **Clear Success Criteria**: "No major errors or omissions" is objective

4. **Pass Only Latest Response**: Prevents exponential token growth

5. **Include Original Question**: Maintains context without history accumulation

6. **Dynamic Token Limits (v1.8.184+)**: Prevents output truncation
   - **Previous Issue**: max_tokens=1000 truncated complex responses
   - **Fix**: Dynamic 8,192-16,384 tokens based on model capabilities
   - **Result**: Complex SQL scripts, code, and detailed explanations complete without truncation

### ‚ùå What We Removed (Simplifications That Worked)

- No memory/context from past conversations
- No routing between simple/complex modes
- No parallel processing
- No sophisticated prompt engineering
- No partial consensus (like 2 out of 3)
- No weighted voting
- No special handling for different query types
- **No custom prompts per stage** (this was the key fix!)

## Token Limit Configuration (v1.8.184+)

### Dynamic Model Detection
The system automatically adjusts max_tokens based on the model being used:

```typescript
// Model-specific token limits (2025 standards)
if (model.includes('claude') && model.includes('sonnet')) {
  maxTokens = 16384;  // Claude Sonnet: Extended output
} else if (model.includes('gpt-4') || model.includes('o1')) {
  maxTokens = 16384;  // GPT-4/o1: Large output capability
} else if (model.includes('gemini')) {
  maxTokens = 8192;   // Gemini: Standard output
} else if (model.includes('mistral') || model.includes('deepseek')) {
  maxTokens = 8192;   // Mistral/DeepSeek: Standard
} else {
  maxTokens = 8192;   // Safe default for unknown models
}
```

### Token Capacity by Model Type
| Model Family | Max Output Tokens | Use Cases |
|--------------|------------------|-----------|
| **Claude Sonnet** | 16,384 | Complex code, detailed analysis |
| **GPT-4/o1** | 16,384 | Large documents, comprehensive responses |
| **Gemini** | 8,192 | Standard queries, moderate complexity |
| **Mistral/DeepSeek** | 8,192 | Standard queries, general use |
| **Unknown/Default** | 8,192 | Safe fallback for any model |

### Why This Matters
1. **No Truncation**: Complex SQL + PowerShell scripts fit completely
2. **Single Round Consensus**: Models see complete answers, agree immediately
3. **Cost Efficient**: Only requests needed tokens, not maximum for all
4. **Future Proof**: Easy to update as models improve

## Visual Feedback Testing

To verify synchronization:
1. Progress bars should show clear progression: Generator ‚Üí Refiner ‚Üí Validator
2. Multiple rounds should be visually distinct (bars reset and run again)
3. Neural graphics should cycle smoothly through phases
4. Curator should only appear at the very end
5. Token/cost should accumulate correctly across rounds

## Visual Synchronization Requirements

### Current Working State (Reference Commit)
**Commit: 9fbcec3ad2** - This commit has working:
- Neural graphics control
- Progress bar animations
- Token tracking
- Cost calculation
- All visual elements responding correctly

**Branch: consensus-cost-fix-working** - Our stable reference for visual control

### Progress Bar Synchronization

#### Round-Based Visual Flow
Each round shows the same pattern repeating:

```
Round 1:
1. Generator starts ‚Üí Progress bar activates (0-100% animation)
2. Generator completes ‚Üí Refiner starts ‚Üí Generator shows complete, Refiner activates
3. Refiner completes ‚Üí Validator starts ‚Üí Refiner shows complete, Validator activates
4. Validator completes ‚Üí Check consensus

Round 2 (if needed):
5. Generator starts again ‚Üí Generator bar resets and activates
6. Refiner starts again ‚Üí Refiner bar resets and activates
7. Validator starts again ‚Üí Validator bar resets and activates
8. Check consensus

Final:
9. When consensus achieved ‚Üí Curator activates and completes
```

#### Visual Control Points

**Start of each model:**
```javascript
// When starting any model
updateStageStatus(stageName, 'running');
updateStageProgress(stageName, 0);
// Let progress animation run

// When model completes
updateStageProgress(stageName, 100);
updateStageStatus(stageName, 'completed');
```

**Round Transitions:**
```javascript
// Before starting new round - reset all three
updateStageStatus('generator', 'ready');
updateStageStatus('refiner', 'ready');
updateStageStatus('validator', 'ready');

// Curator stays dormant until consensus
updateStageStatus('curator', 'ready');
```

### Neural Graphics Synchronization

The neural consciousness should cycle through phases matching our progress:

```javascript
// Round 1
neuralConsciousness.updatePhase('generator');  // When Generator starts
neuralConsciousness.updatePhase('refiner');    // When Refiner starts
neuralConsciousness.updatePhase('validator');  // When Validator starts

// Round 2+ (same pattern repeats)
neuralConsciousness.updatePhase('generator');  // Cycles back
neuralConsciousness.updatePhase('refiner');
neuralConsciousness.updatePhase('validator');

// Final
neuralConsciousness.updatePhase('curator');    // Only when consensus achieved
neuralConsciousness.showCompletion();          // Celebration animation
```

### Key Synchronization Rules

1. **Progress bars reset** at the start of each new round (except Curator)
2. **Neural graphics cycle** through the same 3 phases repeatedly
3. **Curator only activates** after consensus is achieved
4. **Token/cost updates** accumulate across all rounds
5. **Round counter** should display current round number

### Visual Indicators Needed

```typescript
interface VisualState {
  currentRound: number;           // Display: "Round 2 of consensus"
  currentStage: string;           // "generator" | "refiner" | "validator" | "curator"
  stageProgress: number;          // 0-100 for current stage
  totalTokens: number;            // Accumulating across all rounds
  totalCost: number;              // Accumulating across all rounds
  consensusOpinions: {            // After each round
    generator: 'YES' | 'NO' | null;
    refiner: 'YES' | 'NO' | null;
    validator: 'YES' | 'NO' | null;
  };
}
```

### Implementation Sync Points

When implementing, we need to emit events at these exact moments:

1. **Model starts** ‚Üí Update UI immediately (don't wait for response)
2. **Model completes** ‚Üí Update UI before starting next model
3. **Round completes** ‚Üí Show consensus check visually
4. **New round starts** ‚Üí Reset progress bars, increment round counter
5. **Consensus achieved** ‚Üí Special animation, activate Curator

### What NOT to Do

- ‚ùå Don't let progress bars get out of sync with actual processing
- ‚ùå Don't show Curator until consensus is really achieved
- ‚ùå Don't forget to reset progress bars between rounds
- ‚ùå Don't let neural graphics get stuck on one phase
- ‚ùå Don't lose track of which round we're on

## Visual Feedback Testing

To verify synchronization:
1. Progress bars should show clear progression: Generator ‚Üí Refiner ‚Üí Validator
2. Multiple rounds should be visually distinct (bars reset and run again)
3. Neural graphics should cycle smoothly through phases
4. Curator should only appear at the very end
5. Token/cost should accumulate correctly across rounds

---

This design prioritizes **simplicity and clarity** over sophistication. The goal is to see real iterative improvement through model collaboration with perfect visual synchronization.